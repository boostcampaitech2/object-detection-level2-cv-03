2021-09-29 12:39:15,017 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2
OpenCV: 4.5.3
MMCV: 1.3.14
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: not available
MMDetection: 2.16.0+597a4a0
------------------------------------------------------------

2021-09-29 12:39:19,941 - mmdet - INFO - Distributed training: False
2021-09-29 12:39:25,423 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '/opt/ml/detection/dataset/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
imsize = 800
multi_scale_dict = [
    dict(type='Resize', height=512, width=512),
    dict(type='Resize', height=544, width=512),
    dict(type='Resize', height=576, width=512),
    dict(type='Resize', height=608, width=512),
    dict(type='Resize', height=640, width=512),
    dict(type='Resize', height=672, width=512),
    dict(type='Resize', height=704, width=512),
    dict(type='Resize', height=736, width=512),
    dict(type='Resize', height=768, width=512),
    dict(type='Resize', height=800, width=512),
    dict(type='Resize', height=512, width=544),
    dict(type='Resize', height=544, width=544),
    dict(type='Resize', height=576, width=544),
    dict(type='Resize', height=608, width=544),
    dict(type='Resize', height=640, width=544),
    dict(type='Resize', height=672, width=544),
    dict(type='Resize', height=704, width=544),
    dict(type='Resize', height=736, width=544),
    dict(type='Resize', height=768, width=544),
    dict(type='Resize', height=800, width=544),
    dict(type='Resize', height=512, width=576),
    dict(type='Resize', height=544, width=576),
    dict(type='Resize', height=576, width=576),
    dict(type='Resize', height=608, width=576),
    dict(type='Resize', height=640, width=576),
    dict(type='Resize', height=672, width=576),
    dict(type='Resize', height=704, width=576),
    dict(type='Resize', height=736, width=576),
    dict(type='Resize', height=768, width=576),
    dict(type='Resize', height=800, width=576),
    dict(type='Resize', height=512, width=608),
    dict(type='Resize', height=544, width=608),
    dict(type='Resize', height=576, width=608),
    dict(type='Resize', height=608, width=608),
    dict(type='Resize', height=640, width=608),
    dict(type='Resize', height=672, width=608),
    dict(type='Resize', height=704, width=608),
    dict(type='Resize', height=736, width=608),
    dict(type='Resize', height=768, width=608),
    dict(type='Resize', height=800, width=608),
    dict(type='Resize', height=512, width=640),
    dict(type='Resize', height=544, width=640),
    dict(type='Resize', height=576, width=640),
    dict(type='Resize', height=608, width=640),
    dict(type='Resize', height=640, width=640),
    dict(type='Resize', height=672, width=640),
    dict(type='Resize', height=704, width=640),
    dict(type='Resize', height=736, width=640),
    dict(type='Resize', height=768, width=640),
    dict(type='Resize', height=800, width=640),
    dict(type='Resize', height=512, width=672),
    dict(type='Resize', height=544, width=672),
    dict(type='Resize', height=576, width=672),
    dict(type='Resize', height=608, width=672),
    dict(type='Resize', height=640, width=672),
    dict(type='Resize', height=672, width=672),
    dict(type='Resize', height=704, width=672),
    dict(type='Resize', height=736, width=672),
    dict(type='Resize', height=768, width=672),
    dict(type='Resize', height=800, width=672),
    dict(type='Resize', height=512, width=704),
    dict(type='Resize', height=544, width=704),
    dict(type='Resize', height=576, width=704),
    dict(type='Resize', height=608, width=704),
    dict(type='Resize', height=640, width=704),
    dict(type='Resize', height=672, width=704),
    dict(type='Resize', height=704, width=704),
    dict(type='Resize', height=736, width=704),
    dict(type='Resize', height=768, width=704),
    dict(type='Resize', height=800, width=704),
    dict(type='Resize', height=512, width=736),
    dict(type='Resize', height=544, width=736),
    dict(type='Resize', height=576, width=736),
    dict(type='Resize', height=608, width=736),
    dict(type='Resize', height=640, width=736),
    dict(type='Resize', height=672, width=736),
    dict(type='Resize', height=704, width=736),
    dict(type='Resize', height=736, width=736),
    dict(type='Resize', height=768, width=736),
    dict(type='Resize', height=800, width=736),
    dict(type='Resize', height=512, width=768),
    dict(type='Resize', height=544, width=768),
    dict(type='Resize', height=576, width=768),
    dict(type='Resize', height=608, width=768),
    dict(type='Resize', height=640, width=768),
    dict(type='Resize', height=672, width=768),
    dict(type='Resize', height=704, width=768),
    dict(type='Resize', height=736, width=768),
    dict(type='Resize', height=768, width=768),
    dict(type='Resize', height=800, width=768),
    dict(type='Resize', height=512, width=800),
    dict(type='Resize', height=544, width=800),
    dict(type='Resize', height=576, width=800),
    dict(type='Resize', height=608, width=800),
    dict(type='Resize', height=640, width=800),
    dict(type='Resize', height=672, width=800),
    dict(type='Resize', height=704, width=800),
    dict(type='Resize', height=736, width=800),
    dict(type='Resize', height=768, width=800),
    dict(type='Resize', height=800, width=800)
]
i = 800
w = 800
h = 800
alb_transform = [
    dict(
        type='OneOf',
        transforms=[
            dict(type='Resize', height=512, width=512),
            dict(type='Resize', height=544, width=512),
            dict(type='Resize', height=576, width=512),
            dict(type='Resize', height=608, width=512),
            dict(type='Resize', height=640, width=512),
            dict(type='Resize', height=672, width=512),
            dict(type='Resize', height=704, width=512),
            dict(type='Resize', height=736, width=512),
            dict(type='Resize', height=768, width=512),
            dict(type='Resize', height=800, width=512),
            dict(type='Resize', height=512, width=544),
            dict(type='Resize', height=544, width=544),
            dict(type='Resize', height=576, width=544),
            dict(type='Resize', height=608, width=544),
            dict(type='Resize', height=640, width=544),
            dict(type='Resize', height=672, width=544),
            dict(type='Resize', height=704, width=544),
            dict(type='Resize', height=736, width=544),
            dict(type='Resize', height=768, width=544),
            dict(type='Resize', height=800, width=544),
            dict(type='Resize', height=512, width=576),
            dict(type='Resize', height=544, width=576),
            dict(type='Resize', height=576, width=576),
            dict(type='Resize', height=608, width=576),
            dict(type='Resize', height=640, width=576),
            dict(type='Resize', height=672, width=576),
            dict(type='Resize', height=704, width=576),
            dict(type='Resize', height=736, width=576),
            dict(type='Resize', height=768, width=576),
            dict(type='Resize', height=800, width=576),
            dict(type='Resize', height=512, width=608),
            dict(type='Resize', height=544, width=608),
            dict(type='Resize', height=576, width=608),
            dict(type='Resize', height=608, width=608),
            dict(type='Resize', height=640, width=608),
            dict(type='Resize', height=672, width=608),
            dict(type='Resize', height=704, width=608),
            dict(type='Resize', height=736, width=608),
            dict(type='Resize', height=768, width=608),
            dict(type='Resize', height=800, width=608),
            dict(type='Resize', height=512, width=640),
            dict(type='Resize', height=544, width=640),
            dict(type='Resize', height=576, width=640),
            dict(type='Resize', height=608, width=640),
            dict(type='Resize', height=640, width=640),
            dict(type='Resize', height=672, width=640),
            dict(type='Resize', height=704, width=640),
            dict(type='Resize', height=736, width=640),
            dict(type='Resize', height=768, width=640),
            dict(type='Resize', height=800, width=640),
            dict(type='Resize', height=512, width=672),
            dict(type='Resize', height=544, width=672),
            dict(type='Resize', height=576, width=672),
            dict(type='Resize', height=608, width=672),
            dict(type='Resize', height=640, width=672),
            dict(type='Resize', height=672, width=672),
            dict(type='Resize', height=704, width=672),
            dict(type='Resize', height=736, width=672),
            dict(type='Resize', height=768, width=672),
            dict(type='Resize', height=800, width=672),
            dict(type='Resize', height=512, width=704),
            dict(type='Resize', height=544, width=704),
            dict(type='Resize', height=576, width=704),
            dict(type='Resize', height=608, width=704),
            dict(type='Resize', height=640, width=704),
            dict(type='Resize', height=672, width=704),
            dict(type='Resize', height=704, width=704),
            dict(type='Resize', height=736, width=704),
            dict(type='Resize', height=768, width=704),
            dict(type='Resize', height=800, width=704),
            dict(type='Resize', height=512, width=736),
            dict(type='Resize', height=544, width=736),
            dict(type='Resize', height=576, width=736),
            dict(type='Resize', height=608, width=736),
            dict(type='Resize', height=640, width=736),
            dict(type='Resize', height=672, width=736),
            dict(type='Resize', height=704, width=736),
            dict(type='Resize', height=736, width=736),
            dict(type='Resize', height=768, width=736),
            dict(type='Resize', height=800, width=736),
            dict(type='Resize', height=512, width=768),
            dict(type='Resize', height=544, width=768),
            dict(type='Resize', height=576, width=768),
            dict(type='Resize', height=608, width=768),
            dict(type='Resize', height=640, width=768),
            dict(type='Resize', height=672, width=768),
            dict(type='Resize', height=704, width=768),
            dict(type='Resize', height=736, width=768),
            dict(type='Resize', height=768, width=768),
            dict(type='Resize', height=800, width=768),
            dict(type='Resize', height=512, width=800),
            dict(type='Resize', height=544, width=800),
            dict(type='Resize', height=576, width=800),
            dict(type='Resize', height=608, width=800),
            dict(type='Resize', height=640, width=800),
            dict(type='Resize', height=672, width=800),
            dict(type='Resize', height=704, width=800),
            dict(type='Resize', height=736, width=800),
            dict(type='Resize', height=768, width=800),
            dict(type='Resize', height=800, width=800)
        ],
        p=1.0),
    dict(
        type='OneOf',
        transforms=[
            dict(type='GaussNoise', p=1.0),
            dict(type='GaussianBlur', p=1.0),
            dict(type='Blur', p=1.0)
        ],
        p=0.1),
    dict(
        type='OneOf',
        transforms=[
            dict(type='CLAHE', p=1.0),
            dict(type='RandomGamma', p=1.0),
            dict(type='HueSaturationValue', p=1.0),
            dict(type='ChannelDropout', p=1.0),
            dict(type='ChannelShuffle', p=1.0),
            dict(type='RGBShift', p=1.0)
        ],
        p=0.1),
    dict(
        type='OneOf',
        transforms=[
            dict(type='ShiftScaleRotate', p=1.0),
            dict(type='Rotate', p=1.0)
        ],
        p=0.1)
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(800, 800)),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Resize', height=512, width=512),
                    dict(type='Resize', height=544, width=512),
                    dict(type='Resize', height=576, width=512),
                    dict(type='Resize', height=608, width=512),
                    dict(type='Resize', height=640, width=512),
                    dict(type='Resize', height=672, width=512),
                    dict(type='Resize', height=704, width=512),
                    dict(type='Resize', height=736, width=512),
                    dict(type='Resize', height=768, width=512),
                    dict(type='Resize', height=800, width=512),
                    dict(type='Resize', height=512, width=544),
                    dict(type='Resize', height=544, width=544),
                    dict(type='Resize', height=576, width=544),
                    dict(type='Resize', height=608, width=544),
                    dict(type='Resize', height=640, width=544),
                    dict(type='Resize', height=672, width=544),
                    dict(type='Resize', height=704, width=544),
                    dict(type='Resize', height=736, width=544),
                    dict(type='Resize', height=768, width=544),
                    dict(type='Resize', height=800, width=544),
                    dict(type='Resize', height=512, width=576),
                    dict(type='Resize', height=544, width=576),
                    dict(type='Resize', height=576, width=576),
                    dict(type='Resize', height=608, width=576),
                    dict(type='Resize', height=640, width=576),
                    dict(type='Resize', height=672, width=576),
                    dict(type='Resize', height=704, width=576),
                    dict(type='Resize', height=736, width=576),
                    dict(type='Resize', height=768, width=576),
                    dict(type='Resize', height=800, width=576),
                    dict(type='Resize', height=512, width=608),
                    dict(type='Resize', height=544, width=608),
                    dict(type='Resize', height=576, width=608),
                    dict(type='Resize', height=608, width=608),
                    dict(type='Resize', height=640, width=608),
                    dict(type='Resize', height=672, width=608),
                    dict(type='Resize', height=704, width=608),
                    dict(type='Resize', height=736, width=608),
                    dict(type='Resize', height=768, width=608),
                    dict(type='Resize', height=800, width=608),
                    dict(type='Resize', height=512, width=640),
                    dict(type='Resize', height=544, width=640),
                    dict(type='Resize', height=576, width=640),
                    dict(type='Resize', height=608, width=640),
                    dict(type='Resize', height=640, width=640),
                    dict(type='Resize', height=672, width=640),
                    dict(type='Resize', height=704, width=640),
                    dict(type='Resize', height=736, width=640),
                    dict(type='Resize', height=768, width=640),
                    dict(type='Resize', height=800, width=640),
                    dict(type='Resize', height=512, width=672),
                    dict(type='Resize', height=544, width=672),
                    dict(type='Resize', height=576, width=672),
                    dict(type='Resize', height=608, width=672),
                    dict(type='Resize', height=640, width=672),
                    dict(type='Resize', height=672, width=672),
                    dict(type='Resize', height=704, width=672),
                    dict(type='Resize', height=736, width=672),
                    dict(type='Resize', height=768, width=672),
                    dict(type='Resize', height=800, width=672),
                    dict(type='Resize', height=512, width=704),
                    dict(type='Resize', height=544, width=704),
                    dict(type='Resize', height=576, width=704),
                    dict(type='Resize', height=608, width=704),
                    dict(type='Resize', height=640, width=704),
                    dict(type='Resize', height=672, width=704),
                    dict(type='Resize', height=704, width=704),
                    dict(type='Resize', height=736, width=704),
                    dict(type='Resize', height=768, width=704),
                    dict(type='Resize', height=800, width=704),
                    dict(type='Resize', height=512, width=736),
                    dict(type='Resize', height=544, width=736),
                    dict(type='Resize', height=576, width=736),
                    dict(type='Resize', height=608, width=736),
                    dict(type='Resize', height=640, width=736),
                    dict(type='Resize', height=672, width=736),
                    dict(type='Resize', height=704, width=736),
                    dict(type='Resize', height=736, width=736),
                    dict(type='Resize', height=768, width=736),
                    dict(type='Resize', height=800, width=736),
                    dict(type='Resize', height=512, width=768),
                    dict(type='Resize', height=544, width=768),
                    dict(type='Resize', height=576, width=768),
                    dict(type='Resize', height=608, width=768),
                    dict(type='Resize', height=640, width=768),
                    dict(type='Resize', height=672, width=768),
                    dict(type='Resize', height=704, width=768),
                    dict(type='Resize', height=736, width=768),
                    dict(type='Resize', height=768, width=768),
                    dict(type='Resize', height=800, width=768),
                    dict(type='Resize', height=512, width=800),
                    dict(type='Resize', height=544, width=800),
                    dict(type='Resize', height=576, width=800),
                    dict(type='Resize', height=608, width=800),
                    dict(type='Resize', height=640, width=800),
                    dict(type='Resize', height=672, width=800),
                    dict(type='Resize', height=704, width=800),
                    dict(type='Resize', height=736, width=800),
                    dict(type='Resize', height=768, width=800),
                    dict(type='Resize', height=800, width=800)
                ],
                p=1.0),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='GaussNoise', p=1.0),
                    dict(type='GaussianBlur', p=1.0),
                    dict(type='Blur', p=1.0)
                ],
                p=0.1),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='CLAHE', p=1.0),
                    dict(type='RandomGamma', p=1.0),
                    dict(type='HueSaturationValue', p=1.0),
                    dict(type='ChannelDropout', p=1.0),
                    dict(type='ChannelShuffle', p=1.0),
                    dict(type='RGBShift', p=1.0)
                ],
                p=0.1),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='ShiftScaleRotate', p=1.0),
                    dict(type='Rotate', p=1.0)
                ],
                p=0.1)
        ],
        bbox_params=dict(
            type='BboxParams',
            format='pascal_voc',
            label_fields=['gt_labels'],
            min_visibility=0.0,
            filter_lost_elements=True),
        keymap=dict(img='image', gt_bboxes='bboxes'),
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(type='CutOut', n_holes=4, cutout_shape=(30, 30)),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',
           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/train_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(800, 800)),
            dict(
                type='Albu',
                transforms=[
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Resize', height=512, width=512),
                            dict(type='Resize', height=544, width=512),
                            dict(type='Resize', height=576, width=512),
                            dict(type='Resize', height=608, width=512),
                            dict(type='Resize', height=640, width=512),
                            dict(type='Resize', height=672, width=512),
                            dict(type='Resize', height=704, width=512),
                            dict(type='Resize', height=736, width=512),
                            dict(type='Resize', height=768, width=512),
                            dict(type='Resize', height=800, width=512),
                            dict(type='Resize', height=512, width=544),
                            dict(type='Resize', height=544, width=544),
                            dict(type='Resize', height=576, width=544),
                            dict(type='Resize', height=608, width=544),
                            dict(type='Resize', height=640, width=544),
                            dict(type='Resize', height=672, width=544),
                            dict(type='Resize', height=704, width=544),
                            dict(type='Resize', height=736, width=544),
                            dict(type='Resize', height=768, width=544),
                            dict(type='Resize', height=800, width=544),
                            dict(type='Resize', height=512, width=576),
                            dict(type='Resize', height=544, width=576),
                            dict(type='Resize', height=576, width=576),
                            dict(type='Resize', height=608, width=576),
                            dict(type='Resize', height=640, width=576),
                            dict(type='Resize', height=672, width=576),
                            dict(type='Resize', height=704, width=576),
                            dict(type='Resize', height=736, width=576),
                            dict(type='Resize', height=768, width=576),
                            dict(type='Resize', height=800, width=576),
                            dict(type='Resize', height=512, width=608),
                            dict(type='Resize', height=544, width=608),
                            dict(type='Resize', height=576, width=608),
                            dict(type='Resize', height=608, width=608),
                            dict(type='Resize', height=640, width=608),
                            dict(type='Resize', height=672, width=608),
                            dict(type='Resize', height=704, width=608),
                            dict(type='Resize', height=736, width=608),
                            dict(type='Resize', height=768, width=608),
                            dict(type='Resize', height=800, width=608),
                            dict(type='Resize', height=512, width=640),
                            dict(type='Resize', height=544, width=640),
                            dict(type='Resize', height=576, width=640),
                            dict(type='Resize', height=608, width=640),
                            dict(type='Resize', height=640, width=640),
                            dict(type='Resize', height=672, width=640),
                            dict(type='Resize', height=704, width=640),
                            dict(type='Resize', height=736, width=640),
                            dict(type='Resize', height=768, width=640),
                            dict(type='Resize', height=800, width=640),
                            dict(type='Resize', height=512, width=672),
                            dict(type='Resize', height=544, width=672),
                            dict(type='Resize', height=576, width=672),
                            dict(type='Resize', height=608, width=672),
                            dict(type='Resize', height=640, width=672),
                            dict(type='Resize', height=672, width=672),
                            dict(type='Resize', height=704, width=672),
                            dict(type='Resize', height=736, width=672),
                            dict(type='Resize', height=768, width=672),
                            dict(type='Resize', height=800, width=672),
                            dict(type='Resize', height=512, width=704),
                            dict(type='Resize', height=544, width=704),
                            dict(type='Resize', height=576, width=704),
                            dict(type='Resize', height=608, width=704),
                            dict(type='Resize', height=640, width=704),
                            dict(type='Resize', height=672, width=704),
                            dict(type='Resize', height=704, width=704),
                            dict(type='Resize', height=736, width=704),
                            dict(type='Resize', height=768, width=704),
                            dict(type='Resize', height=800, width=704),
                            dict(type='Resize', height=512, width=736),
                            dict(type='Resize', height=544, width=736),
                            dict(type='Resize', height=576, width=736),
                            dict(type='Resize', height=608, width=736),
                            dict(type='Resize', height=640, width=736),
                            dict(type='Resize', height=672, width=736),
                            dict(type='Resize', height=704, width=736),
                            dict(type='Resize', height=736, width=736),
                            dict(type='Resize', height=768, width=736),
                            dict(type='Resize', height=800, width=736),
                            dict(type='Resize', height=512, width=768),
                            dict(type='Resize', height=544, width=768),
                            dict(type='Resize', height=576, width=768),
                            dict(type='Resize', height=608, width=768),
                            dict(type='Resize', height=640, width=768),
                            dict(type='Resize', height=672, width=768),
                            dict(type='Resize', height=704, width=768),
                            dict(type='Resize', height=736, width=768),
                            dict(type='Resize', height=768, width=768),
                            dict(type='Resize', height=800, width=768),
                            dict(type='Resize', height=512, width=800),
                            dict(type='Resize', height=544, width=800),
                            dict(type='Resize', height=576, width=800),
                            dict(type='Resize', height=608, width=800),
                            dict(type='Resize', height=640, width=800),
                            dict(type='Resize', height=672, width=800),
                            dict(type='Resize', height=704, width=800),
                            dict(type='Resize', height=736, width=800),
                            dict(type='Resize', height=768, width=800),
                            dict(type='Resize', height=800, width=800)
                        ],
                        p=1.0),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='GaussNoise', p=1.0),
                            dict(type='GaussianBlur', p=1.0),
                            dict(type='Blur', p=1.0)
                        ],
                        p=0.1),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='CLAHE', p=1.0),
                            dict(type='RandomGamma', p=1.0),
                            dict(type='HueSaturationValue', p=1.0),
                            dict(type='ChannelDropout', p=1.0),
                            dict(type='ChannelShuffle', p=1.0),
                            dict(type='RGBShift', p=1.0)
                        ],
                        p=0.1),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='ShiftScaleRotate', p=1.0),
                            dict(type='Rotate', p=1.0)
                        ],
                        p=0.1)
                ],
                bbox_params=dict(
                    type='BboxParams',
                    format='pascal_voc',
                    label_fields=['gt_labels'],
                    min_visibility=0.0,
                    filter_lost_elements=True),
                keymap=dict(img='image', gt_bboxes='bboxes'),
                update_pad_shape=False,
                skip_img_without_anno=True),
            dict(type='CutOut', n_holes=4, cutout_shape=(30, 30)),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/val_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/val_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
lr = 0.0001
optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.1,
    min_lr_ratio=1e-06)
total_epochs = 50
expr_name = 'hrn_cascade_16_cutout_832ms'
dist_params = dict(backend='nccl')
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=10,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(
            type='WandbLoggerHook',
            init_kwargs=dict(
                project='P-stage2-detection',
                name='hrn_cascade_16_cutout_832ms'))
    ])
custom_hooks = [dict(type='NumClassCheckHook')]
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
runner = dict(type='EpochBasedRunner', max_epochs=50)
work_dir = './work_dirs/hrn_cascade_16_cutout_832ms'
gpu_ids = range(0, 1)
model = dict(
    type='CascadeRCNN',
    backbone=dict(
        type='HRNet',
        extra=dict(
            stage1=dict(
                num_modules=1,
                num_branches=1,
                block='BOTTLENECK',
                num_blocks=(4, ),
                num_channels=(64, )),
            stage2=dict(
                num_modules=1,
                num_branches=2,
                block='BASIC',
                num_blocks=(4, 4),
                num_channels=(18, 36)),
            stage3=dict(
                num_modules=4,
                num_branches=3,
                block='BASIC',
                num_blocks=(4, 4, 4),
                num_channels=(18, 36, 72)),
            stage4=dict(
                num_modules=3,
                num_branches=4,
                block='BASIC',
                num_blocks=(4, 4, 4, 4),
                num_channels=(18, 36, 72, 144))),
        init_cfg=dict(
            type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18')),
    neck=dict(
        type='HRFPN',
        in_channels=[18, 36, 72, 144],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='DIoULoss', loss_weight=2.5)),
    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=2.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=2.5)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=3.0))
        ]),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=30),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=30),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=71)))

/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/core/anchor/builder.py:17: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` 
  '``build_anchor_generator`` would be deprecated soon, please use '
2021-09-29 12:39:26,172 - mmdet - INFO - initialize HRNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://msra/hrnetv2_w18'}
2021-09-29 12:39:26,172 - mmcv - INFO - load model from: open-mmlab://msra/hrnetv2_w18
2021-09-29 12:39:26,172 - mmcv - INFO - Use load_from_openmmlab loader
2021-09-29 12:39:26,638 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: incre_modules.0.0.conv1.weight, incre_modules.0.0.bn1.weight, incre_modules.0.0.bn1.bias, incre_modules.0.0.bn1.running_mean, incre_modules.0.0.bn1.running_var, incre_modules.0.0.bn1.num_batches_tracked, incre_modules.0.0.conv2.weight, incre_modules.0.0.bn2.weight, incre_modules.0.0.bn2.bias, incre_modules.0.0.bn2.running_mean, incre_modules.0.0.bn2.running_var, incre_modules.0.0.bn2.num_batches_tracked, incre_modules.0.0.conv3.weight, incre_modules.0.0.bn3.weight, incre_modules.0.0.bn3.bias, incre_modules.0.0.bn3.running_mean, incre_modules.0.0.bn3.running_var, incre_modules.0.0.bn3.num_batches_tracked, incre_modules.0.0.downsample.0.weight, incre_modules.0.0.downsample.1.weight, incre_modules.0.0.downsample.1.bias, incre_modules.0.0.downsample.1.running_mean, incre_modules.0.0.downsample.1.running_var, incre_modules.0.0.downsample.1.num_batches_tracked, incre_modules.1.0.conv1.weight, incre_modules.1.0.bn1.weight, incre_modules.1.0.bn1.bias, incre_modules.1.0.bn1.running_mean, incre_modules.1.0.bn1.running_var, incre_modules.1.0.bn1.num_batches_tracked, incre_modules.1.0.conv2.weight, incre_modules.1.0.bn2.weight, incre_modules.1.0.bn2.bias, incre_modules.1.0.bn2.running_mean, incre_modules.1.0.bn2.running_var, incre_modules.1.0.bn2.num_batches_tracked, incre_modules.1.0.conv3.weight, incre_modules.1.0.bn3.weight, incre_modules.1.0.bn3.bias, incre_modules.1.0.bn3.running_mean, incre_modules.1.0.bn3.running_var, incre_modules.1.0.bn3.num_batches_tracked, incre_modules.1.0.downsample.0.weight, incre_modules.1.0.downsample.1.weight, incre_modules.1.0.downsample.1.bias, incre_modules.1.0.downsample.1.running_mean, incre_modules.1.0.downsample.1.running_var, incre_modules.1.0.downsample.1.num_batches_tracked, incre_modules.2.0.conv1.weight, incre_modules.2.0.bn1.weight, incre_modules.2.0.bn1.bias, incre_modules.2.0.bn1.running_mean, incre_modules.2.0.bn1.running_var, incre_modules.2.0.bn1.num_batches_tracked, incre_modules.2.0.conv2.weight, incre_modules.2.0.bn2.weight, incre_modules.2.0.bn2.bias, incre_modules.2.0.bn2.running_mean, incre_modules.2.0.bn2.running_var, incre_modules.2.0.bn2.num_batches_tracked, incre_modules.2.0.conv3.weight, incre_modules.2.0.bn3.weight, incre_modules.2.0.bn3.bias, incre_modules.2.0.bn3.running_mean, incre_modules.2.0.bn3.running_var, incre_modules.2.0.bn3.num_batches_tracked, incre_modules.2.0.downsample.0.weight, incre_modules.2.0.downsample.1.weight, incre_modules.2.0.downsample.1.bias, incre_modules.2.0.downsample.1.running_mean, incre_modules.2.0.downsample.1.running_var, incre_modules.2.0.downsample.1.num_batches_tracked, incre_modules.3.0.conv1.weight, incre_modules.3.0.bn1.weight, incre_modules.3.0.bn1.bias, incre_modules.3.0.bn1.running_mean, incre_modules.3.0.bn1.running_var, incre_modules.3.0.bn1.num_batches_tracked, incre_modules.3.0.conv2.weight, incre_modules.3.0.bn2.weight, incre_modules.3.0.bn2.bias, incre_modules.3.0.bn2.running_mean, incre_modules.3.0.bn2.running_var, incre_modules.3.0.bn2.num_batches_tracked, incre_modules.3.0.conv3.weight, incre_modules.3.0.bn3.weight, incre_modules.3.0.bn3.bias, incre_modules.3.0.bn3.running_mean, incre_modules.3.0.bn3.running_var, incre_modules.3.0.bn3.num_batches_tracked, incre_modules.3.0.downsample.0.weight, incre_modules.3.0.downsample.1.weight, incre_modules.3.0.downsample.1.bias, incre_modules.3.0.downsample.1.running_mean, incre_modules.3.0.downsample.1.running_var, incre_modules.3.0.downsample.1.num_batches_tracked, downsamp_modules.0.0.weight, downsamp_modules.0.0.bias, downsamp_modules.0.1.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.1.0.weight, downsamp_modules.1.0.bias, downsamp_modules.1.1.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.2.0.weight, downsamp_modules.2.0.bias, downsamp_modules.2.1.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.num_batches_tracked, final_layer.0.weight, final_layer.0.bias, final_layer.1.weight, final_layer.1.bias, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.num_batches_tracked, classifier.weight, classifier.bias

2021-09-29 12:39:26,743 - mmdet - INFO - initialize HRFPN with init_cfg {'type': 'Caffe2Xavier', 'layer': 'Conv2d'}
2021-09-29 12:39:26,769 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2021-09-29 12:39:26,778 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 12:39:27,118 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 12:39:27,464 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/datasets/api_wrappers/coco_api.py:22: UserWarning: mmpycocotools is deprecated. Please install official pycocotools by "pip install pycocotools"
  UserWarning)
/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/datasets/api_wrappers/coco_api.py:22: UserWarning: mmpycocotools is deprecated. Please install official pycocotools by "pip install pycocotools"
  UserWarning)
2021-09-29 12:39:31,418 - mmdet - INFO - Start running, host: root@965f40750ba2, work_dir: /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/work_dirs/hrn_cascade_16_cutout_832ms
2021-09-29 12:39:31,418 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_run:
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
2021-09-29 12:39:31,419 - mmdet - INFO - workflow: [('train', 1)], max: 50 epochs
wandb: Currently logged in as: ark10806 (use `wandb login --relogin` to force relogin)
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
loading annotations into memory...
Done (t=0.22s)
creating index...
index created!
wandb: Tracking run with wandb version 0.12.2
wandb: Syncing run hrn_cascade_16_cutout_832ms
wandb:  View project at https://wandb.ai/ark10806/P-stage2-detection
wandb:  View run at https://wandb.ai/ark10806/P-stage2-detection/runs/1hbxrzl3
wandb: Run data is saved locally in /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/wandb/run-20210929_123932-1hbxrzl3
wandb: Run `wandb offline` to turn off syncing.

/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` 
  warnings.warn('``grid_anchors`` would be deprecated soon. '
/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/core/anchor/anchor_generator.py:361: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` 
  '``single_level_grid_anchors`` would be deprecated soon. '
Traceback (most recent call last):
  File "tools/train.py", line 189, in <module>
    main()
  File "tools/train.py", line 185, in main
    meta=meta)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/apis/train.py", line 174, in train_detector
    runner.run(data_loaders, cfg.workflow)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 50, in train
    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 30, in run_iter
    **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/data_parallel.py", line 67, in train_step
    return self.module.train_step(*inputs[0], **kwargs[0])
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 238, in train_step
    losses = self(**data)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
    return old_func(*args, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 172, in forward
    return self.forward_train(img, img_metas, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/detectors/two_stage.py", line 141, in forward_train
    proposal_cfg=proposal_cfg)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/dense_heads/base_dense_head.py", line 59, in forward_train
    proposal_list = self.get_bboxes(*outs, img_metas, cfg=proposal_cfg)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 186, in new_func
    return old_func(*args, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/dense_heads/rpn_head.py", line 131, in get_bboxes
    scale_factor, cfg, rescale)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/dense_heads/rpn_head.py", line 221, in _get_bboxes_single
    dets, keep = batched_nms(proposals, scores, ids, cfg.nms)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/ops/nms.py", line 307, in batched_nms
    dets, keep = nms_op(boxes_for_nms, scores, **nms_cfg_)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/utils/misc.py", line 330, in new_func
    output = old_func(*args, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/ops/nms.py", line 172, in nms
    score_threshold, max_num)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/ops/nms.py", line 27, in forward
    bboxes, scores, iou_threshold=float(iou_threshold), offset=offset)
RuntimeError: nms is not compiled with GPU support
Exception raised from nms at /tmp/mmcv/mmcv/ops/csrc/pytorch/nms.cpp:71 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f22c296d8b2 in /opt/conda/envs/detection/lib/python3.7/site-packages/torch/lib/libc10.so)
frame #1: nms(at::Tensor, at::Tensor, float, int) + 0x754 (0x7f228ab2c9b4 in /opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/_ext.cpython-37m-x86_64-linux-gnu.so)
frame #2: <unknown function> + 0x82184 (0x7f228ab6b184 in /opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/_ext.cpython-37m-x86_64-linux-gnu.so)
frame #3: <unknown function> + 0x74f4f (0x7f228ab5df4f in /opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/_ext.cpython-37m-x86_64-linux-gnu.so)
<omitting python frames>
frame #8: THPFunction_apply(_object*, _object*) + 0x93d (0x7f2341c2200d in /opt/conda/envs/detection/lib/python3.7/site-packages/torch/lib/libtorch_python.so)

wandb: Waiting for W&B process to finish, PID 27538
wandb: Program failed with code 1.  Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/wandb/run-20210929_123932-1hbxrzl3/logs/debug.log
wandb: Find internal logs for this run at: /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/wandb/run-20210929_123932-1hbxrzl3/logs/debug-internal.log
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced hrn_cascade_16_cutout_832ms: https://wandb.ai/ark10806/P-stage2-detection/runs/1hbxrzl3

2021-09-29 12:41:10,741 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2
OpenCV: 4.5.3
MMCV: 1.3.14
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: not available
MMDetection: 2.16.0+597a4a0
------------------------------------------------------------

2021-09-29 12:41:15,900 - mmdet - INFO - Distributed training: False
2021-09-29 12:41:21,126 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '/opt/ml/detection/dataset/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
imsize = 800
multi_scale_dict = [
    dict(type='Resize', height=512, width=512),
    dict(type='Resize', height=544, width=512),
    dict(type='Resize', height=576, width=512),
    dict(type='Resize', height=608, width=512),
    dict(type='Resize', height=640, width=512),
    dict(type='Resize', height=672, width=512),
    dict(type='Resize', height=704, width=512),
    dict(type='Resize', height=736, width=512),
    dict(type='Resize', height=768, width=512),
    dict(type='Resize', height=800, width=512),
    dict(type='Resize', height=512, width=544),
    dict(type='Resize', height=544, width=544),
    dict(type='Resize', height=576, width=544),
    dict(type='Resize', height=608, width=544),
    dict(type='Resize', height=640, width=544),
    dict(type='Resize', height=672, width=544),
    dict(type='Resize', height=704, width=544),
    dict(type='Resize', height=736, width=544),
    dict(type='Resize', height=768, width=544),
    dict(type='Resize', height=800, width=544),
    dict(type='Resize', height=512, width=576),
    dict(type='Resize', height=544, width=576),
    dict(type='Resize', height=576, width=576),
    dict(type='Resize', height=608, width=576),
    dict(type='Resize', height=640, width=576),
    dict(type='Resize', height=672, width=576),
    dict(type='Resize', height=704, width=576),
    dict(type='Resize', height=736, width=576),
    dict(type='Resize', height=768, width=576),
    dict(type='Resize', height=800, width=576),
    dict(type='Resize', height=512, width=608),
    dict(type='Resize', height=544, width=608),
    dict(type='Resize', height=576, width=608),
    dict(type='Resize', height=608, width=608),
    dict(type='Resize', height=640, width=608),
    dict(type='Resize', height=672, width=608),
    dict(type='Resize', height=704, width=608),
    dict(type='Resize', height=736, width=608),
    dict(type='Resize', height=768, width=608),
    dict(type='Resize', height=800, width=608),
    dict(type='Resize', height=512, width=640),
    dict(type='Resize', height=544, width=640),
    dict(type='Resize', height=576, width=640),
    dict(type='Resize', height=608, width=640),
    dict(type='Resize', height=640, width=640),
    dict(type='Resize', height=672, width=640),
    dict(type='Resize', height=704, width=640),
    dict(type='Resize', height=736, width=640),
    dict(type='Resize', height=768, width=640),
    dict(type='Resize', height=800, width=640),
    dict(type='Resize', height=512, width=672),
    dict(type='Resize', height=544, width=672),
    dict(type='Resize', height=576, width=672),
    dict(type='Resize', height=608, width=672),
    dict(type='Resize', height=640, width=672),
    dict(type='Resize', height=672, width=672),
    dict(type='Resize', height=704, width=672),
    dict(type='Resize', height=736, width=672),
    dict(type='Resize', height=768, width=672),
    dict(type='Resize', height=800, width=672),
    dict(type='Resize', height=512, width=704),
    dict(type='Resize', height=544, width=704),
    dict(type='Resize', height=576, width=704),
    dict(type='Resize', height=608, width=704),
    dict(type='Resize', height=640, width=704),
    dict(type='Resize', height=672, width=704),
    dict(type='Resize', height=704, width=704),
    dict(type='Resize', height=736, width=704),
    dict(type='Resize', height=768, width=704),
    dict(type='Resize', height=800, width=704),
    dict(type='Resize', height=512, width=736),
    dict(type='Resize', height=544, width=736),
    dict(type='Resize', height=576, width=736),
    dict(type='Resize', height=608, width=736),
    dict(type='Resize', height=640, width=736),
    dict(type='Resize', height=672, width=736),
    dict(type='Resize', height=704, width=736),
    dict(type='Resize', height=736, width=736),
    dict(type='Resize', height=768, width=736),
    dict(type='Resize', height=800, width=736),
    dict(type='Resize', height=512, width=768),
    dict(type='Resize', height=544, width=768),
    dict(type='Resize', height=576, width=768),
    dict(type='Resize', height=608, width=768),
    dict(type='Resize', height=640, width=768),
    dict(type='Resize', height=672, width=768),
    dict(type='Resize', height=704, width=768),
    dict(type='Resize', height=736, width=768),
    dict(type='Resize', height=768, width=768),
    dict(type='Resize', height=800, width=768),
    dict(type='Resize', height=512, width=800),
    dict(type='Resize', height=544, width=800),
    dict(type='Resize', height=576, width=800),
    dict(type='Resize', height=608, width=800),
    dict(type='Resize', height=640, width=800),
    dict(type='Resize', height=672, width=800),
    dict(type='Resize', height=704, width=800),
    dict(type='Resize', height=736, width=800),
    dict(type='Resize', height=768, width=800),
    dict(type='Resize', height=800, width=800)
]
i = 800
w = 800
h = 800
alb_transform = [
    dict(
        type='OneOf',
        transforms=[
            dict(type='Resize', height=512, width=512),
            dict(type='Resize', height=544, width=512),
            dict(type='Resize', height=576, width=512),
            dict(type='Resize', height=608, width=512),
            dict(type='Resize', height=640, width=512),
            dict(type='Resize', height=672, width=512),
            dict(type='Resize', height=704, width=512),
            dict(type='Resize', height=736, width=512),
            dict(type='Resize', height=768, width=512),
            dict(type='Resize', height=800, width=512),
            dict(type='Resize', height=512, width=544),
            dict(type='Resize', height=544, width=544),
            dict(type='Resize', height=576, width=544),
            dict(type='Resize', height=608, width=544),
            dict(type='Resize', height=640, width=544),
            dict(type='Resize', height=672, width=544),
            dict(type='Resize', height=704, width=544),
            dict(type='Resize', height=736, width=544),
            dict(type='Resize', height=768, width=544),
            dict(type='Resize', height=800, width=544),
            dict(type='Resize', height=512, width=576),
            dict(type='Resize', height=544, width=576),
            dict(type='Resize', height=576, width=576),
            dict(type='Resize', height=608, width=576),
            dict(type='Resize', height=640, width=576),
            dict(type='Resize', height=672, width=576),
            dict(type='Resize', height=704, width=576),
            dict(type='Resize', height=736, width=576),
            dict(type='Resize', height=768, width=576),
            dict(type='Resize', height=800, width=576),
            dict(type='Resize', height=512, width=608),
            dict(type='Resize', height=544, width=608),
            dict(type='Resize', height=576, width=608),
            dict(type='Resize', height=608, width=608),
            dict(type='Resize', height=640, width=608),
            dict(type='Resize', height=672, width=608),
            dict(type='Resize', height=704, width=608),
            dict(type='Resize', height=736, width=608),
            dict(type='Resize', height=768, width=608),
            dict(type='Resize', height=800, width=608),
            dict(type='Resize', height=512, width=640),
            dict(type='Resize', height=544, width=640),
            dict(type='Resize', height=576, width=640),
            dict(type='Resize', height=608, width=640),
            dict(type='Resize', height=640, width=640),
            dict(type='Resize', height=672, width=640),
            dict(type='Resize', height=704, width=640),
            dict(type='Resize', height=736, width=640),
            dict(type='Resize', height=768, width=640),
            dict(type='Resize', height=800, width=640),
            dict(type='Resize', height=512, width=672),
            dict(type='Resize', height=544, width=672),
            dict(type='Resize', height=576, width=672),
            dict(type='Resize', height=608, width=672),
            dict(type='Resize', height=640, width=672),
            dict(type='Resize', height=672, width=672),
            dict(type='Resize', height=704, width=672),
            dict(type='Resize', height=736, width=672),
            dict(type='Resize', height=768, width=672),
            dict(type='Resize', height=800, width=672),
            dict(type='Resize', height=512, width=704),
            dict(type='Resize', height=544, width=704),
            dict(type='Resize', height=576, width=704),
            dict(type='Resize', height=608, width=704),
            dict(type='Resize', height=640, width=704),
            dict(type='Resize', height=672, width=704),
            dict(type='Resize', height=704, width=704),
            dict(type='Resize', height=736, width=704),
            dict(type='Resize', height=768, width=704),
            dict(type='Resize', height=800, width=704),
            dict(type='Resize', height=512, width=736),
            dict(type='Resize', height=544, width=736),
            dict(type='Resize', height=576, width=736),
            dict(type='Resize', height=608, width=736),
            dict(type='Resize', height=640, width=736),
            dict(type='Resize', height=672, width=736),
            dict(type='Resize', height=704, width=736),
            dict(type='Resize', height=736, width=736),
            dict(type='Resize', height=768, width=736),
            dict(type='Resize', height=800, width=736),
            dict(type='Resize', height=512, width=768),
            dict(type='Resize', height=544, width=768),
            dict(type='Resize', height=576, width=768),
            dict(type='Resize', height=608, width=768),
            dict(type='Resize', height=640, width=768),
            dict(type='Resize', height=672, width=768),
            dict(type='Resize', height=704, width=768),
            dict(type='Resize', height=736, width=768),
            dict(type='Resize', height=768, width=768),
            dict(type='Resize', height=800, width=768),
            dict(type='Resize', height=512, width=800),
            dict(type='Resize', height=544, width=800),
            dict(type='Resize', height=576, width=800),
            dict(type='Resize', height=608, width=800),
            dict(type='Resize', height=640, width=800),
            dict(type='Resize', height=672, width=800),
            dict(type='Resize', height=704, width=800),
            dict(type='Resize', height=736, width=800),
            dict(type='Resize', height=768, width=800),
            dict(type='Resize', height=800, width=800)
        ],
        p=1.0),
    dict(
        type='OneOf',
        transforms=[
            dict(type='GaussNoise', p=1.0),
            dict(type='GaussianBlur', p=1.0),
            dict(type='Blur', p=1.0)
        ],
        p=0.1),
    dict(
        type='OneOf',
        transforms=[
            dict(type='CLAHE', p=1.0),
            dict(type='RandomGamma', p=1.0),
            dict(type='HueSaturationValue', p=1.0),
            dict(type='ChannelDropout', p=1.0),
            dict(type='ChannelShuffle', p=1.0),
            dict(type='RGBShift', p=1.0)
        ],
        p=0.1),
    dict(
        type='OneOf',
        transforms=[
            dict(type='ShiftScaleRotate', p=1.0),
            dict(type='Rotate', p=1.0)
        ],
        p=0.1)
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(800, 800)),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Resize', height=512, width=512),
                    dict(type='Resize', height=544, width=512),
                    dict(type='Resize', height=576, width=512),
                    dict(type='Resize', height=608, width=512),
                    dict(type='Resize', height=640, width=512),
                    dict(type='Resize', height=672, width=512),
                    dict(type='Resize', height=704, width=512),
                    dict(type='Resize', height=736, width=512),
                    dict(type='Resize', height=768, width=512),
                    dict(type='Resize', height=800, width=512),
                    dict(type='Resize', height=512, width=544),
                    dict(type='Resize', height=544, width=544),
                    dict(type='Resize', height=576, width=544),
                    dict(type='Resize', height=608, width=544),
                    dict(type='Resize', height=640, width=544),
                    dict(type='Resize', height=672, width=544),
                    dict(type='Resize', height=704, width=544),
                    dict(type='Resize', height=736, width=544),
                    dict(type='Resize', height=768, width=544),
                    dict(type='Resize', height=800, width=544),
                    dict(type='Resize', height=512, width=576),
                    dict(type='Resize', height=544, width=576),
                    dict(type='Resize', height=576, width=576),
                    dict(type='Resize', height=608, width=576),
                    dict(type='Resize', height=640, width=576),
                    dict(type='Resize', height=672, width=576),
                    dict(type='Resize', height=704, width=576),
                    dict(type='Resize', height=736, width=576),
                    dict(type='Resize', height=768, width=576),
                    dict(type='Resize', height=800, width=576),
                    dict(type='Resize', height=512, width=608),
                    dict(type='Resize', height=544, width=608),
                    dict(type='Resize', height=576, width=608),
                    dict(type='Resize', height=608, width=608),
                    dict(type='Resize', height=640, width=608),
                    dict(type='Resize', height=672, width=608),
                    dict(type='Resize', height=704, width=608),
                    dict(type='Resize', height=736, width=608),
                    dict(type='Resize', height=768, width=608),
                    dict(type='Resize', height=800, width=608),
                    dict(type='Resize', height=512, width=640),
                    dict(type='Resize', height=544, width=640),
                    dict(type='Resize', height=576, width=640),
                    dict(type='Resize', height=608, width=640),
                    dict(type='Resize', height=640, width=640),
                    dict(type='Resize', height=672, width=640),
                    dict(type='Resize', height=704, width=640),
                    dict(type='Resize', height=736, width=640),
                    dict(type='Resize', height=768, width=640),
                    dict(type='Resize', height=800, width=640),
                    dict(type='Resize', height=512, width=672),
                    dict(type='Resize', height=544, width=672),
                    dict(type='Resize', height=576, width=672),
                    dict(type='Resize', height=608, width=672),
                    dict(type='Resize', height=640, width=672),
                    dict(type='Resize', height=672, width=672),
                    dict(type='Resize', height=704, width=672),
                    dict(type='Resize', height=736, width=672),
                    dict(type='Resize', height=768, width=672),
                    dict(type='Resize', height=800, width=672),
                    dict(type='Resize', height=512, width=704),
                    dict(type='Resize', height=544, width=704),
                    dict(type='Resize', height=576, width=704),
                    dict(type='Resize', height=608, width=704),
                    dict(type='Resize', height=640, width=704),
                    dict(type='Resize', height=672, width=704),
                    dict(type='Resize', height=704, width=704),
                    dict(type='Resize', height=736, width=704),
                    dict(type='Resize', height=768, width=704),
                    dict(type='Resize', height=800, width=704),
                    dict(type='Resize', height=512, width=736),
                    dict(type='Resize', height=544, width=736),
                    dict(type='Resize', height=576, width=736),
                    dict(type='Resize', height=608, width=736),
                    dict(type='Resize', height=640, width=736),
                    dict(type='Resize', height=672, width=736),
                    dict(type='Resize', height=704, width=736),
                    dict(type='Resize', height=736, width=736),
                    dict(type='Resize', height=768, width=736),
                    dict(type='Resize', height=800, width=736),
                    dict(type='Resize', height=512, width=768),
                    dict(type='Resize', height=544, width=768),
                    dict(type='Resize', height=576, width=768),
                    dict(type='Resize', height=608, width=768),
                    dict(type='Resize', height=640, width=768),
                    dict(type='Resize', height=672, width=768),
                    dict(type='Resize', height=704, width=768),
                    dict(type='Resize', height=736, width=768),
                    dict(type='Resize', height=768, width=768),
                    dict(type='Resize', height=800, width=768),
                    dict(type='Resize', height=512, width=800),
                    dict(type='Resize', height=544, width=800),
                    dict(type='Resize', height=576, width=800),
                    dict(type='Resize', height=608, width=800),
                    dict(type='Resize', height=640, width=800),
                    dict(type='Resize', height=672, width=800),
                    dict(type='Resize', height=704, width=800),
                    dict(type='Resize', height=736, width=800),
                    dict(type='Resize', height=768, width=800),
                    dict(type='Resize', height=800, width=800)
                ],
                p=1.0),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='GaussNoise', p=1.0),
                    dict(type='GaussianBlur', p=1.0),
                    dict(type='Blur', p=1.0)
                ],
                p=0.1),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='CLAHE', p=1.0),
                    dict(type='RandomGamma', p=1.0),
                    dict(type='HueSaturationValue', p=1.0),
                    dict(type='ChannelDropout', p=1.0),
                    dict(type='ChannelShuffle', p=1.0),
                    dict(type='RGBShift', p=1.0)
                ],
                p=0.1),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='ShiftScaleRotate', p=1.0),
                    dict(type='Rotate', p=1.0)
                ],
                p=0.1)
        ],
        bbox_params=dict(
            type='BboxParams',
            format='pascal_voc',
            label_fields=['gt_labels'],
            min_visibility=0.0,
            filter_lost_elements=True),
        keymap=dict(img='image', gt_bboxes='bboxes'),
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(type='CutOut', n_holes=4, cutout_shape=(30, 30)),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',
           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/train_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(800, 800)),
            dict(
                type='Albu',
                transforms=[
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Resize', height=512, width=512),
                            dict(type='Resize', height=544, width=512),
                            dict(type='Resize', height=576, width=512),
                            dict(type='Resize', height=608, width=512),
                            dict(type='Resize', height=640, width=512),
                            dict(type='Resize', height=672, width=512),
                            dict(type='Resize', height=704, width=512),
                            dict(type='Resize', height=736, width=512),
                            dict(type='Resize', height=768, width=512),
                            dict(type='Resize', height=800, width=512),
                            dict(type='Resize', height=512, width=544),
                            dict(type='Resize', height=544, width=544),
                            dict(type='Resize', height=576, width=544),
                            dict(type='Resize', height=608, width=544),
                            dict(type='Resize', height=640, width=544),
                            dict(type='Resize', height=672, width=544),
                            dict(type='Resize', height=704, width=544),
                            dict(type='Resize', height=736, width=544),
                            dict(type='Resize', height=768, width=544),
                            dict(type='Resize', height=800, width=544),
                            dict(type='Resize', height=512, width=576),
                            dict(type='Resize', height=544, width=576),
                            dict(type='Resize', height=576, width=576),
                            dict(type='Resize', height=608, width=576),
                            dict(type='Resize', height=640, width=576),
                            dict(type='Resize', height=672, width=576),
                            dict(type='Resize', height=704, width=576),
                            dict(type='Resize', height=736, width=576),
                            dict(type='Resize', height=768, width=576),
                            dict(type='Resize', height=800, width=576),
                            dict(type='Resize', height=512, width=608),
                            dict(type='Resize', height=544, width=608),
                            dict(type='Resize', height=576, width=608),
                            dict(type='Resize', height=608, width=608),
                            dict(type='Resize', height=640, width=608),
                            dict(type='Resize', height=672, width=608),
                            dict(type='Resize', height=704, width=608),
                            dict(type='Resize', height=736, width=608),
                            dict(type='Resize', height=768, width=608),
                            dict(type='Resize', height=800, width=608),
                            dict(type='Resize', height=512, width=640),
                            dict(type='Resize', height=544, width=640),
                            dict(type='Resize', height=576, width=640),
                            dict(type='Resize', height=608, width=640),
                            dict(type='Resize', height=640, width=640),
                            dict(type='Resize', height=672, width=640),
                            dict(type='Resize', height=704, width=640),
                            dict(type='Resize', height=736, width=640),
                            dict(type='Resize', height=768, width=640),
                            dict(type='Resize', height=800, width=640),
                            dict(type='Resize', height=512, width=672),
                            dict(type='Resize', height=544, width=672),
                            dict(type='Resize', height=576, width=672),
                            dict(type='Resize', height=608, width=672),
                            dict(type='Resize', height=640, width=672),
                            dict(type='Resize', height=672, width=672),
                            dict(type='Resize', height=704, width=672),
                            dict(type='Resize', height=736, width=672),
                            dict(type='Resize', height=768, width=672),
                            dict(type='Resize', height=800, width=672),
                            dict(type='Resize', height=512, width=704),
                            dict(type='Resize', height=544, width=704),
                            dict(type='Resize', height=576, width=704),
                            dict(type='Resize', height=608, width=704),
                            dict(type='Resize', height=640, width=704),
                            dict(type='Resize', height=672, width=704),
                            dict(type='Resize', height=704, width=704),
                            dict(type='Resize', height=736, width=704),
                            dict(type='Resize', height=768, width=704),
                            dict(type='Resize', height=800, width=704),
                            dict(type='Resize', height=512, width=736),
                            dict(type='Resize', height=544, width=736),
                            dict(type='Resize', height=576, width=736),
                            dict(type='Resize', height=608, width=736),
                            dict(type='Resize', height=640, width=736),
                            dict(type='Resize', height=672, width=736),
                            dict(type='Resize', height=704, width=736),
                            dict(type='Resize', height=736, width=736),
                            dict(type='Resize', height=768, width=736),
                            dict(type='Resize', height=800, width=736),
                            dict(type='Resize', height=512, width=768),
                            dict(type='Resize', height=544, width=768),
                            dict(type='Resize', height=576, width=768),
                            dict(type='Resize', height=608, width=768),
                            dict(type='Resize', height=640, width=768),
                            dict(type='Resize', height=672, width=768),
                            dict(type='Resize', height=704, width=768),
                            dict(type='Resize', height=736, width=768),
                            dict(type='Resize', height=768, width=768),
                            dict(type='Resize', height=800, width=768),
                            dict(type='Resize', height=512, width=800),
                            dict(type='Resize', height=544, width=800),
                            dict(type='Resize', height=576, width=800),
                            dict(type='Resize', height=608, width=800),
                            dict(type='Resize', height=640, width=800),
                            dict(type='Resize', height=672, width=800),
                            dict(type='Resize', height=704, width=800),
                            dict(type='Resize', height=736, width=800),
                            dict(type='Resize', height=768, width=800),
                            dict(type='Resize', height=800, width=800)
                        ],
                        p=1.0),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='GaussNoise', p=1.0),
                            dict(type='GaussianBlur', p=1.0),
                            dict(type='Blur', p=1.0)
                        ],
                        p=0.1),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='CLAHE', p=1.0),
                            dict(type='RandomGamma', p=1.0),
                            dict(type='HueSaturationValue', p=1.0),
                            dict(type='ChannelDropout', p=1.0),
                            dict(type='ChannelShuffle', p=1.0),
                            dict(type='RGBShift', p=1.0)
                        ],
                        p=0.1),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='ShiftScaleRotate', p=1.0),
                            dict(type='Rotate', p=1.0)
                        ],
                        p=0.1)
                ],
                bbox_params=dict(
                    type='BboxParams',
                    format='pascal_voc',
                    label_fields=['gt_labels'],
                    min_visibility=0.0,
                    filter_lost_elements=True),
                keymap=dict(img='image', gt_bboxes='bboxes'),
                update_pad_shape=False,
                skip_img_without_anno=True),
            dict(type='CutOut', n_holes=4, cutout_shape=(30, 30)),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/val_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/val_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
lr = 0.0001
optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.1,
    min_lr_ratio=1e-06)
total_epochs = 50
expr_name = 'hrn_cascade_16_cutout_832ms'
dist_params = dict(backend='nccl')
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=10,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(
            type='WandbLoggerHook',
            init_kwargs=dict(
                project='P-stage2-detection',
                name='hrn_cascade_16_cutout_832ms'))
    ])
custom_hooks = [dict(type='NumClassCheckHook')]
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
runner = dict(type='EpochBasedRunner', max_epochs=50)
work_dir = './work_dirs/hrn_cascade_16_cutout_832ms'
gpu_ids = range(0, 1)
model = dict(
    type='CascadeRCNN',
    backbone=dict(
        type='HRNet',
        extra=dict(
            stage1=dict(
                num_modules=1,
                num_branches=1,
                block='BOTTLENECK',
                num_blocks=(4, ),
                num_channels=(64, )),
            stage2=dict(
                num_modules=1,
                num_branches=2,
                block='BASIC',
                num_blocks=(4, 4),
                num_channels=(18, 36)),
            stage3=dict(
                num_modules=4,
                num_branches=3,
                block='BASIC',
                num_blocks=(4, 4, 4),
                num_channels=(18, 36, 72)),
            stage4=dict(
                num_modules=3,
                num_branches=4,
                block='BASIC',
                num_blocks=(4, 4, 4, 4),
                num_channels=(18, 36, 72, 144))),
        init_cfg=dict(
            type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18')),
    neck=dict(
        type='HRFPN',
        in_channels=[18, 36, 72, 144],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='DIoULoss', loss_weight=2.5)),
    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=2.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=2.5)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=3.0))
        ]),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=30),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=30),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=71)))

/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/core/anchor/builder.py:17: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` 
  '``build_anchor_generator`` would be deprecated soon, please use '
2021-09-29 12:41:21,812 - mmdet - INFO - initialize HRNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://msra/hrnetv2_w18'}
2021-09-29 12:41:21,812 - mmcv - INFO - load model from: open-mmlab://msra/hrnetv2_w18
2021-09-29 12:41:21,813 - mmcv - INFO - Use load_from_openmmlab loader
2021-09-29 12:41:22,263 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: incre_modules.0.0.conv1.weight, incre_modules.0.0.bn1.weight, incre_modules.0.0.bn1.bias, incre_modules.0.0.bn1.running_mean, incre_modules.0.0.bn1.running_var, incre_modules.0.0.bn1.num_batches_tracked, incre_modules.0.0.conv2.weight, incre_modules.0.0.bn2.weight, incre_modules.0.0.bn2.bias, incre_modules.0.0.bn2.running_mean, incre_modules.0.0.bn2.running_var, incre_modules.0.0.bn2.num_batches_tracked, incre_modules.0.0.conv3.weight, incre_modules.0.0.bn3.weight, incre_modules.0.0.bn3.bias, incre_modules.0.0.bn3.running_mean, incre_modules.0.0.bn3.running_var, incre_modules.0.0.bn3.num_batches_tracked, incre_modules.0.0.downsample.0.weight, incre_modules.0.0.downsample.1.weight, incre_modules.0.0.downsample.1.bias, incre_modules.0.0.downsample.1.running_mean, incre_modules.0.0.downsample.1.running_var, incre_modules.0.0.downsample.1.num_batches_tracked, incre_modules.1.0.conv1.weight, incre_modules.1.0.bn1.weight, incre_modules.1.0.bn1.bias, incre_modules.1.0.bn1.running_mean, incre_modules.1.0.bn1.running_var, incre_modules.1.0.bn1.num_batches_tracked, incre_modules.1.0.conv2.weight, incre_modules.1.0.bn2.weight, incre_modules.1.0.bn2.bias, incre_modules.1.0.bn2.running_mean, incre_modules.1.0.bn2.running_var, incre_modules.1.0.bn2.num_batches_tracked, incre_modules.1.0.conv3.weight, incre_modules.1.0.bn3.weight, incre_modules.1.0.bn3.bias, incre_modules.1.0.bn3.running_mean, incre_modules.1.0.bn3.running_var, incre_modules.1.0.bn3.num_batches_tracked, incre_modules.1.0.downsample.0.weight, incre_modules.1.0.downsample.1.weight, incre_modules.1.0.downsample.1.bias, incre_modules.1.0.downsample.1.running_mean, incre_modules.1.0.downsample.1.running_var, incre_modules.1.0.downsample.1.num_batches_tracked, incre_modules.2.0.conv1.weight, incre_modules.2.0.bn1.weight, incre_modules.2.0.bn1.bias, incre_modules.2.0.bn1.running_mean, incre_modules.2.0.bn1.running_var, incre_modules.2.0.bn1.num_batches_tracked, incre_modules.2.0.conv2.weight, incre_modules.2.0.bn2.weight, incre_modules.2.0.bn2.bias, incre_modules.2.0.bn2.running_mean, incre_modules.2.0.bn2.running_var, incre_modules.2.0.bn2.num_batches_tracked, incre_modules.2.0.conv3.weight, incre_modules.2.0.bn3.weight, incre_modules.2.0.bn3.bias, incre_modules.2.0.bn3.running_mean, incre_modules.2.0.bn3.running_var, incre_modules.2.0.bn3.num_batches_tracked, incre_modules.2.0.downsample.0.weight, incre_modules.2.0.downsample.1.weight, incre_modules.2.0.downsample.1.bias, incre_modules.2.0.downsample.1.running_mean, incre_modules.2.0.downsample.1.running_var, incre_modules.2.0.downsample.1.num_batches_tracked, incre_modules.3.0.conv1.weight, incre_modules.3.0.bn1.weight, incre_modules.3.0.bn1.bias, incre_modules.3.0.bn1.running_mean, incre_modules.3.0.bn1.running_var, incre_modules.3.0.bn1.num_batches_tracked, incre_modules.3.0.conv2.weight, incre_modules.3.0.bn2.weight, incre_modules.3.0.bn2.bias, incre_modules.3.0.bn2.running_mean, incre_modules.3.0.bn2.running_var, incre_modules.3.0.bn2.num_batches_tracked, incre_modules.3.0.conv3.weight, incre_modules.3.0.bn3.weight, incre_modules.3.0.bn3.bias, incre_modules.3.0.bn3.running_mean, incre_modules.3.0.bn3.running_var, incre_modules.3.0.bn3.num_batches_tracked, incre_modules.3.0.downsample.0.weight, incre_modules.3.0.downsample.1.weight, incre_modules.3.0.downsample.1.bias, incre_modules.3.0.downsample.1.running_mean, incre_modules.3.0.downsample.1.running_var, incre_modules.3.0.downsample.1.num_batches_tracked, downsamp_modules.0.0.weight, downsamp_modules.0.0.bias, downsamp_modules.0.1.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.1.0.weight, downsamp_modules.1.0.bias, downsamp_modules.1.1.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.2.0.weight, downsamp_modules.2.0.bias, downsamp_modules.2.1.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.num_batches_tracked, final_layer.0.weight, final_layer.0.bias, final_layer.1.weight, final_layer.1.bias, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.num_batches_tracked, classifier.weight, classifier.bias

2021-09-29 12:41:22,386 - mmdet - INFO - initialize HRFPN with init_cfg {'type': 'Caffe2Xavier', 'layer': 'Conv2d'}
2021-09-29 12:41:22,410 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2021-09-29 12:41:22,418 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 12:41:22,736 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 12:41:23,058 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/datasets/api_wrappers/coco_api.py:22: UserWarning: mmpycocotools is deprecated. Please install official pycocotools by "pip install pycocotools"
  UserWarning)
/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/datasets/api_wrappers/coco_api.py:22: UserWarning: mmpycocotools is deprecated. Please install official pycocotools by "pip install pycocotools"
  UserWarning)
2021-09-29 12:41:27,078 - mmdet - INFO - Start running, host: root@965f40750ba2, work_dir: /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/work_dirs/hrn_cascade_16_cutout_832ms
2021-09-29 12:41:27,079 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_run:
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
2021-09-29 12:41:27,079 - mmdet - INFO - workflow: [('train', 1)], max: 50 epochs
wandb: Currently logged in as: ark10806 (use `wandb login --relogin` to force relogin)
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
loading annotations into memory...
Done (t=0.22s)
creating index...
index created!
wandb: Tracking run with wandb version 0.12.2
wandb: Syncing run hrn_cascade_16_cutout_832ms
wandb:  View project at https://wandb.ai/ark10806/P-stage2-detection
wandb:  View run at https://wandb.ai/ark10806/P-stage2-detection/runs/1jgpxhrp
wandb: Run data is saved locally in /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/wandb/run-20210929_124127-1jgpxhrp
wandb: Run `wandb offline` to turn off syncing.

/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` 
  warnings.warn('``grid_anchors`` would be deprecated soon. '
/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/core/anchor/anchor_generator.py:361: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` 
  '``single_level_grid_anchors`` would be deprecated soon. '
Traceback (most recent call last):
  File "tools/train.py", line 189, in <module>
    main()
  File "tools/train.py", line 185, in main
    meta=meta)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/apis/train.py", line 174, in train_detector
    runner.run(data_loaders, cfg.workflow)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 50, in train
    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py", line 30, in run_iter
    **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/parallel/data_parallel.py", line 67, in train_step
    return self.module.train_step(*inputs[0], **kwargs[0])
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 238, in train_step
    losses = self(**data)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
    return old_func(*args, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/detectors/base.py", line 172, in forward
    return self.forward_train(img, img_metas, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/detectors/two_stage.py", line 141, in forward_train
    proposal_cfg=proposal_cfg)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/dense_heads/base_dense_head.py", line 59, in forward_train
    proposal_list = self.get_bboxes(*outs, img_metas, cfg=proposal_cfg)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 186, in new_func
    return old_func(*args, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/dense_heads/rpn_head.py", line 131, in get_bboxes
    scale_factor, cfg, rescale)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/models/dense_heads/rpn_head.py", line 221, in _get_bboxes_single
    dets, keep = batched_nms(proposals, scores, ids, cfg.nms)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/ops/nms.py", line 307, in batched_nms
    dets, keep = nms_op(boxes_for_nms, scores, **nms_cfg_)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/utils/misc.py", line 330, in new_func
    output = old_func(*args, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/ops/nms.py", line 172, in nms
    score_threshold, max_num)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/ops/nms.py", line 27, in forward
    bboxes, scores, iou_threshold=float(iou_threshold), offset=offset)
RuntimeError: nms is not compiled with GPU support
Exception raised from nms at /tmp/mmcv/mmcv/ops/csrc/pytorch/nms.cpp:71 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f3bd4b278b2 in /opt/conda/envs/detection/lib/python3.7/site-packages/torch/lib/libc10.so)
frame #1: nms(at::Tensor, at::Tensor, float, int) + 0x754 (0x7f3b9cce69b4 in /opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/_ext.cpython-37m-x86_64-linux-gnu.so)
frame #2: <unknown function> + 0x82184 (0x7f3b9cd25184 in /opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/_ext.cpython-37m-x86_64-linux-gnu.so)
frame #3: <unknown function> + 0x74f4f (0x7f3b9cd17f4f in /opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/_ext.cpython-37m-x86_64-linux-gnu.so)
<omitting python frames>
frame #8: THPFunction_apply(_object*, _object*) + 0x93d (0x7f3c53ddc00d in /opt/conda/envs/detection/lib/python3.7/site-packages/torch/lib/libtorch_python.so)

wandb: Waiting for W&B process to finish, PID 27805
wandb: Program failed with code 1.  Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/wandb/run-20210929_124127-1jgpxhrp/logs/debug.log
wandb: Find internal logs for this run at: /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/wandb/run-20210929_124127-1jgpxhrp/logs/debug-internal.log
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced hrn_cascade_16_cutout_832ms: https://wandb.ai/ark10806/P-stage2-detection/runs/1jgpxhrp

Traceback (most recent call last):
  File "tools/train.py", line 9, in <module>
    import mmcv
ModuleNotFoundError: No module named 'mmcv'
2021-09-29 12:50:40,104 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.0a0
OpenCV: 4.5.3
MMCV: 1.3.14
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMDetection: 2.16.0+597a4a0
------------------------------------------------------------

2021-09-29 12:50:44,908 - mmdet - INFO - Distributed training: False
2021-09-29 12:50:49,874 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '/opt/ml/detection/dataset/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
imsize = 800
multi_scale_dict = [
    dict(type='Resize', height=512, width=512),
    dict(type='Resize', height=544, width=512),
    dict(type='Resize', height=576, width=512),
    dict(type='Resize', height=608, width=512),
    dict(type='Resize', height=640, width=512),
    dict(type='Resize', height=672, width=512),
    dict(type='Resize', height=704, width=512),
    dict(type='Resize', height=736, width=512),
    dict(type='Resize', height=768, width=512),
    dict(type='Resize', height=800, width=512),
    dict(type='Resize', height=512, width=544),
    dict(type='Resize', height=544, width=544),
    dict(type='Resize', height=576, width=544),
    dict(type='Resize', height=608, width=544),
    dict(type='Resize', height=640, width=544),
    dict(type='Resize', height=672, width=544),
    dict(type='Resize', height=704, width=544),
    dict(type='Resize', height=736, width=544),
    dict(type='Resize', height=768, width=544),
    dict(type='Resize', height=800, width=544),
    dict(type='Resize', height=512, width=576),
    dict(type='Resize', height=544, width=576),
    dict(type='Resize', height=576, width=576),
    dict(type='Resize', height=608, width=576),
    dict(type='Resize', height=640, width=576),
    dict(type='Resize', height=672, width=576),
    dict(type='Resize', height=704, width=576),
    dict(type='Resize', height=736, width=576),
    dict(type='Resize', height=768, width=576),
    dict(type='Resize', height=800, width=576),
    dict(type='Resize', height=512, width=608),
    dict(type='Resize', height=544, width=608),
    dict(type='Resize', height=576, width=608),
    dict(type='Resize', height=608, width=608),
    dict(type='Resize', height=640, width=608),
    dict(type='Resize', height=672, width=608),
    dict(type='Resize', height=704, width=608),
    dict(type='Resize', height=736, width=608),
    dict(type='Resize', height=768, width=608),
    dict(type='Resize', height=800, width=608),
    dict(type='Resize', height=512, width=640),
    dict(type='Resize', height=544, width=640),
    dict(type='Resize', height=576, width=640),
    dict(type='Resize', height=608, width=640),
    dict(type='Resize', height=640, width=640),
    dict(type='Resize', height=672, width=640),
    dict(type='Resize', height=704, width=640),
    dict(type='Resize', height=736, width=640),
    dict(type='Resize', height=768, width=640),
    dict(type='Resize', height=800, width=640),
    dict(type='Resize', height=512, width=672),
    dict(type='Resize', height=544, width=672),
    dict(type='Resize', height=576, width=672),
    dict(type='Resize', height=608, width=672),
    dict(type='Resize', height=640, width=672),
    dict(type='Resize', height=672, width=672),
    dict(type='Resize', height=704, width=672),
    dict(type='Resize', height=736, width=672),
    dict(type='Resize', height=768, width=672),
    dict(type='Resize', height=800, width=672),
    dict(type='Resize', height=512, width=704),
    dict(type='Resize', height=544, width=704),
    dict(type='Resize', height=576, width=704),
    dict(type='Resize', height=608, width=704),
    dict(type='Resize', height=640, width=704),
    dict(type='Resize', height=672, width=704),
    dict(type='Resize', height=704, width=704),
    dict(type='Resize', height=736, width=704),
    dict(type='Resize', height=768, width=704),
    dict(type='Resize', height=800, width=704),
    dict(type='Resize', height=512, width=736),
    dict(type='Resize', height=544, width=736),
    dict(type='Resize', height=576, width=736),
    dict(type='Resize', height=608, width=736),
    dict(type='Resize', height=640, width=736),
    dict(type='Resize', height=672, width=736),
    dict(type='Resize', height=704, width=736),
    dict(type='Resize', height=736, width=736),
    dict(type='Resize', height=768, width=736),
    dict(type='Resize', height=800, width=736),
    dict(type='Resize', height=512, width=768),
    dict(type='Resize', height=544, width=768),
    dict(type='Resize', height=576, width=768),
    dict(type='Resize', height=608, width=768),
    dict(type='Resize', height=640, width=768),
    dict(type='Resize', height=672, width=768),
    dict(type='Resize', height=704, width=768),
    dict(type='Resize', height=736, width=768),
    dict(type='Resize', height=768, width=768),
    dict(type='Resize', height=800, width=768),
    dict(type='Resize', height=512, width=800),
    dict(type='Resize', height=544, width=800),
    dict(type='Resize', height=576, width=800),
    dict(type='Resize', height=608, width=800),
    dict(type='Resize', height=640, width=800),
    dict(type='Resize', height=672, width=800),
    dict(type='Resize', height=704, width=800),
    dict(type='Resize', height=736, width=800),
    dict(type='Resize', height=768, width=800),
    dict(type='Resize', height=800, width=800)
]
i = 800
w = 800
h = 800
alb_transform = [
    dict(
        type='OneOf',
        transforms=[
            dict(type='Resize', height=512, width=512),
            dict(type='Resize', height=544, width=512),
            dict(type='Resize', height=576, width=512),
            dict(type='Resize', height=608, width=512),
            dict(type='Resize', height=640, width=512),
            dict(type='Resize', height=672, width=512),
            dict(type='Resize', height=704, width=512),
            dict(type='Resize', height=736, width=512),
            dict(type='Resize', height=768, width=512),
            dict(type='Resize', height=800, width=512),
            dict(type='Resize', height=512, width=544),
            dict(type='Resize', height=544, width=544),
            dict(type='Resize', height=576, width=544),
            dict(type='Resize', height=608, width=544),
            dict(type='Resize', height=640, width=544),
            dict(type='Resize', height=672, width=544),
            dict(type='Resize', height=704, width=544),
            dict(type='Resize', height=736, width=544),
            dict(type='Resize', height=768, width=544),
            dict(type='Resize', height=800, width=544),
            dict(type='Resize', height=512, width=576),
            dict(type='Resize', height=544, width=576),
            dict(type='Resize', height=576, width=576),
            dict(type='Resize', height=608, width=576),
            dict(type='Resize', height=640, width=576),
            dict(type='Resize', height=672, width=576),
            dict(type='Resize', height=704, width=576),
            dict(type='Resize', height=736, width=576),
            dict(type='Resize', height=768, width=576),
            dict(type='Resize', height=800, width=576),
            dict(type='Resize', height=512, width=608),
            dict(type='Resize', height=544, width=608),
            dict(type='Resize', height=576, width=608),
            dict(type='Resize', height=608, width=608),
            dict(type='Resize', height=640, width=608),
            dict(type='Resize', height=672, width=608),
            dict(type='Resize', height=704, width=608),
            dict(type='Resize', height=736, width=608),
            dict(type='Resize', height=768, width=608),
            dict(type='Resize', height=800, width=608),
            dict(type='Resize', height=512, width=640),
            dict(type='Resize', height=544, width=640),
            dict(type='Resize', height=576, width=640),
            dict(type='Resize', height=608, width=640),
            dict(type='Resize', height=640, width=640),
            dict(type='Resize', height=672, width=640),
            dict(type='Resize', height=704, width=640),
            dict(type='Resize', height=736, width=640),
            dict(type='Resize', height=768, width=640),
            dict(type='Resize', height=800, width=640),
            dict(type='Resize', height=512, width=672),
            dict(type='Resize', height=544, width=672),
            dict(type='Resize', height=576, width=672),
            dict(type='Resize', height=608, width=672),
            dict(type='Resize', height=640, width=672),
            dict(type='Resize', height=672, width=672),
            dict(type='Resize', height=704, width=672),
            dict(type='Resize', height=736, width=672),
            dict(type='Resize', height=768, width=672),
            dict(type='Resize', height=800, width=672),
            dict(type='Resize', height=512, width=704),
            dict(type='Resize', height=544, width=704),
            dict(type='Resize', height=576, width=704),
            dict(type='Resize', height=608, width=704),
            dict(type='Resize', height=640, width=704),
            dict(type='Resize', height=672, width=704),
            dict(type='Resize', height=704, width=704),
            dict(type='Resize', height=736, width=704),
            dict(type='Resize', height=768, width=704),
            dict(type='Resize', height=800, width=704),
            dict(type='Resize', height=512, width=736),
            dict(type='Resize', height=544, width=736),
            dict(type='Resize', height=576, width=736),
            dict(type='Resize', height=608, width=736),
            dict(type='Resize', height=640, width=736),
            dict(type='Resize', height=672, width=736),
            dict(type='Resize', height=704, width=736),
            dict(type='Resize', height=736, width=736),
            dict(type='Resize', height=768, width=736),
            dict(type='Resize', height=800, width=736),
            dict(type='Resize', height=512, width=768),
            dict(type='Resize', height=544, width=768),
            dict(type='Resize', height=576, width=768),
            dict(type='Resize', height=608, width=768),
            dict(type='Resize', height=640, width=768),
            dict(type='Resize', height=672, width=768),
            dict(type='Resize', height=704, width=768),
            dict(type='Resize', height=736, width=768),
            dict(type='Resize', height=768, width=768),
            dict(type='Resize', height=800, width=768),
            dict(type='Resize', height=512, width=800),
            dict(type='Resize', height=544, width=800),
            dict(type='Resize', height=576, width=800),
            dict(type='Resize', height=608, width=800),
            dict(type='Resize', height=640, width=800),
            dict(type='Resize', height=672, width=800),
            dict(type='Resize', height=704, width=800),
            dict(type='Resize', height=736, width=800),
            dict(type='Resize', height=768, width=800),
            dict(type='Resize', height=800, width=800)
        ],
        p=1.0),
    dict(
        type='OneOf',
        transforms=[
            dict(type='GaussNoise', p=1.0),
            dict(type='GaussianBlur', p=1.0),
            dict(type='Blur', p=1.0)
        ],
        p=0.1),
    dict(
        type='OneOf',
        transforms=[
            dict(type='CLAHE', p=1.0),
            dict(type='RandomGamma', p=1.0),
            dict(type='HueSaturationValue', p=1.0),
            dict(type='ChannelDropout', p=1.0),
            dict(type='ChannelShuffle', p=1.0),
            dict(type='RGBShift', p=1.0)
        ],
        p=0.1),
    dict(
        type='OneOf',
        transforms=[
            dict(type='ShiftScaleRotate', p=1.0),
            dict(type='Rotate', p=1.0)
        ],
        p=0.1)
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(800, 800)),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Resize', height=512, width=512),
                    dict(type='Resize', height=544, width=512),
                    dict(type='Resize', height=576, width=512),
                    dict(type='Resize', height=608, width=512),
                    dict(type='Resize', height=640, width=512),
                    dict(type='Resize', height=672, width=512),
                    dict(type='Resize', height=704, width=512),
                    dict(type='Resize', height=736, width=512),
                    dict(type='Resize', height=768, width=512),
                    dict(type='Resize', height=800, width=512),
                    dict(type='Resize', height=512, width=544),
                    dict(type='Resize', height=544, width=544),
                    dict(type='Resize', height=576, width=544),
                    dict(type='Resize', height=608, width=544),
                    dict(type='Resize', height=640, width=544),
                    dict(type='Resize', height=672, width=544),
                    dict(type='Resize', height=704, width=544),
                    dict(type='Resize', height=736, width=544),
                    dict(type='Resize', height=768, width=544),
                    dict(type='Resize', height=800, width=544),
                    dict(type='Resize', height=512, width=576),
                    dict(type='Resize', height=544, width=576),
                    dict(type='Resize', height=576, width=576),
                    dict(type='Resize', height=608, width=576),
                    dict(type='Resize', height=640, width=576),
                    dict(type='Resize', height=672, width=576),
                    dict(type='Resize', height=704, width=576),
                    dict(type='Resize', height=736, width=576),
                    dict(type='Resize', height=768, width=576),
                    dict(type='Resize', height=800, width=576),
                    dict(type='Resize', height=512, width=608),
                    dict(type='Resize', height=544, width=608),
                    dict(type='Resize', height=576, width=608),
                    dict(type='Resize', height=608, width=608),
                    dict(type='Resize', height=640, width=608),
                    dict(type='Resize', height=672, width=608),
                    dict(type='Resize', height=704, width=608),
                    dict(type='Resize', height=736, width=608),
                    dict(type='Resize', height=768, width=608),
                    dict(type='Resize', height=800, width=608),
                    dict(type='Resize', height=512, width=640),
                    dict(type='Resize', height=544, width=640),
                    dict(type='Resize', height=576, width=640),
                    dict(type='Resize', height=608, width=640),
                    dict(type='Resize', height=640, width=640),
                    dict(type='Resize', height=672, width=640),
                    dict(type='Resize', height=704, width=640),
                    dict(type='Resize', height=736, width=640),
                    dict(type='Resize', height=768, width=640),
                    dict(type='Resize', height=800, width=640),
                    dict(type='Resize', height=512, width=672),
                    dict(type='Resize', height=544, width=672),
                    dict(type='Resize', height=576, width=672),
                    dict(type='Resize', height=608, width=672),
                    dict(type='Resize', height=640, width=672),
                    dict(type='Resize', height=672, width=672),
                    dict(type='Resize', height=704, width=672),
                    dict(type='Resize', height=736, width=672),
                    dict(type='Resize', height=768, width=672),
                    dict(type='Resize', height=800, width=672),
                    dict(type='Resize', height=512, width=704),
                    dict(type='Resize', height=544, width=704),
                    dict(type='Resize', height=576, width=704),
                    dict(type='Resize', height=608, width=704),
                    dict(type='Resize', height=640, width=704),
                    dict(type='Resize', height=672, width=704),
                    dict(type='Resize', height=704, width=704),
                    dict(type='Resize', height=736, width=704),
                    dict(type='Resize', height=768, width=704),
                    dict(type='Resize', height=800, width=704),
                    dict(type='Resize', height=512, width=736),
                    dict(type='Resize', height=544, width=736),
                    dict(type='Resize', height=576, width=736),
                    dict(type='Resize', height=608, width=736),
                    dict(type='Resize', height=640, width=736),
                    dict(type='Resize', height=672, width=736),
                    dict(type='Resize', height=704, width=736),
                    dict(type='Resize', height=736, width=736),
                    dict(type='Resize', height=768, width=736),
                    dict(type='Resize', height=800, width=736),
                    dict(type='Resize', height=512, width=768),
                    dict(type='Resize', height=544, width=768),
                    dict(type='Resize', height=576, width=768),
                    dict(type='Resize', height=608, width=768),
                    dict(type='Resize', height=640, width=768),
                    dict(type='Resize', height=672, width=768),
                    dict(type='Resize', height=704, width=768),
                    dict(type='Resize', height=736, width=768),
                    dict(type='Resize', height=768, width=768),
                    dict(type='Resize', height=800, width=768),
                    dict(type='Resize', height=512, width=800),
                    dict(type='Resize', height=544, width=800),
                    dict(type='Resize', height=576, width=800),
                    dict(type='Resize', height=608, width=800),
                    dict(type='Resize', height=640, width=800),
                    dict(type='Resize', height=672, width=800),
                    dict(type='Resize', height=704, width=800),
                    dict(type='Resize', height=736, width=800),
                    dict(type='Resize', height=768, width=800),
                    dict(type='Resize', height=800, width=800)
                ],
                p=1.0),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='GaussNoise', p=1.0),
                    dict(type='GaussianBlur', p=1.0),
                    dict(type='Blur', p=1.0)
                ],
                p=0.1),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='CLAHE', p=1.0),
                    dict(type='RandomGamma', p=1.0),
                    dict(type='HueSaturationValue', p=1.0),
                    dict(type='ChannelDropout', p=1.0),
                    dict(type='ChannelShuffle', p=1.0),
                    dict(type='RGBShift', p=1.0)
                ],
                p=0.1),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='ShiftScaleRotate', p=1.0),
                    dict(type='Rotate', p=1.0)
                ],
                p=0.1)
        ],
        bbox_params=dict(
            type='BboxParams',
            format='pascal_voc',
            label_fields=['gt_labels'],
            min_visibility=0.0,
            filter_lost_elements=True),
        keymap=dict(img='image', gt_bboxes='bboxes'),
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(type='CutOut', n_holes=4, cutout_shape=(30, 30)),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',
           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/train_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(800, 800)),
            dict(
                type='Albu',
                transforms=[
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Resize', height=512, width=512),
                            dict(type='Resize', height=544, width=512),
                            dict(type='Resize', height=576, width=512),
                            dict(type='Resize', height=608, width=512),
                            dict(type='Resize', height=640, width=512),
                            dict(type='Resize', height=672, width=512),
                            dict(type='Resize', height=704, width=512),
                            dict(type='Resize', height=736, width=512),
                            dict(type='Resize', height=768, width=512),
                            dict(type='Resize', height=800, width=512),
                            dict(type='Resize', height=512, width=544),
                            dict(type='Resize', height=544, width=544),
                            dict(type='Resize', height=576, width=544),
                            dict(type='Resize', height=608, width=544),
                            dict(type='Resize', height=640, width=544),
                            dict(type='Resize', height=672, width=544),
                            dict(type='Resize', height=704, width=544),
                            dict(type='Resize', height=736, width=544),
                            dict(type='Resize', height=768, width=544),
                            dict(type='Resize', height=800, width=544),
                            dict(type='Resize', height=512, width=576),
                            dict(type='Resize', height=544, width=576),
                            dict(type='Resize', height=576, width=576),
                            dict(type='Resize', height=608, width=576),
                            dict(type='Resize', height=640, width=576),
                            dict(type='Resize', height=672, width=576),
                            dict(type='Resize', height=704, width=576),
                            dict(type='Resize', height=736, width=576),
                            dict(type='Resize', height=768, width=576),
                            dict(type='Resize', height=800, width=576),
                            dict(type='Resize', height=512, width=608),
                            dict(type='Resize', height=544, width=608),
                            dict(type='Resize', height=576, width=608),
                            dict(type='Resize', height=608, width=608),
                            dict(type='Resize', height=640, width=608),
                            dict(type='Resize', height=672, width=608),
                            dict(type='Resize', height=704, width=608),
                            dict(type='Resize', height=736, width=608),
                            dict(type='Resize', height=768, width=608),
                            dict(type='Resize', height=800, width=608),
                            dict(type='Resize', height=512, width=640),
                            dict(type='Resize', height=544, width=640),
                            dict(type='Resize', height=576, width=640),
                            dict(type='Resize', height=608, width=640),
                            dict(type='Resize', height=640, width=640),
                            dict(type='Resize', height=672, width=640),
                            dict(type='Resize', height=704, width=640),
                            dict(type='Resize', height=736, width=640),
                            dict(type='Resize', height=768, width=640),
                            dict(type='Resize', height=800, width=640),
                            dict(type='Resize', height=512, width=672),
                            dict(type='Resize', height=544, width=672),
                            dict(type='Resize', height=576, width=672),
                            dict(type='Resize', height=608, width=672),
                            dict(type='Resize', height=640, width=672),
                            dict(type='Resize', height=672, width=672),
                            dict(type='Resize', height=704, width=672),
                            dict(type='Resize', height=736, width=672),
                            dict(type='Resize', height=768, width=672),
                            dict(type='Resize', height=800, width=672),
                            dict(type='Resize', height=512, width=704),
                            dict(type='Resize', height=544, width=704),
                            dict(type='Resize', height=576, width=704),
                            dict(type='Resize', height=608, width=704),
                            dict(type='Resize', height=640, width=704),
                            dict(type='Resize', height=672, width=704),
                            dict(type='Resize', height=704, width=704),
                            dict(type='Resize', height=736, width=704),
                            dict(type='Resize', height=768, width=704),
                            dict(type='Resize', height=800, width=704),
                            dict(type='Resize', height=512, width=736),
                            dict(type='Resize', height=544, width=736),
                            dict(type='Resize', height=576, width=736),
                            dict(type='Resize', height=608, width=736),
                            dict(type='Resize', height=640, width=736),
                            dict(type='Resize', height=672, width=736),
                            dict(type='Resize', height=704, width=736),
                            dict(type='Resize', height=736, width=736),
                            dict(type='Resize', height=768, width=736),
                            dict(type='Resize', height=800, width=736),
                            dict(type='Resize', height=512, width=768),
                            dict(type='Resize', height=544, width=768),
                            dict(type='Resize', height=576, width=768),
                            dict(type='Resize', height=608, width=768),
                            dict(type='Resize', height=640, width=768),
                            dict(type='Resize', height=672, width=768),
                            dict(type='Resize', height=704, width=768),
                            dict(type='Resize', height=736, width=768),
                            dict(type='Resize', height=768, width=768),
                            dict(type='Resize', height=800, width=768),
                            dict(type='Resize', height=512, width=800),
                            dict(type='Resize', height=544, width=800),
                            dict(type='Resize', height=576, width=800),
                            dict(type='Resize', height=608, width=800),
                            dict(type='Resize', height=640, width=800),
                            dict(type='Resize', height=672, width=800),
                            dict(type='Resize', height=704, width=800),
                            dict(type='Resize', height=736, width=800),
                            dict(type='Resize', height=768, width=800),
                            dict(type='Resize', height=800, width=800)
                        ],
                        p=1.0),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='GaussNoise', p=1.0),
                            dict(type='GaussianBlur', p=1.0),
                            dict(type='Blur', p=1.0)
                        ],
                        p=0.1),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='CLAHE', p=1.0),
                            dict(type='RandomGamma', p=1.0),
                            dict(type='HueSaturationValue', p=1.0),
                            dict(type='ChannelDropout', p=1.0),
                            dict(type='ChannelShuffle', p=1.0),
                            dict(type='RGBShift', p=1.0)
                        ],
                        p=0.1),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='ShiftScaleRotate', p=1.0),
                            dict(type='Rotate', p=1.0)
                        ],
                        p=0.1)
                ],
                bbox_params=dict(
                    type='BboxParams',
                    format='pascal_voc',
                    label_fields=['gt_labels'],
                    min_visibility=0.0,
                    filter_lost_elements=True),
                keymap=dict(img='image', gt_bboxes='bboxes'),
                update_pad_shape=False,
                skip_img_without_anno=True),
            dict(type='CutOut', n_holes=4, cutout_shape=(30, 30)),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/val_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/val_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
lr = 0.0001
optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.1,
    min_lr_ratio=1e-06)
total_epochs = 50
expr_name = 'hrn_cascade_16_cutout_832ms'
dist_params = dict(backend='nccl')
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=10,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(
            type='WandbLoggerHook',
            init_kwargs=dict(
                project='P-stage2-detection',
                name='hrn_cascade_16_cutout_832ms'))
    ])
custom_hooks = [dict(type='NumClassCheckHook')]
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
runner = dict(type='EpochBasedRunner', max_epochs=50)
work_dir = './work_dirs/hrn_cascade_16_cutout_832ms'
gpu_ids = range(0, 1)
model = dict(
    type='CascadeRCNN',
    backbone=dict(
        type='HRNet',
        extra=dict(
            stage1=dict(
                num_modules=1,
                num_branches=1,
                block='BOTTLENECK',
                num_blocks=(4, ),
                num_channels=(64, )),
            stage2=dict(
                num_modules=1,
                num_branches=2,
                block='BASIC',
                num_blocks=(4, 4),
                num_channels=(18, 36)),
            stage3=dict(
                num_modules=4,
                num_branches=3,
                block='BASIC',
                num_blocks=(4, 4, 4),
                num_channels=(18, 36, 72)),
            stage4=dict(
                num_modules=3,
                num_branches=4,
                block='BASIC',
                num_blocks=(4, 4, 4, 4),
                num_channels=(18, 36, 72, 144))),
        init_cfg=dict(
            type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18')),
    neck=dict(
        type='HRFPN',
        in_channels=[18, 36, 72, 144],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='DIoULoss', loss_weight=2.5)),
    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=2.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=2.5)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=3.0))
        ]),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=30),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=30),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=71)))

/opt/conda/envs/psc/lib/python3.8/site-packages/mmdet/core/anchor/builder.py:16: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` 
  warnings.warn(
2021-09-29 12:50:50,570 - mmdet - INFO - initialize HRNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://msra/hrnetv2_w18'}
2021-09-29 12:50:50,570 - mmcv - INFO - load model from: open-mmlab://msra/hrnetv2_w18
2021-09-29 12:50:50,571 - mmcv - INFO - Use load_from_openmmlab loader
2021-09-29 12:50:50,993 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: incre_modules.0.0.conv1.weight, incre_modules.0.0.bn1.weight, incre_modules.0.0.bn1.bias, incre_modules.0.0.bn1.running_mean, incre_modules.0.0.bn1.running_var, incre_modules.0.0.bn1.num_batches_tracked, incre_modules.0.0.conv2.weight, incre_modules.0.0.bn2.weight, incre_modules.0.0.bn2.bias, incre_modules.0.0.bn2.running_mean, incre_modules.0.0.bn2.running_var, incre_modules.0.0.bn2.num_batches_tracked, incre_modules.0.0.conv3.weight, incre_modules.0.0.bn3.weight, incre_modules.0.0.bn3.bias, incre_modules.0.0.bn3.running_mean, incre_modules.0.0.bn3.running_var, incre_modules.0.0.bn3.num_batches_tracked, incre_modules.0.0.downsample.0.weight, incre_modules.0.0.downsample.1.weight, incre_modules.0.0.downsample.1.bias, incre_modules.0.0.downsample.1.running_mean, incre_modules.0.0.downsample.1.running_var, incre_modules.0.0.downsample.1.num_batches_tracked, incre_modules.1.0.conv1.weight, incre_modules.1.0.bn1.weight, incre_modules.1.0.bn1.bias, incre_modules.1.0.bn1.running_mean, incre_modules.1.0.bn1.running_var, incre_modules.1.0.bn1.num_batches_tracked, incre_modules.1.0.conv2.weight, incre_modules.1.0.bn2.weight, incre_modules.1.0.bn2.bias, incre_modules.1.0.bn2.running_mean, incre_modules.1.0.bn2.running_var, incre_modules.1.0.bn2.num_batches_tracked, incre_modules.1.0.conv3.weight, incre_modules.1.0.bn3.weight, incre_modules.1.0.bn3.bias, incre_modules.1.0.bn3.running_mean, incre_modules.1.0.bn3.running_var, incre_modules.1.0.bn3.num_batches_tracked, incre_modules.1.0.downsample.0.weight, incre_modules.1.0.downsample.1.weight, incre_modules.1.0.downsample.1.bias, incre_modules.1.0.downsample.1.running_mean, incre_modules.1.0.downsample.1.running_var, incre_modules.1.0.downsample.1.num_batches_tracked, incre_modules.2.0.conv1.weight, incre_modules.2.0.bn1.weight, incre_modules.2.0.bn1.bias, incre_modules.2.0.bn1.running_mean, incre_modules.2.0.bn1.running_var, incre_modules.2.0.bn1.num_batches_tracked, incre_modules.2.0.conv2.weight, incre_modules.2.0.bn2.weight, incre_modules.2.0.bn2.bias, incre_modules.2.0.bn2.running_mean, incre_modules.2.0.bn2.running_var, incre_modules.2.0.bn2.num_batches_tracked, incre_modules.2.0.conv3.weight, incre_modules.2.0.bn3.weight, incre_modules.2.0.bn3.bias, incre_modules.2.0.bn3.running_mean, incre_modules.2.0.bn3.running_var, incre_modules.2.0.bn3.num_batches_tracked, incre_modules.2.0.downsample.0.weight, incre_modules.2.0.downsample.1.weight, incre_modules.2.0.downsample.1.bias, incre_modules.2.0.downsample.1.running_mean, incre_modules.2.0.downsample.1.running_var, incre_modules.2.0.downsample.1.num_batches_tracked, incre_modules.3.0.conv1.weight, incre_modules.3.0.bn1.weight, incre_modules.3.0.bn1.bias, incre_modules.3.0.bn1.running_mean, incre_modules.3.0.bn1.running_var, incre_modules.3.0.bn1.num_batches_tracked, incre_modules.3.0.conv2.weight, incre_modules.3.0.bn2.weight, incre_modules.3.0.bn2.bias, incre_modules.3.0.bn2.running_mean, incre_modules.3.0.bn2.running_var, incre_modules.3.0.bn2.num_batches_tracked, incre_modules.3.0.conv3.weight, incre_modules.3.0.bn3.weight, incre_modules.3.0.bn3.bias, incre_modules.3.0.bn3.running_mean, incre_modules.3.0.bn3.running_var, incre_modules.3.0.bn3.num_batches_tracked, incre_modules.3.0.downsample.0.weight, incre_modules.3.0.downsample.1.weight, incre_modules.3.0.downsample.1.bias, incre_modules.3.0.downsample.1.running_mean, incre_modules.3.0.downsample.1.running_var, incre_modules.3.0.downsample.1.num_batches_tracked, downsamp_modules.0.0.weight, downsamp_modules.0.0.bias, downsamp_modules.0.1.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.1.0.weight, downsamp_modules.1.0.bias, downsamp_modules.1.1.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.2.0.weight, downsamp_modules.2.0.bias, downsamp_modules.2.1.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.num_batches_tracked, final_layer.0.weight, final_layer.0.bias, final_layer.1.weight, final_layer.1.bias, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.num_batches_tracked, classifier.weight, classifier.bias

2021-09-29 12:50:51,135 - mmdet - INFO - initialize HRFPN with init_cfg {'type': 'Caffe2Xavier', 'layer': 'Conv2d'}
2021-09-29 12:50:51,159 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2021-09-29 12:50:51,167 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 12:50:51,483 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 12:50:51,801 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 12:50:55,742 - mmdet - INFO - Start running, host: root@965f40750ba2, work_dir: /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/work_dirs/hrn_cascade_16_cutout_832ms
2021-09-29 12:50:55,742 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_run:
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
2021-09-29 12:50:55,742 - mmdet - INFO - workflow: [('train', 1)], max: 50 epochs
wandb: Currently logged in as: ark10806 (use `wandb login --relogin` to force relogin)
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
wandb: Tracking run with wandb version 0.12.2
wandb: Syncing run hrn_cascade_16_cutout_832ms
wandb:  View project at https://wandb.ai/ark10806/P-stage2-detection
wandb:  View run at https://wandb.ai/ark10806/P-stage2-detection/runs/1mywdl9c
wandb: Run data is saved locally in /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/wandb/run-20210929_125056-1mywdl9c
wandb: Run `wandb offline` to turn off syncing.

/opt/conda/envs/psc/lib/python3.8/site-packages/torch/nn/functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn("Default upsampling behavior when mode={} is changed "
/opt/conda/envs/psc/lib/python3.8/site-packages/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` 
  warnings.warn('``grid_anchors`` would be deprecated soon. '
/opt/conda/envs/psc/lib/python3.8/site-packages/mmdet/core/anchor/anchor_generator.py:360: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` 
  warnings.warn(
2021-09-29 12:51:32,570 - mmdet - INFO - Epoch [1][10/245]	lr: 1.162e-05, eta: 10:20:59, time: 3.044, data_time: 0.313, memory: 29438, loss_rpn_cls: 0.6954, loss_rpn_bbox: 78.7130, s0.loss_cls: 1.9072, s0.acc: 46.9434, s0.loss_bbox: 4661.2976, s1.loss_cls: 0.7255, s1.acc: 49.2419, s1.loss_bbox: 284.7222, s2.loss_cls: 0.9778, s2.acc: 0.2856, s2.loss_bbox: 114.7983, loss: 5143.8369, grad_norm: 1396656.4693
2021-09-29 12:51:59,826 - mmdet - INFO - Epoch [1][20/245]	lr: 1.342e-05, eta: 9:48:01, time: 2.726, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.6923, loss_rpn_bbox: 28.5828, s0.loss_cls: 1.8234, s0.acc: 48.7793, s0.loss_bbox: 115.4783, s1.loss_cls: 0.4440, s1.acc: 64.9109, s1.loss_bbox: 455.8542, s2.loss_cls: 0.9691, s2.acc: 0.2490, s2.loss_bbox: 0.0198, loss: 603.8640, grad_norm: 67710.7613
2021-09-29 12:52:27,264 - mmdet - INFO - Epoch [1][30/245]	lr: 1.522e-05, eta: 9:37:58, time: 2.744, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.6836, loss_rpn_bbox: 8.3113, s0.loss_cls: 0.7120, s0.acc: 79.3628, s0.loss_bbox: 0.0970, s1.loss_cls: 0.1959, s1.acc: 91.2244, s1.loss_bbox: 0.0197, s2.loss_cls: 0.2680, s2.acc: 67.1643, s2.loss_bbox: 0.0128, loss: 10.3003, grad_norm: 948.8018
2021-09-29 12:52:54,197 - mmdet - INFO - Epoch [1][40/245]	lr: 1.702e-05, eta: 9:30:08, time: 2.693, data_time: 0.025, memory: 29438, loss_rpn_cls: 0.6384, loss_rpn_bbox: 6.4943, s0.loss_cls: 0.3288, s0.acc: 95.2563, s0.loss_bbox: 0.1081, s1.loss_cls: 0.0546, s1.acc: 98.6597, s1.loss_bbox: 0.0187, s2.loss_cls: 0.0310, s2.acc: 98.9612, s2.loss_bbox: 0.0098, loss: 7.6837, grad_norm: 2240.5462
2021-09-29 12:53:21,606 - mmdet - INFO - Epoch [1][50/245]	lr: 1.882e-05, eta: 9:27:12, time: 2.741, data_time: 0.029, memory: 29438, loss_rpn_cls: 0.5738, loss_rpn_bbox: 0.2253, s0.loss_cls: 0.2518, s0.acc: 95.7898, s0.loss_bbox: 0.0909, s1.loss_cls: 0.0566, s1.acc: 98.6121, s1.loss_bbox: 0.0185, s2.loss_cls: 0.0301, s2.acc: 99.0430, s2.loss_bbox: 0.0077, loss: 1.2546, grad_norm: 20.5884
2021-09-29 12:53:48,712 - mmdet - INFO - Epoch [1][60/245]	lr: 2.062e-05, eta: 9:24:04, time: 2.711, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.4833, loss_rpn_bbox: 0.2036, s0.loss_cls: 0.2520, s0.acc: 95.1819, s0.loss_bbox: 0.0996, s1.loss_cls: 0.0578, s1.acc: 98.4253, s1.loss_bbox: 0.0205, s2.loss_cls: 0.0250, s2.acc: 98.9221, s2.loss_bbox: 0.0083, loss: 1.1500, grad_norm: 3.3480
2021-09-29 12:54:15,783 - mmdet - INFO - Epoch [1][70/245]	lr: 2.242e-05, eta: 9:21:35, time: 2.707, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.3579, loss_rpn_bbox: 0.2264, s0.loss_cls: 0.2497, s0.acc: 94.9805, s0.loss_bbox: 0.1006, s1.loss_cls: 0.0486, s1.acc: 98.5168, s1.loss_bbox: 0.0189, s2.loss_cls: 0.0197, s2.acc: 98.8647, s2.loss_bbox: 0.0086, loss: 1.0306, grad_norm: 3.6134
2021-09-29 12:54:43,577 - mmdet - INFO - Epoch [1][80/245]	lr: 2.422e-05, eta: 9:21:27, time: 2.779, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.2173, loss_rpn_bbox: 0.1931, s0.loss_cls: 0.2281, s0.acc: 95.3857, s0.loss_bbox: 0.0904, s1.loss_cls: 0.0474, s1.acc: 98.5901, s1.loss_bbox: 0.0181, s2.loss_cls: 0.0179, s2.acc: 98.9636, s2.loss_bbox: 0.0079, loss: 0.8203, grad_norm: 3.7647
2021-09-29 12:55:11,780 - mmdet - INFO - Epoch [1][90/245]	lr: 2.602e-05, eta: 9:22:10, time: 2.820, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1774, loss_rpn_bbox: 0.2096, s0.loss_cls: 0.2325, s0.acc: 95.3845, s0.loss_bbox: 0.0922, s1.loss_cls: 0.0427, s1.acc: 98.6658, s1.loss_bbox: 0.0173, s2.loss_cls: 0.0158, s2.acc: 98.9270, s2.loss_bbox: 0.0085, loss: 0.7960, grad_norm: 4.1287
2021-09-29 12:55:39,860 - mmdet - INFO - Epoch [1][100/245]	lr: 2.782e-05, eta: 9:22:24, time: 2.808, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1697, loss_rpn_bbox: 0.1941, s0.loss_cls: 0.2587, s0.acc: 95.0378, s0.loss_bbox: 0.0976, s1.loss_cls: 0.0603, s1.acc: 98.1628, s1.loss_bbox: 0.0222, s2.loss_cls: 0.0209, s2.acc: 98.7573, s2.loss_bbox: 0.0096, loss: 0.8332, grad_norm: 4.5405
2021-09-29 12:56:07,514 - mmdet - INFO - Epoch [1][110/245]	lr: 2.962e-05, eta: 9:21:43, time: 2.765, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1394, loss_rpn_bbox: 0.1564, s0.loss_cls: 0.2388, s0.acc: 95.0769, s0.loss_bbox: 0.0987, s1.loss_cls: 0.0594, s1.acc: 98.2690, s1.loss_bbox: 0.0222, s2.loss_cls: 0.0163, s2.acc: 99.0027, s2.loss_bbox: 0.0077, loss: 0.7390, grad_norm: 4.0630
2021-09-29 12:56:36,097 - mmdet - INFO - Epoch [1][120/245]	lr: 3.142e-05, eta: 9:22:38, time: 2.858, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1501, loss_rpn_bbox: 0.1829, s0.loss_cls: 0.2654, s0.acc: 94.7058, s0.loss_bbox: 0.1058, s1.loss_cls: 0.0632, s1.acc: 98.0090, s1.loss_bbox: 0.0258, s2.loss_cls: 0.0213, s2.acc: 98.7476, s2.loss_bbox: 0.0099, loss: 0.8243, grad_norm: 3.4074
2021-09-29 12:57:04,123 - mmdet - INFO - Epoch [1][130/245]	lr: 3.322e-05, eta: 9:22:28, time: 2.803, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1558, loss_rpn_bbox: 0.1961, s0.loss_cls: 0.2519, s0.acc: 94.6008, s0.loss_bbox: 0.1073, s1.loss_cls: 0.0523, s1.acc: 98.1885, s1.loss_bbox: 0.0237, s2.loss_cls: 0.0161, s2.acc: 98.8452, s2.loss_bbox: 0.0095, loss: 0.8128, grad_norm: 2.9784
2021-09-29 12:57:31,966 - mmdet - INFO - Epoch [1][140/245]	lr: 3.502e-05, eta: 9:22:00, time: 2.784, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1418, loss_rpn_bbox: 0.1888, s0.loss_cls: 0.2469, s0.acc: 94.7607, s0.loss_bbox: 0.1061, s1.loss_cls: 0.0491, s1.acc: 98.1641, s1.loss_bbox: 0.0233, s2.loss_cls: 0.0139, s2.acc: 98.9441, s2.loss_bbox: 0.0086, loss: 0.7785, grad_norm: 2.6151
2021-09-29 12:57:59,609 - mmdet - INFO - Epoch [1][150/245]	lr: 3.682e-05, eta: 9:21:16, time: 2.764, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1167, loss_rpn_bbox: 0.1492, s0.loss_cls: 0.2396, s0.acc: 95.0854, s0.loss_bbox: 0.0992, s1.loss_cls: 0.0510, s1.acc: 98.2092, s1.loss_bbox: 0.0227, s2.loss_cls: 0.0140, s2.acc: 99.0149, s2.loss_bbox: 0.0077, loss: 0.7001, grad_norm: 2.5275
2021-09-29 12:58:27,411 - mmdet - INFO - Epoch [1][160/245]	lr: 3.862e-05, eta: 9:20:46, time: 2.780, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1493, loss_rpn_bbox: 0.1987, s0.loss_cls: 0.2555, s0.acc: 94.7278, s0.loss_bbox: 0.1087, s1.loss_cls: 0.0557, s1.acc: 97.9553, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0163, s2.acc: 98.7012, s2.loss_bbox: 0.0100, loss: 0.8201, grad_norm: 3.1003
2021-09-29 12:58:55,725 - mmdet - INFO - Epoch [1][170/245]	lr: 4.042e-05, eta: 9:20:52, time: 2.831, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1215, loss_rpn_bbox: 0.1680, s0.loss_cls: 0.2629, s0.acc: 94.2725, s0.loss_bbox: 0.1143, s1.loss_cls: 0.0544, s1.acc: 98.0725, s1.loss_bbox: 0.0240, s2.loss_cls: 0.0168, s2.acc: 98.7646, s2.loss_bbox: 0.0095, loss: 0.7714, grad_norm: 3.5218
2021-09-29 12:59:23,844 - mmdet - INFO - Epoch [1][180/245]	lr: 4.222e-05, eta: 9:20:42, time: 2.812, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1315, loss_rpn_bbox: 0.1728, s0.loss_cls: 0.2556, s0.acc: 94.5825, s0.loss_bbox: 0.1100, s1.loss_cls: 0.0484, s1.acc: 98.2056, s1.loss_bbox: 0.0229, s2.loss_cls: 0.0151, s2.acc: 98.8489, s2.loss_bbox: 0.0085, loss: 0.7646, grad_norm: 2.7638
2021-09-29 12:59:51,924 - mmdet - INFO - Epoch [1][190/245]	lr: 4.402e-05, eta: 9:20:27, time: 2.808, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1407, loss_rpn_bbox: 0.1898, s0.loss_cls: 0.2588, s0.acc: 94.5325, s0.loss_bbox: 0.1112, s1.loss_cls: 0.0638, s1.acc: 97.6599, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0205, s2.acc: 98.5535, s2.loss_bbox: 0.0114, loss: 0.8248, grad_norm: 2.7896
2021-09-29 13:00:19,794 - mmdet - INFO - Epoch [1][200/245]	lr: 4.582e-05, eta: 9:19:59, time: 2.787, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1394, loss_rpn_bbox: 0.1876, s0.loss_cls: 0.2495, s0.acc: 94.6960, s0.loss_bbox: 0.1082, s1.loss_cls: 0.0546, s1.acc: 98.1079, s1.loss_bbox: 0.0239, s2.loss_cls: 0.0163, s2.acc: 98.8000, s2.loss_bbox: 0.0094, loss: 0.7889, grad_norm: 2.5891
2021-09-29 13:00:48,171 - mmdet - INFO - Epoch [1][210/245]	lr: 4.762e-05, eta: 9:19:59, time: 2.838, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.1430, loss_rpn_bbox: 0.1973, s0.loss_cls: 0.2665, s0.acc: 94.0503, s0.loss_bbox: 0.1219, s1.loss_cls: 0.0584, s1.acc: 97.8601, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0168, s2.acc: 98.7427, s2.loss_bbox: 0.0099, loss: 0.8406, grad_norm: 3.0634
2021-09-29 13:01:16,441 - mmdet - INFO - Epoch [1][220/245]	lr: 4.942e-05, eta: 9:19:51, time: 2.827, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1175, loss_rpn_bbox: 0.1733, s0.loss_cls: 0.2463, s0.acc: 94.4287, s0.loss_bbox: 0.1094, s1.loss_cls: 0.0528, s1.acc: 98.1128, s1.loss_bbox: 0.0237, s2.loss_cls: 0.0133, s2.acc: 98.9612, s2.loss_bbox: 0.0081, loss: 0.7445, grad_norm: 2.8664
2021-09-29 13:01:45,250 - mmdet - INFO - Epoch [1][230/245]	lr: 5.122e-05, eta: 9:20:09, time: 2.881, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1279, loss_rpn_bbox: 0.1887, s0.loss_cls: 0.2752, s0.acc: 93.6755, s0.loss_bbox: 0.1293, s1.loss_cls: 0.0685, s1.acc: 97.3999, s1.loss_bbox: 0.0328, s2.loss_cls: 0.0208, s2.acc: 98.4668, s2.loss_bbox: 0.0116, loss: 0.8548, grad_norm: 2.6755
2021-09-29 13:02:13,059 - mmdet - INFO - Epoch [1][240/245]	lr: 5.302e-05, eta: 9:19:34, time: 2.781, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1010, loss_rpn_bbox: 0.1541, s0.loss_cls: 0.2346, s0.acc: 94.8999, s0.loss_bbox: 0.1030, s1.loss_cls: 0.0451, s1.acc: 98.3984, s1.loss_bbox: 0.0203, s2.loss_cls: 0.0137, s2.acc: 98.9856, s2.loss_bbox: 0.0077, loss: 0.6796, grad_norm: 2.1345
2021-09-29 13:02:26,910 - mmdet - INFO - Saving checkpoint at 1 epochs
[                                                  ] 0/977, elapsed: 0s, ETA:[  ] 1/977, 3.9 task/s, elapsed: 0s, ETA:   249s[  ] 2/977, 5.6 task/s, elapsed: 0s, ETA:   175s[  ] 3/977, 6.4 task/s, elapsed: 0s, ETA:   152s[  ] 4/977, 6.8 task/s, elapsed: 1s, ETA:   143s[  ] 5/977, 7.3 task/s, elapsed: 1s, ETA:   134s[  ] 6/977, 7.6 task/s, elapsed: 1s, ETA:   128s[  ] 7/977, 7.9 task/s, elapsed: 1s, ETA:   123s[  ] 8/977, 8.1 task/s, elapsed: 1s, ETA:   120s[  ] 9/977, 8.2 task/s, elapsed: 1s, ETA:   117s[  ] 10/977, 8.4 task/s, elapsed: 1s, ETA:   115s[  ] 11/977, 8.5 task/s, elapsed: 1s, ETA:   113s[  ] 12/977, 8.6 task/s, elapsed: 1s, ETA:   112s[  ] 13/977, 8.7 task/s, elapsed: 1s, ETA:   111s[  ] 14/977, 8.8 task/s, elapsed: 2s, ETA:   110s[  ] 15/977, 8.8 task/s, elapsed: 2s, ETA:   109s[  ] 16/977, 8.8 task/s, elapsed: 2s, ETA:   109s[  ] 17/977, 8.9 task/s, elapsed: 2s, ETA:   108s[  ] 18/977, 8.9 task/s, elapsed: 2s, ETA:   107s[  ] 19/977, 9.0 task/s, elapsed: 2s, ETA:   107s[  ] 20/977, 9.0 task/s, elapsed: 2s, ETA:   106s[  ] 21/977, 9.1 task/s, elapsed: 2s, ETA:   105s[  ] 22/977, 9.1 task/s, elapsed: 2s, ETA:   105s[  ] 23/977, 9.1 task/s, elapsed: 3s, ETA:   104s[  ] 24/977, 9.2 task/s, elapsed: 3s, ETA:   104s[  ] 25/977, 9.2 task/s, elapsed: 3s, ETA:   104s[  ] 26/977, 9.2 task/s, elapsed: 3s, ETA:   103s[  ] 27/977, 9.2 task/s, elapsed: 3s, ETA:   103s[  ] 28/977, 9.3 task/s, elapsed: 3s, ETA:   102s[  ] 29/977, 9.3 task/s, elapsed: 3s, ETA:   102s[  ] 30/977, 9.3 task/s, elapsed: 3s, ETA:   102s[  ] 31/977, 9.3 task/s, elapsed: 3s, ETA:   101s[  ] 32/977, 9.3 task/s, elapsed: 3s, ETA:   101s[  ] 33/977, 9.4 task/s, elapsed: 4s, ETA:   101s[  ] 34/977, 9.4 task/s, elapsed: 4s, ETA:   101s[  ] 35/977, 9.4 task/s, elapsed: 4s, ETA:   100s[  ] 36/977, 9.4 task/s, elapsed: 4s, ETA:   100s[  ] 37/977, 9.4 task/s, elapsed: 4s, ETA:   100s[  ] 38/977, 9.4 task/s, elapsed: 4s, ETA:   100s[  ] 39/977, 9.4 task/s, elapsed: 4s, ETA:   100s[  ] 40/977, 9.4 task/s, elapsed: 4s, ETA:   100s[  ] 41/977, 9.4 task/s, elapsed: 4s, ETA:    99s[  ] 42/977, 9.4 task/s, elapsed: 4s, ETA:    99s[  ] 43/977, 9.4 task/s, elapsed: 5s, ETA:    99s[  ] 44/977, 9.4 task/s, elapsed: 5s, ETA:    99s[  ] 45/977, 9.4 task/s, elapsed: 5s, ETA:    99s[  ] 46/977, 9.5 task/s, elapsed: 5s, ETA:    98s[  ] 47/977, 9.5 task/s, elapsed: 5s, ETA:    98s[  ] 48/977, 9.5 task/s, elapsed: 5s, ETA:    98s[  ] 49/977, 9.5 task/s, elapsed: 5s, ETA:    98s[  ] 50/977, 9.5 task/s, elapsed: 5s, ETA:    98s[  ] 51/977, 9.5 task/s, elapsed: 5s, ETA:    98s[  ] 52/977, 9.5 task/s, elapsed: 5s, ETA:    97s[  ] 53/977, 9.5 task/s, elapsed: 6s, ETA:    97s[  ] 54/977, 9.5 task/s, elapsed: 6s, ETA:    97s[  ] 55/977, 9.5 task/s, elapsed: 6s, ETA:    97s[  ] 56/977, 9.5 task/s, elapsed: 6s, ETA:    97s[  ] 57/977, 9.5 task/s, elapsed: 6s, ETA:    96s[  ] 58/977, 9.5 task/s, elapsed: 6s, ETA:    96s[  ] 59/977, 9.6 task/s, elapsed: 6s, ETA:    96s[  ] 60/977, 9.6 task/s, elapsed: 6s, ETA:    96s[  ] 61/977, 9.6 task/s, elapsed: 6s, ETA:    96s[  ] 62/977, 9.6 task/s, elapsed: 6s, ETA:    96s[  ] 63/977, 9.6 task/s, elapsed: 7s, ETA:    95s[  ] 64/977, 9.6 task/s, elapsed: 7s, ETA:    95s[  ] 65/977, 9.6 task/s, elapsed: 7s, ETA:    95s[  ] 66/977, 9.6 task/s, elapsed: 7s, ETA:    95s[  ] 67/977, 9.6 task/s, elapsed: 7s, ETA:    95s[  ] 68/977, 9.6 task/s, elapsed: 7s, ETA:    95s[  ] 69/977, 9.6 task/s, elapsed: 7s, ETA:    95s[  ] 70/977, 9.6 task/s, elapsed: 7s, ETA:    94s[  ] 71/977, 9.6 task/s, elapsed: 7s, ETA:    94s[  ] 72/977, 9.6 task/s, elapsed: 7s, ETA:    94s[  ] 73/977, 9.6 task/s, elapsed: 8s, ETA:    94s[  ] 74/977, 9.6 task/s, elapsed: 8s, ETA:    94s[  ] 75/977, 9.6 task/s, elapsed: 8s, ETA:    94s[  ] 76/977, 9.6 task/s, elapsed: 8s, ETA:    94s[  ] 77/977, 9.6 task/s, elapsed: 8s, ETA:    93s[  ] 78/977, 9.6 task/s, elapsed: 8s, ETA:    93s[  ] 79/977, 9.6 task/s, elapsed: 8s, ETA:    93s[  ] 80/977, 9.6 task/s, elapsed: 8s, ETA:    93s[  ] 81/977, 9.6 task/s, elapsed: 8s, ETA:    93s[  ] 82/977, 9.7 task/s, elapsed: 8s, ETA:    93s[  ] 83/977, 9.7 task/s, elapsed: 9s, ETA:    93s[  ] 84/977, 9.7 task/s, elapsed: 9s, ETA:    93s[  ] 85/977, 9.7 task/s, elapsed: 9s, ETA:    92s[  ] 86/977, 9.7 task/s, elapsed: 9s, ETA:    92s[  ] 87/977, 9.7 task/s, elapsed: 9s, ETA:    92s[  ] 88/977, 9.7 task/s, elapsed: 9s, ETA:    92s[  ] 89/977, 9.7 task/s, elapsed: 9s, ETA:    92s[  ] 90/977, 9.7 task/s, elapsed: 9s, ETA:    92s[  ] 91/977, 9.7 task/s, elapsed: 9s, ETA:    92s[  ] 92/977, 9.7 task/s, elapsed: 10s, ETA:    92s[  ] 93/977, 9.7 task/s, elapsed: 10s, ETA:    91s[  ] 94/977, 9.7 task/s, elapsed: 10s, ETA:    91s[  ] 95/977, 9.7 task/s, elapsed: 10s, ETA:    91s[  ] 96/977, 9.7 task/s, elapsed: 10s, ETA:    91s[  ] 97/977, 9.7 task/s, elapsed: 10s, ETA:    91s[  ] 98/977, 9.7 task/s, elapsed: 10s, ETA:    91s[  ] 99/977, 9.6 task/s, elapsed: 10s, ETA:    91s[  ] 100/977, 9.7 task/s, elapsed: 10s, ETA:    91s[  ] 101/977, 9.7 task/s, elapsed: 10s, ETA:    91s[  ] 102/977, 9.6 task/s, elapsed: 11s, ETA:    91s[  ] 103/977, 9.6 task/s, elapsed: 11s, ETA:    91s[  ] 104/977, 9.6 task/s, elapsed: 11s, ETA:    91s[  ] 105/977, 9.6 task/s, elapsed: 11s, ETA:    91s[  ] 106/977, 9.6 task/s, elapsed: 11s, ETA:    91s[  ] 107/977, 9.6 task/s, elapsed: 11s, ETA:    91s[  ] 108/977, 9.6 task/s, elapsed: 11s, ETA:    91s[  ] 109/977, 9.6 task/s, elapsed: 11s, ETA:    91s[  ] 110/977, 9.6 task/s, elapsed: 11s, ETA:    91s[  ] 111/977, 9.6 task/s, elapsed: 12s, ETA:    91s[  ] 112/977, 9.5 task/s, elapsed: 12s, ETA:    91s[  ] 113/977, 9.5 task/s, elapsed: 12s, ETA:    91s[  ] 114/977, 9.5 task/s, elapsed: 12s, ETA:    91s[  ] 115/977, 9.5 task/s, elapsed: 12s, ETA:    91s[  ] 116/977, 9.5 task/s, elapsed: 12s, ETA:    91s[  ] 117/977, 9.5 task/s, elapsed: 12s, ETA:    91s[  ] 118/977, 9.5 task/s, elapsed: 12s, ETA:    90s[  ] 119/977, 9.5 task/s, elapsed: 13s, ETA:    90s[  ] 120/977, 9.5 task/s, elapsed: 13s, ETA:    90s[  ] 121/977, 9.5 task/s, elapsed: 13s, ETA:    90s[  ] 122/977, 9.5 task/s, elapsed: 13s, ETA:    90s[  ] 123/977, 9.5 task/s, elapsed: 13s, ETA:    90s[  ] 124/977, 9.5 task/s, elapsed: 13s, ETA:    90s[  ] 125/977, 9.5 task/s, elapsed: 13s, ETA:    90s[  ] 126/977, 9.5 task/s, elapsed: 13s, ETA:    89s[  ] 127/977, 9.5 task/s, elapsed: 13s, ETA:    89s[  ] 128/977, 9.5 task/s, elapsed: 13s, ETA:    89s[  ] 129/977, 9.5 task/s, elapsed: 14s, ETA:    89s[  ] 130/977, 9.5 task/s, elapsed: 14s, ETA:    89s[  ] 131/977, 9.5 task/s, elapsed: 14s, ETA:    89s[  ] 132/977, 9.5 task/s, elapsed: 14s, ETA:    89s[  ] 133/977, 9.5 task/s, elapsed: 14s, ETA:    88s[  ] 134/977, 9.5 task/s, elapsed: 14s, ETA:    88s[  ] 135/977, 9.6 task/s, elapsed: 14s, ETA:    88s[  ] 136/977, 9.6 task/s, elapsed: 14s, ETA:    88s[  ] 137/977, 9.6 task/s, elapsed: 14s, ETA:    88s[  ] 138/977, 9.6 task/s, elapsed: 14s, ETA:    88s[  ] 139/977, 9.6 task/s, elapsed: 15s, ETA:    88s[  ] 140/977, 9.6 task/s, elapsed: 15s, ETA:    88s[  ] 141/977, 9.6 task/s, elapsed: 15s, ETA:    87s[  ] 142/977, 9.6 task/s, elapsed: 15s, ETA:    87s[  ] 143/977, 9.6 task/s, elapsed: 15s, ETA:    87s[  ] 144/977, 9.6 task/s, elapsed: 15s, ETA:    87s[  ] 145/977, 9.6 task/s, elapsed: 15s, ETA:    87s[  ] 146/977, 9.6 task/s, elapsed: 15s, ETA:    87s[  ] 147/977, 9.6 task/s, elapsed: 15s, ETA:    87s[  ] 148/977, 9.6 task/s, elapsed: 15s, ETA:    87s[  ] 149/977, 9.6 task/s, elapsed: 16s, ETA:    86s[  ] 150/977, 9.6 task/s, elapsed: 16s, ETA:    86s[  ] 151/977, 9.6 task/s, elapsed: 16s, ETA:    86s[  ] 152/977, 9.6 task/s, elapsed: 16s, ETA:    86s[  ] 153/977, 9.6 task/s, elapsed: 16s, ETA:    86s[  ] 154/977, 9.6 task/s, elapsed: 16s, ETA:    86s[  ] 155/977, 9.6 task/s, elapsed: 16s, ETA:    86s[  ] 156/977, 9.6 task/s, elapsed: 16s, ETA:    86s[  ] 157/977, 9.6 task/s, elapsed: 16s, ETA:    86s[  ] 158/977, 9.6 task/s, elapsed: 16s, ETA:    85s[  ] 159/977, 9.6 task/s, elapsed: 17s, ETA:    85s[  ] 160/977, 9.6 task/s, elapsed: 17s, ETA:    85s[  ] 161/977, 9.6 task/s, elapsed: 17s, ETA:    85s[  ] 162/977, 9.6 task/s, elapsed: 17s, ETA:    85s[  ] 163/977, 9.6 task/s, elapsed: 17s, ETA:    85s[  ] 164/977, 9.6 task/s, elapsed: 17s, ETA:    85s[  ] 165/977, 9.6 task/s, elapsed: 17s, ETA:    85s[  ] 166/977, 9.6 task/s, elapsed: 17s, ETA:    85s[  ] 167/977, 9.6 task/s, elapsed: 17s, ETA:    85s[  ] 168/977, 9.6 task/s, elapsed: 18s, ETA:    84s[  ] 169/977, 9.6 task/s, elapsed: 18s, ETA:    84s[  ] 170/977, 9.6 task/s, elapsed: 18s, ETA:    84s[  ] 171/977, 9.6 task/s, elapsed: 18s, ETA:    84s[  ] 172/977, 9.6 task/s, elapsed: 18s, ETA:    84s[  ] 173/977, 9.6 task/s, elapsed: 18s, ETA:    84s[  ] 174/977, 9.6 task/s, elapsed: 18s, ETA:    84s[  ] 175/977, 9.6 task/s, elapsed: 18s, ETA:    84s[  ] 176/977, 9.6 task/s, elapsed: 18s, ETA:    83s[  ] 177/977, 9.6 task/s, elapsed: 18s, ETA:    83s[  ] 178/977, 9.6 task/s, elapsed: 19s, ETA:    83s[  ] 179/977, 9.6 task/s, elapsed: 19s, ETA:    83s[  ] 180/977, 9.6 task/s, elapsed: 19s, ETA:    83s[  ] 181/977, 9.6 task/s, elapsed: 19s, ETA:    83s[  ] 182/977, 9.6 task/s, elapsed: 19s, ETA:    83s[  ] 183/977, 9.6 task/s, elapsed: 19s, ETA:    83s[  ] 184/977, 9.6 task/s, elapsed: 19s, ETA:    83s[  ] 185/977, 9.6 task/s, elapsed: 19s, ETA:    82s[  ] 186/977, 9.6 task/s, elapsed: 19s, ETA:    82s[  ] 187/977, 9.6 task/s, elapsed: 19s, ETA:    82s[  ] 188/977, 9.6 task/s, elapsed: 20s, ETA:    82s[  ] 189/977, 9.6 task/s, elapsed: 20s, ETA:    82s[  ] 190/977, 9.6 task/s, elapsed: 20s, ETA:    82s[  ] 191/977, 9.6 task/s, elapsed: 20s, ETA:    82s[  ] 192/977, 9.6 task/s, elapsed: 20s, ETA:    82s[  ] 193/977, 9.6 task/s, elapsed: 20s, ETA:    82s[  ] 194/977, 9.6 task/s, elapsed: 20s, ETA:    81s[  ] 195/977, 9.6 task/s, elapsed: 20s, ETA:    81s[  ] 196/977, 9.6 task/s, elapsed: 20s, ETA:    81s[  ] 197/977, 9.6 task/s, elapsed: 20s, ETA:    81s[  ] 198/977, 9.6 task/s, elapsed: 21s, ETA:    81s[  ] 199/977, 9.6 task/s, elapsed: 21s, ETA:    81s[  ] 200/977, 9.6 task/s, elapsed: 21s, ETA:    81s[  ] 201/977, 9.6 task/s, elapsed: 21s, ETA:    81s[  ] 202/977, 9.6 task/s, elapsed: 21s, ETA:    81s[  ] 203/977, 9.6 task/s, elapsed: 21s, ETA:    80s[  ] 204/977, 9.6 task/s, elapsed: 21s, ETA:    80s[  ] 205/977, 9.6 task/s, elapsed: 21s, ETA:    80s[  ] 206/977, 9.6 task/s, elapsed: 21s, ETA:    80s[  ] 207/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 208/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 209/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 210/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 211/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 212/977, 9.6 task/s, elapsed: 22s, ETA:    79s[  ] 213/977, 9.6 task/s, elapsed: 22s, ETA:    79s[  ] 214/977, 9.6 task/s, elapsed: 22s, ETA:    79s[  ] 215/977, 9.6 task/s, elapsed: 22s, ETA:    79s[  ] 216/977, 9.6 task/s, elapsed: 22s, ETA:    79s[  ] 217/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 218/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 219/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 220/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 221/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 222/977, 9.6 task/s, elapsed: 23s, ETA:    78s[  ] 223/977, 9.6 task/s, elapsed: 23s, ETA:    78s[  ] 224/977, 9.6 task/s, elapsed: 23s, ETA:    78s[  ] 225/977, 9.6 task/s, elapsed: 23s, ETA:    78s[  ] 226/977, 9.6 task/s, elapsed: 23s, ETA:    78s[  ] 227/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 228/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 229/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 230/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 231/977, 9.6 task/s, elapsed: 24s, ETA:    77s[  ] 232/977, 9.6 task/s, elapsed: 24s, ETA:    77s[  ] 233/977, 9.6 task/s, elapsed: 24s, ETA:    77s[  ] 234/977, 9.6 task/s, elapsed: 24s, ETA:    77s[  ] 235/977, 9.6 task/s, elapsed: 24s, ETA:    77s[  ] 236/977, 9.6 task/s, elapsed: 24s, ETA:    77s[  ] 237/977, 9.6 task/s, elapsed: 25s, ETA:    77s[  ] 238/977, 9.6 task/s, elapsed: 25s, ETA:    77s[  ] 239/977, 9.6 task/s, elapsed: 25s, ETA:    77s[  ] 240/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 241/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 242/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 243/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 244/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 245/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 246/977, 9.6 task/s, elapsed: 26s, ETA:    76s[  ] 247/977, 9.6 task/s, elapsed: 26s, ETA:    76s[  ] 248/977, 9.6 task/s, elapsed: 26s, ETA:    76s[  ] 249/977, 9.6 task/s, elapsed: 26s, ETA:    75s[  ] 250/977, 9.7 task/s, elapsed: 26s, ETA:    75s[  ] 251/977, 9.7 task/s, elapsed: 26s, ETA:    75s[  ] 252/977, 9.7 task/s, elapsed: 26s, ETA:    75s[  ] 253/977, 9.7 task/s, elapsed: 26s, ETA:    75s[  ] 254/977, 9.7 task/s, elapsed: 26s, ETA:    75s[  ] 255/977, 9.7 task/s, elapsed: 26s, ETA:    75s[  ] 256/977, 9.7 task/s, elapsed: 27s, ETA:    75s[  ] 257/977, 9.7 task/s, elapsed: 27s, ETA:    75s[  ] 258/977, 9.7 task/s, elapsed: 27s, ETA:    74s[  ] 259/977, 9.7 task/s, elapsed: 27s, ETA:    74s[  ] 260/977, 9.7 task/s, elapsed: 27s, ETA:    74s[  ] 261/977, 9.7 task/s, elapsed: 27s, ETA:    74s[  ] 262/977, 9.7 task/s, elapsed: 27s, ETA:    74s[  ] 263/977, 9.7 task/s, elapsed: 27s, ETA:    74s[  ] 264/977, 9.7 task/s, elapsed: 27s, ETA:    74s[  ] 265/977, 9.7 task/s, elapsed: 27s, ETA:    74s[  ] 266/977, 9.7 task/s, elapsed: 28s, ETA:    74s[  ] 267/977, 9.7 task/s, elapsed: 28s, ETA:    74s[  ] 268/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 269/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 270/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 271/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 272/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 273/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 274/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 275/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 276/977, 9.7 task/s, elapsed: 29s, ETA:    73s[  ] 277/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 278/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 279/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 280/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 281/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 282/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 283/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 284/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 285/977, 9.7 task/s, elapsed: 30s, ETA:    72s[  ] 286/977, 9.7 task/s, elapsed: 30s, ETA:    72s[  ] 287/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 288/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 289/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 290/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 291/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 292/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 293/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 294/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 295/977, 9.7 task/s, elapsed: 31s, ETA:    71s[  ] 296/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 297/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 298/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 299/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 300/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 301/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 302/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 303/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 304/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 305/977, 9.7 task/s, elapsed: 32s, ETA:    70s[  ] 306/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 307/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 308/977, 9.6 task/s, elapsed: 32s, ETA:    69s[  ] 309/977, 9.6 task/s, elapsed: 32s, ETA:    69s[  ] 310/977, 9.6 task/s, elapsed: 32s, ETA:    69s[  ] 311/977, 9.6 task/s, elapsed: 32s, ETA:    69s[  ] 312/977, 9.6 task/s, elapsed: 32s, ETA:    69s[  ] 313/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 314/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 315/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 316/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 317/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 318/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 319/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 320/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 321/977, 9.6 task/s, elapsed: 33s, ETA:    68s[  ] 322/977, 9.6 task/s, elapsed: 34s, ETA:    68s[  ] 323/977, 9.6 task/s, elapsed: 34s, ETA:    68s[  ] 324/977, 9.6 task/s, elapsed: 34s, ETA:    68s[  ] 325/977, 9.6 task/s, elapsed: 34s, ETA:    68s[  ] 326/977, 9.6 task/s, elapsed: 34s, ETA:    68s[  ] 327/977, 9.6 task/s, elapsed: 34s, ETA:    68s[  ] 328/977, 9.6 task/s, elapsed: 34s, ETA:    68s[  ] 329/977, 9.6 task/s, elapsed: 34s, ETA:    68s[  ] 330/977, 9.6 task/s, elapsed: 35s, ETA:    68s[  ] 331/977, 9.6 task/s, elapsed: 35s, ETA:    68s[  ] 332/977, 9.6 task/s, elapsed: 35s, ETA:    68s[  ] 333/977, 9.6 task/s, elapsed: 35s, ETA:    67s[  ] 334/977, 9.6 task/s, elapsed: 35s, ETA:    67s[  ] 335/977, 9.6 task/s, elapsed: 35s, ETA:    67s[  ] 336/977, 9.6 task/s, elapsed: 35s, ETA:    67s[  ] 337/977, 9.6 task/s, elapsed: 35s, ETA:    67s[  ] 338/977, 9.6 task/s, elapsed: 35s, ETA:    67s[  ] 339/977, 9.6 task/s, elapsed: 35s, ETA:    67s[  ] 340/977, 9.6 task/s, elapsed: 36s, ETA:    67s[  ] 341/977, 9.6 task/s, elapsed: 36s, ETA:    67s[  ] 342/977, 9.6 task/s, elapsed: 36s, ETA:    66s[  ] 343/977, 9.6 task/s, elapsed: 36s, ETA:    66s[  ] 344/977, 9.6 task/s, elapsed: 36s, ETA:    66s[  ] 345/977, 9.6 task/s, elapsed: 36s, ETA:    66s[  ] 346/977, 9.6 task/s, elapsed: 36s, ETA:    66s[  ] 347/977, 9.6 task/s, elapsed: 36s, ETA:    66s[  ] 348/977, 9.6 task/s, elapsed: 36s, ETA:    66s[  ] 349/977, 9.6 task/s, elapsed: 37s, ETA:    66s[  ] 350/977, 9.6 task/s, elapsed: 37s, ETA:    66s[  ] 351/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 352/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 353/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 354/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 355/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 356/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 357/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 358/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 359/977, 9.6 task/s, elapsed: 38s, ETA:    65s[  ] 360/977, 9.6 task/s, elapsed: 38s, ETA:    65s[  ] 361/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 362/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 363/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 364/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 365/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 366/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 367/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 368/977, 9.6 task/s, elapsed: 39s, ETA:    64s[  ] 369/977, 9.6 task/s, elapsed: 39s, ETA:    64s[  ] 370/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 371/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 372/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 373/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 374/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 375/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 376/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 377/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 378/977, 9.6 task/s, elapsed: 40s, ETA:    63s[  ] 379/977, 9.6 task/s, elapsed: 40s, ETA:    63s[  ] 380/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 381/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 382/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 383/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 384/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 385/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 386/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 387/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 388/977, 9.6 task/s, elapsed: 41s, ETA:    62s[  ] 389/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 390/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 391/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 392/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 393/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 394/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 395/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 396/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 397/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 398/977, 9.6 task/s, elapsed: 42s, ETA:    61s[  ] 399/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 400/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 401/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 402/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 403/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 404/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 405/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 406/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 407/977, 9.6 task/s, elapsed: 43s, ETA:    60s[  ] 408/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 409/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 410/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 411/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 412/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 413/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 414/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 415/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 416/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 417/977, 9.6 task/s, elapsed: 44s, ETA:    59s[  ] 418/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 419/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 420/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 421/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 422/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 423/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 424/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 425/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 426/977, 9.6 task/s, elapsed: 45s, ETA:    58s[  ] 427/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 428/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 429/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 430/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 431/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 432/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 433/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 434/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 435/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 436/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 437/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 438/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 439/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 440/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 441/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 442/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 443/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 444/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 445/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 446/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 447/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 448/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 449/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 450/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 451/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 452/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 453/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 454/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 455/977, 9.6 task/s, elapsed: 47s, ETA:    54s[  ] 456/977, 9.6 task/s, elapsed: 48s, ETA:    54s[  ] 457/977, 9.6 task/s, elapsed: 48s, ETA:    54s[  ] 458/977, 9.6 task/s, elapsed: 48s, ETA:    54s[  ] 459/977, 9.6 task/s, elapsed: 48s, ETA:    54s[  ] 460/977, 9.6 task/s, elapsed: 48s, ETA:    54s[  ] 461/977, 9.6 task/s, elapsed: 48s, ETA:    54s[  ] 462/977, 9.6 task/s, elapsed: 48s, ETA:    54s[  ] 463/977, 9.6 task/s, elapsed: 48s, ETA:    54s[  ] 464/977, 9.6 task/s, elapsed: 48s, ETA:    53s[  ] 465/977, 9.6 task/s, elapsed: 48s, ETA:    53s[  ] 466/977, 9.6 task/s, elapsed: 49s, ETA:    53s[  ] 467/977, 9.6 task/s, elapsed: 49s, ETA:    53s[  ] 468/977, 9.6 task/s, elapsed: 49s, ETA:    53s[  ] 469/977, 9.6 task/s, elapsed: 49s, ETA:    53s[  ] 470/977, 9.6 task/s, elapsed: 49s, ETA:    53s[  ] 471/977, 9.6 task/s, elapsed: 49s, ETA:    53s[  ] 472/977, 9.6 task/s, elapsed: 49s, ETA:    53s[  ] 473/977, 9.6 task/s, elapsed: 49s, ETA:    53s[  ] 474/977, 9.6 task/s, elapsed: 49s, ETA:    52s[  ] 475/977, 9.6 task/s, elapsed: 50s, ETA:    52s[  ] 476/977, 9.6 task/s, elapsed: 50s, ETA:    52s[  ] 477/977, 9.6 task/s, elapsed: 50s, ETA:    52s[  ] 478/977, 9.6 task/s, elapsed: 50s, ETA:    52s[  ] 479/977, 9.6 task/s, elapsed: 50s, ETA:    52s[  ] 480/977, 9.6 task/s, elapsed: 50s, ETA:    52s[  ] 481/977, 9.6 task/s, elapsed: 50s, ETA:    52s[  ] 482/977, 9.6 task/s, elapsed: 50s, ETA:    52s[  ] 483/977, 9.6 task/s, elapsed: 50s, ETA:    51s[  ] 484/977, 9.6 task/s, elapsed: 50s, ETA:    51s[  ] 485/977, 9.6 task/s, elapsed: 51s, ETA:    51s[  ] 486/977, 9.6 task/s, elapsed: 51s, ETA:    51s[  ] 487/977, 9.6 task/s, elapsed: 51s, ETA:    51s[  ] 488/977, 9.6 task/s, elapsed: 51s, ETA:    51s[> ] 489/977, 9.6 task/s, elapsed: 51s, ETA:    51s[> ] 490/977, 9.6 task/s, elapsed: 51s, ETA:    51s[> ] 491/977, 9.6 task/s, elapsed: 51s, ETA:    51s[> ] 492/977, 9.6 task/s, elapsed: 51s, ETA:    51s[> ] 493/977, 9.6 task/s, elapsed: 51s, ETA:    50s[> ] 494/977, 9.6 task/s, elapsed: 51s, ETA:    50s[> ] 495/977, 9.6 task/s, elapsed: 52s, ETA:    50s[> ] 496/977, 9.6 task/s, elapsed: 52s, ETA:    50s[> ] 497/977, 9.6 task/s, elapsed: 52s, ETA:    50s[> ] 498/977, 9.6 task/s, elapsed: 52s, ETA:    50s[> ] 499/977, 9.6 task/s, elapsed: 52s, ETA:    50s[> ] 500/977, 9.6 task/s, elapsed: 52s, ETA:    50s[> ] 501/977, 9.6 task/s, elapsed: 52s, ETA:    50s[> ] 502/977, 9.6 task/s, elapsed: 52s, ETA:    49s[> ] 503/977, 9.6 task/s, elapsed: 52s, ETA:    49s[> ] 504/977, 9.6 task/s, elapsed: 52s, ETA:    49s[> ] 505/977, 9.6 task/s, elapsed: 53s, ETA:    49s[> ] 506/977, 9.6 task/s, elapsed: 53s, ETA:    49s[> ] 507/977, 9.6 task/s, elapsed: 53s, ETA:    49s[> ] 508/977, 9.6 task/s, elapsed: 53s, ETA:    49s[> ] 509/977, 9.6 task/s, elapsed: 53s, ETA:    49s[> ] 510/977, 9.6 task/s, elapsed: 53s, ETA:    49s[> ] 511/977, 9.6 task/s, elapsed: 53s, ETA:    48s[> ] 512/977, 9.6 task/s, elapsed: 53s, ETA:    48s[> ] 513/977, 9.6 task/s, elapsed: 53s, ETA:    48s[> ] 514/977, 9.6 task/s, elapsed: 53s, ETA:    48s[> ] 515/977, 9.6 task/s, elapsed: 54s, ETA:    48s[> ] 516/977, 9.6 task/s, elapsed: 54s, ETA:    48s[> ] 517/977, 9.6 task/s, elapsed: 54s, ETA:    48s[> ] 518/977, 9.6 task/s, elapsed: 54s, ETA:    48s[> ] 519/977, 9.6 task/s, elapsed: 54s, ETA:    48s[> ] 520/977, 9.6 task/s, elapsed: 54s, ETA:    48s[> ] 521/977, 9.6 task/s, elapsed: 54s, ETA:    47s[> ] 522/977, 9.6 task/s, elapsed: 54s, ETA:    47s[> ] 523/977, 9.6 task/s, elapsed: 54s, ETA:    47s[> ] 524/977, 9.6 task/s, elapsed: 54s, ETA:    47s[> ] 525/977, 9.6 task/s, elapsed: 55s, ETA:    47s[> ] 526/977, 9.6 task/s, elapsed: 55s, ETA:    47s[> ] 527/977, 9.6 task/s, elapsed: 55s, ETA:    47s[> ] 528/977, 9.6 task/s, elapsed: 55s, ETA:    47s[> ] 529/977, 9.6 task/s, elapsed: 55s, ETA:    47s[> ] 530/977, 9.6 task/s, elapsed: 55s, ETA:    46s[> ] 531/977, 9.6 task/s, elapsed: 55s, ETA:    46s[> ] 532/977, 9.6 task/s, elapsed: 55s, ETA:    46s[> ] 533/977, 9.6 task/s, elapsed: 55s, ETA:    46s[> ] 534/977, 9.6 task/s, elapsed: 56s, ETA:    46s[> ] 535/977, 9.6 task/s, elapsed: 56s, ETA:    46s[> ] 536/977, 9.6 task/s, elapsed: 56s, ETA:    46s[> ] 537/977, 9.6 task/s, elapsed: 56s, ETA:    46s[> ] 538/977, 9.6 task/s, elapsed: 56s, ETA:    46s[> ] 539/977, 9.6 task/s, elapsed: 56s, ETA:    46s[> ] 540/977, 9.6 task/s, elapsed: 56s, ETA:    45s[> ] 541/977, 9.6 task/s, elapsed: 56s, ETA:    45s[> ] 542/977, 9.6 task/s, elapsed: 56s, ETA:    45s[> ] 543/977, 9.6 task/s, elapsed: 56s, ETA:    45s[> ] 544/977, 9.6 task/s, elapsed: 57s, ETA:    45s[> ] 545/977, 9.6 task/s, elapsed: 57s, ETA:    45s[> ] 546/977, 9.6 task/s, elapsed: 57s, ETA:    45s[> ] 547/977, 9.6 task/s, elapsed: 57s, ETA:    45s[> ] 548/977, 9.6 task/s, elapsed: 57s, ETA:    45s[> ] 549/977, 9.6 task/s, elapsed: 57s, ETA:    44s[> ] 550/977, 9.6 task/s, elapsed: 57s, ETA:    44s[> ] 551/977, 9.6 task/s, elapsed: 57s, ETA:    44s[> ] 552/977, 9.6 task/s, elapsed: 57s, ETA:    44s[> ] 553/977, 9.6 task/s, elapsed: 57s, ETA:    44s[> ] 554/977, 9.6 task/s, elapsed: 58s, ETA:    44s[> ] 555/977, 9.6 task/s, elapsed: 58s, ETA:    44s[> ] 556/977, 9.6 task/s, elapsed: 58s, ETA:    44s[> ] 557/977, 9.6 task/s, elapsed: 58s, ETA:    44s[> ] 558/977, 9.6 task/s, elapsed: 58s, ETA:    44s[> ] 559/977, 9.6 task/s, elapsed: 58s, ETA:    43s[> ] 560/977, 9.6 task/s, elapsed: 58s, ETA:    43s[> ] 561/977, 9.6 task/s, elapsed: 58s, ETA:    43s[> ] 562/977, 9.6 task/s, elapsed: 58s, ETA:    43s[> ] 563/977, 9.6 task/s, elapsed: 58s, ETA:    43s[> ] 564/977, 9.6 task/s, elapsed: 59s, ETA:    43s[> ] 565/977, 9.6 task/s, elapsed: 59s, ETA:    43s[> ] 566/977, 9.6 task/s, elapsed: 59s, ETA:    43s[> ] 567/977, 9.6 task/s, elapsed: 59s, ETA:    43s[> ] 568/977, 9.6 task/s, elapsed: 59s, ETA:    42s[> ] 569/977, 9.6 task/s, elapsed: 59s, ETA:    42s[> ] 570/977, 9.6 task/s, elapsed: 59s, ETA:    42s[> ] 571/977, 9.6 task/s, elapsed: 59s, ETA:    42s[> ] 572/977, 9.6 task/s, elapsed: 59s, ETA:    42s[> ] 573/977, 9.6 task/s, elapsed: 60s, ETA:    42s[> ] 574/977, 9.6 task/s, elapsed: 60s, ETA:    42s[> ] 575/977, 9.6 task/s, elapsed: 60s, ETA:    42s[> ] 576/977, 9.6 task/s, elapsed: 60s, ETA:    42s[> ] 577/977, 9.6 task/s, elapsed: 60s, ETA:    42s[> ] 578/977, 9.6 task/s, elapsed: 60s, ETA:    41s[> ] 579/977, 9.6 task/s, elapsed: 60s, ETA:    41s[> ] 580/977, 9.6 task/s, elapsed: 60s, ETA:    41s[> ] 581/977, 9.6 task/s, elapsed: 60s, ETA:    41s[> ] 582/977, 9.6 task/s, elapsed: 60s, ETA:    41s[> ] 583/977, 9.6 task/s, elapsed: 61s, ETA:    41s[> ] 584/977, 9.6 task/s, elapsed: 61s, ETA:    41s[> ] 585/977, 9.6 task/s, elapsed: 61s, ETA:    41s[> ] 586/977, 9.6 task/s, elapsed: 61s, ETA:    41s[> ] 587/977, 9.6 task/s, elapsed: 61s, ETA:    40s[> ] 588/977, 9.6 task/s, elapsed: 61s, ETA:    40s[> ] 589/977, 9.6 task/s, elapsed: 61s, ETA:    40s[> ] 590/977, 9.6 task/s, elapsed: 61s, ETA:    40s[> ] 591/977, 9.6 task/s, elapsed: 61s, ETA:    40s[> ] 592/977, 9.6 task/s, elapsed: 61s, ETA:    40s[> ] 593/977, 9.6 task/s, elapsed: 62s, ETA:    40s[> ] 594/977, 9.6 task/s, elapsed: 62s, ETA:    40s[> ] 595/977, 9.6 task/s, elapsed: 62s, ETA:    40s[> ] 596/977, 9.6 task/s, elapsed: 62s, ETA:    40s[> ] 597/977, 9.6 task/s, elapsed: 62s, ETA:    39s[> ] 598/977, 9.6 task/s, elapsed: 62s, ETA:    39s[> ] 599/977, 9.6 task/s, elapsed: 62s, ETA:    39s[> ] 600/977, 9.6 task/s, elapsed: 62s, ETA:    39s[> ] 601/977, 9.6 task/s, elapsed: 62s, ETA:    39s[> ] 602/977, 9.6 task/s, elapsed: 62s, ETA:    39s[> ] 603/977, 9.6 task/s, elapsed: 63s, ETA:    39s[> ] 604/977, 9.6 task/s, elapsed: 63s, ETA:    39s[> ] 605/977, 9.6 task/s, elapsed: 63s, ETA:    39s[> ] 606/977, 9.6 task/s, elapsed: 63s, ETA:    38s[> ] 607/977, 9.6 task/s, elapsed: 63s, ETA:    38s[> ] 608/977, 9.6 task/s, elapsed: 63s, ETA:    38s[> ] 609/977, 9.6 task/s, elapsed: 63s, ETA:    38s[> ] 610/977, 9.6 task/s, elapsed: 63s, ETA:    38s[> ] 611/977, 9.6 task/s, elapsed: 63s, ETA:    38s[> ] 612/977, 9.6 task/s, elapsed: 64s, ETA:    38s[> ] 613/977, 9.6 task/s, elapsed: 64s, ETA:    38s[> ] 614/977, 9.6 task/s, elapsed: 64s, ETA:    38s[> ] 615/977, 9.6 task/s, elapsed: 64s, ETA:    38s[> ] 616/977, 9.6 task/s, elapsed: 64s, ETA:    37s[> ] 617/977, 9.6 task/s, elapsed: 64s, ETA:    37s[> ] 618/977, 9.6 task/s, elapsed: 64s, ETA:    37s[> ] 619/977, 9.6 task/s, elapsed: 64s, ETA:    37s[> ] 620/977, 9.6 task/s, elapsed: 64s, ETA:    37s[> ] 621/977, 9.6 task/s, elapsed: 64s, ETA:    37s[> ] 622/977, 9.6 task/s, elapsed: 65s, ETA:    37s[> ] 623/977, 9.6 task/s, elapsed: 65s, ETA:    37s[> ] 624/977, 9.6 task/s, elapsed: 65s, ETA:    37s[> ] 625/977, 9.6 task/s, elapsed: 65s, ETA:    37s[> ] 626/977, 9.6 task/s, elapsed: 65s, ETA:    36s[> ] 627/977, 9.6 task/s, elapsed: 65s, ETA:    36s[> ] 628/977, 9.6 task/s, elapsed: 65s, ETA:    36s[> ] 629/977, 9.6 task/s, elapsed: 65s, ETA:    36s[> ] 630/977, 9.6 task/s, elapsed: 65s, ETA:    36s[> ] 631/977, 9.6 task/s, elapsed: 65s, ETA:    36s[> ] 632/977, 9.6 task/s, elapsed: 66s, ETA:    36s[> ] 633/977, 9.6 task/s, elapsed: 66s, ETA:    36s[> ] 634/977, 9.6 task/s, elapsed: 66s, ETA:    36s[> ] 635/977, 9.6 task/s, elapsed: 66s, ETA:    35s[> ] 636/977, 9.6 task/s, elapsed: 66s, ETA:    35s[> ] 637/977, 9.6 task/s, elapsed: 66s, ETA:    35s[> ] 638/977, 9.6 task/s, elapsed: 66s, ETA:    35s[> ] 639/977, 9.6 task/s, elapsed: 66s, ETA:    35s[> ] 640/977, 9.6 task/s, elapsed: 66s, ETA:    35s[> ] 641/977, 9.6 task/s, elapsed: 66s, ETA:    35s[> ] 642/977, 9.6 task/s, elapsed: 67s, ETA:    35s[> ] 643/977, 9.6 task/s, elapsed: 67s, ETA:    35s[> ] 644/977, 9.6 task/s, elapsed: 67s, ETA:    35s[> ] 645/977, 9.6 task/s, elapsed: 67s, ETA:    34s[> ] 646/977, 9.6 task/s, elapsed: 67s, ETA:    34s[> ] 647/977, 9.6 task/s, elapsed: 67s, ETA:    34s[> ] 648/977, 9.6 task/s, elapsed: 67s, ETA:    34s[> ] 649/977, 9.6 task/s, elapsed: 67s, ETA:    34s[> ] 650/977, 9.6 task/s, elapsed: 67s, ETA:    34s[> ] 651/977, 9.6 task/s, elapsed: 68s, ETA:    34s[> ] 652/977, 9.6 task/s, elapsed: 68s, ETA:    34s[> ] 653/977, 9.6 task/s, elapsed: 68s, ETA:    34s[> ] 654/977, 9.6 task/s, elapsed: 68s, ETA:    34s[> ] 655/977, 9.6 task/s, elapsed: 68s, ETA:    33s[> ] 656/977, 9.6 task/s, elapsed: 68s, ETA:    33s[> ] 657/977, 9.6 task/s, elapsed: 68s, ETA:    33s[> ] 658/977, 9.6 task/s, elapsed: 68s, ETA:    33s[> ] 659/977, 9.6 task/s, elapsed: 68s, ETA:    33s[> ] 660/977, 9.6 task/s, elapsed: 68s, ETA:    33s[> ] 661/977, 9.6 task/s, elapsed: 69s, ETA:    33s[> ] 662/977, 9.6 task/s, elapsed: 69s, ETA:    33s[> ] 663/977, 9.6 task/s, elapsed: 69s, ETA:    33s[> ] 664/977, 9.6 task/s, elapsed: 69s, ETA:    32s[> ] 665/977, 9.6 task/s, elapsed: 69s, ETA:    32s[> ] 666/977, 9.6 task/s, elapsed: 69s, ETA:    32s[> ] 667/977, 9.6 task/s, elapsed: 69s, ETA:    32s[> ] 668/977, 9.6 task/s, elapsed: 69s, ETA:    32s[> ] 669/977, 9.6 task/s, elapsed: 69s, ETA:    32s[> ] 670/977, 9.6 task/s, elapsed: 69s, ETA:    32s[> ] 671/977, 9.6 task/s, elapsed: 70s, ETA:    32s[> ] 672/977, 9.6 task/s, elapsed: 70s, ETA:    32s[> ] 673/977, 9.6 task/s, elapsed: 70s, ETA:    32s[> ] 674/977, 9.6 task/s, elapsed: 70s, ETA:    31s[> ] 675/977, 9.6 task/s, elapsed: 70s, ETA:    31s[> ] 676/977, 9.6 task/s, elapsed: 70s, ETA:    31s[> ] 677/977, 9.6 task/s, elapsed: 70s, ETA:    31s[> ] 678/977, 9.6 task/s, elapsed: 70s, ETA:    31s[> ] 679/977, 9.6 task/s, elapsed: 70s, ETA:    31s[> ] 680/977, 9.6 task/s, elapsed: 71s, ETA:    31s[> ] 681/977, 9.6 task/s, elapsed: 71s, ETA:    31s[> ] 682/977, 9.6 task/s, elapsed: 71s, ETA:    31s[> ] 683/977, 9.6 task/s, elapsed: 71s, ETA:    30s[> ] 684/977, 9.6 task/s, elapsed: 71s, ETA:    30s[> ] 685/977, 9.6 task/s, elapsed: 71s, ETA:    30s[> ] 686/977, 9.6 task/s, elapsed: 71s, ETA:    30s[> ] 687/977, 9.6 task/s, elapsed: 71s, ETA:    30s[> ] 688/977, 9.6 task/s, elapsed: 71s, ETA:    30s[> ] 689/977, 9.6 task/s, elapsed: 71s, ETA:    30s[> ] 690/977, 9.6 task/s, elapsed: 72s, ETA:    30s[> ] 691/977, 9.6 task/s, elapsed: 72s, ETA:    30s[> ] 692/977, 9.6 task/s, elapsed: 72s, ETA:    30s[> ] 693/977, 9.6 task/s, elapsed: 72s, ETA:    29s[> ] 694/977, 9.6 task/s, elapsed: 72s, ETA:    29s[> ] 695/977, 9.6 task/s, elapsed: 72s, ETA:    29s[> ] 696/977, 9.6 task/s, elapsed: 72s, ETA:    29s[> ] 697/977, 9.6 task/s, elapsed: 72s, ETA:    29s[> ] 698/977, 9.6 task/s, elapsed: 72s, ETA:    29s[> ] 699/977, 9.6 task/s, elapsed: 72s, ETA:    29s[> ] 700/977, 9.6 task/s, elapsed: 73s, ETA:    29s[> ] 701/977, 9.6 task/s, elapsed: 73s, ETA:    29s[> ] 702/977, 9.6 task/s, elapsed: 73s, ETA:    29s[> ] 703/977, 9.6 task/s, elapsed: 73s, ETA:    28s[> ] 704/977, 9.6 task/s, elapsed: 73s, ETA:    28s[> ] 705/977, 9.6 task/s, elapsed: 73s, ETA:    28s[> ] 706/977, 9.6 task/s, elapsed: 73s, ETA:    28s[> ] 707/977, 9.6 task/s, elapsed: 73s, ETA:    28s[> ] 708/977, 9.6 task/s, elapsed: 73s, ETA:    28s[> ] 709/977, 9.6 task/s, elapsed: 73s, ETA:    28s[> ] 710/977, 9.6 task/s, elapsed: 74s, ETA:    28s[> ] 711/977, 9.6 task/s, elapsed: 74s, ETA:    28s[> ] 712/977, 9.6 task/s, elapsed: 74s, ETA:    27s[> ] 713/977, 9.6 task/s, elapsed: 74s, ETA:    27s[> ] 714/977, 9.6 task/s, elapsed: 74s, ETA:    27s[> ] 715/977, 9.6 task/s, elapsed: 74s, ETA:    27s[> ] 716/977, 9.6 task/s, elapsed: 74s, ETA:    27s[> ] 717/977, 9.6 task/s, elapsed: 74s, ETA:    27s[> ] 718/977, 9.6 task/s, elapsed: 74s, ETA:    27s[> ] 719/977, 9.6 task/s, elapsed: 75s, ETA:    27s[> ] 720/977, 9.6 task/s, elapsed: 75s, ETA:    27s[> ] 721/977, 9.7 task/s, elapsed: 75s, ETA:    27s[> ] 722/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 723/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 724/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 725/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 726/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 727/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 728/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 729/977, 9.7 task/s, elapsed: 76s, ETA:    26s[> ] 730/977, 9.7 task/s, elapsed: 76s, ETA:    26s[> ] 731/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 732/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 733/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 734/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 735/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 736/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 737/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 738/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 739/977, 9.7 task/s, elapsed: 77s, ETA:    25s[> ] 740/977, 9.7 task/s, elapsed: 77s, ETA:    25s[> ] 741/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 742/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 743/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 744/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 745/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 746/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 747/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 748/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 749/977, 9.7 task/s, elapsed: 78s, ETA:    24s[> ] 750/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 751/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 752/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 753/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 754/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 755/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 756/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 757/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 758/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 759/977, 9.7 task/s, elapsed: 79s, ETA:    23s[> ] 760/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 761/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 762/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 763/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 764/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 765/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 766/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 767/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 768/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 769/977, 9.7 task/s, elapsed: 80s, ETA:    22s[> ] 770/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 771/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 772/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 773/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 774/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 775/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 776/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 777/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 778/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 779/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 780/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 781/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 782/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 783/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 784/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 785/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 786/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 787/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 788/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 789/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 790/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 791/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 792/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 793/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 794/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 795/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 796/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 797/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 798/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 799/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 800/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 801/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 802/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 803/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 804/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 805/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 806/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 807/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 808/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 809/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 810/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 811/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 812/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 813/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 814/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 815/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 816/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 817/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 818/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 819/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 820/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 821/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 822/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 823/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 824/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 825/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 826/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 827/977, 9.7 task/s, elapsed: 86s, ETA:    16s[> ] 828/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 829/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 830/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 831/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 832/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 833/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 834/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 835/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 836/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 837/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 838/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 839/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 840/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 841/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 842/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 843/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 844/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 845/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 846/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 847/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 848/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 849/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 850/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 851/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 852/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 853/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 854/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 855/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 856/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 857/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 858/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 859/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 860/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 861/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 862/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 863/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 864/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 865/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 866/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 867/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 868/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 869/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 870/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 871/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 872/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 873/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 874/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 875/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 876/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 877/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 878/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 879/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 880/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 881/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 882/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 883/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 884/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 885/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 886/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 887/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 888/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 889/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 890/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 891/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 892/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 893/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 894/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 895/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 896/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 897/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 898/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 899/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 900/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 901/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 902/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 903/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 904/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 905/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 906/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 907/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 908/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 909/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 910/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 911/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 912/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 913/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 914/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 915/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 916/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 917/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 918/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 919/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 920/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 921/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 922/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 923/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 924/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 925/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 926/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 927/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 928/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 929/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 930/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 931/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 932/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 933/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 934/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 935/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 936/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 937/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 938/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 939/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 940/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 941/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 942/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 943/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 944/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 945/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 946/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 947/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 948/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 949/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 950/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 951/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 952/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 953/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 954/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 955/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 956/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 957/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 958/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 959/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 960/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 961/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 962/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 963/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 964/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 965/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 966/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 967/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 968/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 969/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 970/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 971/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 972/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 973/977, 9.7 task/s, elapsed: 101s, ETA:     0s[> ] 974/977, 9.7 task/s, elapsed: 101s, ETA:     0s[> ] 975/977, 9.7 task/s, elapsed: 101s, ETA:     0s[> ] 976/977, 9.7 task/s, elapsed: 101s, ETA:     0s[>>] 977/977, 9.7 task/s, elapsed: 101s, ETA:     0s2021-09-29 13:04:09,887 - mmdet - INFO - Evaluating bbox...
2021-09-29 13:04:11,468 - mmdet - INFO - Exp name: waste_hrnet_16.py
2021-09-29 13:04:11,470 - mmdet - INFO - Epoch(val) [1][977]	bbox_mAP: 0.0020, bbox_mAP_50: 0.0080, bbox_mAP_75: 0.0010, bbox_mAP_s: 0.0000, bbox_mAP_m: 0.0000, bbox_mAP_l: 0.0030, bbox_mAP_copypaste: 0.002 0.008 0.001 0.000 0.000 0.003
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=1.25s).
Accumulating evaluation results...
DONE (t=0.28s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.008
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.003
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.010
2021-09-29 13:04:42,088 - mmdet - INFO - Epoch [2][10/245]	lr: 5.567e-05, eta: 9:09:58, time: 3.059, data_time: 0.300, memory: 29438, loss_rpn_cls: 0.1127, loss_rpn_bbox: 0.1801, s0.loss_cls: 0.2318, s0.acc: 94.7583, s0.loss_bbox: 0.1066, s1.loss_cls: 0.0476, s1.acc: 98.1079, s1.loss_bbox: 0.0240, s2.loss_cls: 0.0134, s2.acc: 98.8977, s2.loss_bbox: 0.0087, loss: 0.7249, grad_norm: 2.0679
2021-09-29 13:05:10,653 - mmdet - INFO - Epoch [2][20/245]	lr: 5.746e-05, eta: 9:10:19, time: 2.857, data_time: 0.030, memory: 29438, loss_rpn_cls: 0.1034, loss_rpn_bbox: 0.1658, s0.loss_cls: 0.2434, s0.acc: 94.4202, s0.loss_bbox: 0.1125, s1.loss_cls: 0.0480, s1.acc: 98.0920, s1.loss_bbox: 0.0242, s2.loss_cls: 0.0148, s2.acc: 98.8147, s2.loss_bbox: 0.0093, loss: 0.7213, grad_norm: 2.7979
2021-09-29 13:05:38,926 - mmdet - INFO - Epoch [2][30/245]	lr: 5.926e-05, eta: 9:10:22, time: 2.827, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1019, loss_rpn_bbox: 0.1532, s0.loss_cls: 0.2332, s0.acc: 94.8840, s0.loss_bbox: 0.1039, s1.loss_cls: 0.0486, s1.acc: 98.1421, s1.loss_bbox: 0.0231, s2.loss_cls: 0.0144, s2.acc: 98.9380, s2.loss_bbox: 0.0076, loss: 0.6859, grad_norm: 3.4496
2021-09-29 13:06:06,712 - mmdet - INFO - Epoch [2][40/245]	lr: 6.106e-05, eta: 9:10:04, time: 2.778, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1130, loss_rpn_bbox: 0.1745, s0.loss_cls: 0.2711, s0.acc: 94.1736, s0.loss_bbox: 0.1180, s1.loss_cls: 0.0624, s1.acc: 97.6196, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0196, s2.acc: 98.5852, s2.loss_bbox: 0.0110, loss: 0.7996, grad_norm: 2.6623
2021-09-29 13:06:34,417 - mmdet - INFO - Epoch [2][50/245]	lr: 6.286e-05, eta: 9:09:41, time: 2.771, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1056, loss_rpn_bbox: 0.1647, s0.loss_cls: 0.2173, s0.acc: 95.3540, s0.loss_bbox: 0.0967, s1.loss_cls: 0.0520, s1.acc: 97.8259, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0155, s2.acc: 98.7732, s2.loss_bbox: 0.0098, loss: 0.6889, grad_norm: 2.0302
2021-09-29 13:07:02,406 - mmdet - INFO - Epoch [2][60/245]	lr: 6.466e-05, eta: 9:09:29, time: 2.799, data_time: 0.029, memory: 29438, loss_rpn_cls: 0.1012, loss_rpn_bbox: 0.1644, s0.loss_cls: 0.2313, s0.acc: 95.0330, s0.loss_bbox: 0.1010, s1.loss_cls: 0.0546, s1.acc: 97.8381, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0169, s2.acc: 98.6768, s2.loss_bbox: 0.0104, loss: 0.7073, grad_norm: 2.3729
2021-09-29 13:07:30,437 - mmdet - INFO - Epoch [2][70/245]	lr: 6.645e-05, eta: 9:09:18, time: 2.803, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1067, loss_rpn_bbox: 0.1866, s0.loss_cls: 0.2352, s0.acc: 94.7473, s0.loss_bbox: 0.1071, s1.loss_cls: 0.0539, s1.acc: 97.7747, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0157, s2.acc: 98.7256, s2.loss_bbox: 0.0100, loss: 0.7434, grad_norm: 1.9975
2021-09-29 13:07:58,339 - mmdet - INFO - Epoch [2][80/245]	lr: 6.825e-05, eta: 9:09:01, time: 2.790, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.1159, loss_rpn_bbox: 0.1869, s0.loss_cls: 0.2266, s0.acc: 95.0464, s0.loss_bbox: 0.0997, s1.loss_cls: 0.0553, s1.acc: 97.8528, s1.loss_bbox: 0.0270, s2.loss_cls: 0.0153, s2.acc: 98.7988, s2.loss_bbox: 0.0096, loss: 0.7362, grad_norm: 1.9898
2021-09-29 13:08:25,635 - mmdet - INFO - Epoch [2][90/245]	lr: 7.005e-05, eta: 9:08:21, time: 2.730, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1113, loss_rpn_bbox: 0.1899, s0.loss_cls: 0.2443, s0.acc: 94.8303, s0.loss_bbox: 0.1051, s1.loss_cls: 0.0630, s1.acc: 97.6770, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0170, s2.acc: 98.6975, s2.loss_bbox: 0.0105, loss: 0.7708, grad_norm: 2.3317
2021-09-29 13:08:53,274 - mmdet - INFO - Epoch [2][100/245]	lr: 7.185e-05, eta: 9:07:55, time: 2.764, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.0922, loss_rpn_bbox: 0.1750, s0.loss_cls: 0.2428, s0.acc: 94.6143, s0.loss_bbox: 0.1095, s1.loss_cls: 0.0648, s1.acc: 97.5415, s1.loss_bbox: 0.0304, s2.loss_cls: 0.0185, s2.acc: 98.6633, s2.loss_bbox: 0.0105, loss: 0.7437, grad_norm: 2.3884
2021-09-29 13:09:21,429 - mmdet - INFO - Epoch [2][110/245]	lr: 7.365e-05, eta: 9:07:45, time: 2.815, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0956, loss_rpn_bbox: 0.1562, s0.loss_cls: 0.2231, s0.acc: 95.1062, s0.loss_bbox: 0.1005, s1.loss_cls: 0.0537, s1.acc: 97.8247, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0132, s2.acc: 98.9014, s2.loss_bbox: 0.0085, loss: 0.6773, grad_norm: 2.4533
2021-09-29 13:09:50,054 - mmdet - INFO - Epoch [2][120/245]	lr: 7.545e-05, eta: 9:07:50, time: 2.862, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0954, loss_rpn_bbox: 0.1761, s0.loss_cls: 0.2261, s0.acc: 95.1306, s0.loss_bbox: 0.0984, s1.loss_cls: 0.0576, s1.acc: 97.6465, s1.loss_bbox: 0.0294, s2.loss_cls: 0.0168, s2.acc: 98.6401, s2.loss_bbox: 0.0105, loss: 0.7104, grad_norm: 1.9125
2021-09-29 13:10:18,153 - mmdet - INFO - Epoch [2][130/245]	lr: 7.724e-05, eta: 9:07:36, time: 2.810, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0910, loss_rpn_bbox: 0.1729, s0.loss_cls: 0.2126, s0.acc: 95.1245, s0.loss_bbox: 0.0998, s1.loss_cls: 0.0552, s1.acc: 97.7612, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0159, s2.acc: 98.7097, s2.loss_bbox: 0.0105, loss: 0.6864, grad_norm: 1.6674
2021-09-29 13:10:46,101 - mmdet - INFO - Epoch [2][140/245]	lr: 7.904e-05, eta: 9:07:17, time: 2.795, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0957, loss_rpn_bbox: 0.1885, s0.loss_cls: 0.2161, s0.acc: 94.9255, s0.loss_bbox: 0.1028, s1.loss_cls: 0.0504, s1.acc: 97.9895, s1.loss_bbox: 0.0258, s2.loss_cls: 0.0142, s2.acc: 98.8574, s2.loss_bbox: 0.0095, loss: 0.7029, grad_norm: 1.7288
2021-09-29 13:11:14,057 - mmdet - INFO - Epoch [2][150/245]	lr: 8.084e-05, eta: 9:06:58, time: 2.796, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1285, loss_rpn_bbox: 0.2284, s0.loss_cls: 0.2296, s0.acc: 94.5032, s0.loss_bbox: 0.1128, s1.loss_cls: 0.0552, s1.acc: 97.8064, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0179, s2.acc: 98.5583, s2.loss_bbox: 0.0122, loss: 0.8135, grad_norm: 1.6658
2021-09-29 13:11:41,994 - mmdet - INFO - Epoch [2][160/245]	lr: 8.264e-05, eta: 9:06:38, time: 2.794, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1076, loss_rpn_bbox: 0.1791, s0.loss_cls: 0.2024, s0.acc: 95.4700, s0.loss_bbox: 0.0929, s1.loss_cls: 0.0532, s1.acc: 97.8906, s1.loss_bbox: 0.0271, s2.loss_cls: 0.0169, s2.acc: 98.6597, s2.loss_bbox: 0.0108, loss: 0.6900, grad_norm: 1.9855
2021-09-29 13:12:09,645 - mmdet - INFO - Epoch [2][170/245]	lr: 8.444e-05, eta: 9:06:09, time: 2.765, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0986, loss_rpn_bbox: 0.1706, s0.loss_cls: 0.1926, s0.acc: 95.6702, s0.loss_bbox: 0.0881, s1.loss_cls: 0.0466, s1.acc: 98.0859, s1.loss_bbox: 0.0247, s2.loss_cls: 0.0142, s2.acc: 98.8635, s2.loss_bbox: 0.0095, loss: 0.6449, grad_norm: 1.7864
2021-09-29 13:12:37,393 - mmdet - INFO - Epoch [2][180/245]	lr: 8.623e-05, eta: 9:05:43, time: 2.775, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1100, loss_rpn_bbox: 0.1883, s0.loss_cls: 0.2295, s0.acc: 94.7131, s0.loss_bbox: 0.1082, s1.loss_cls: 0.0570, s1.acc: 97.7380, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0174, s2.acc: 98.6499, s2.loss_bbox: 0.0110, loss: 0.7506, grad_norm: 1.9320
2021-09-29 13:13:04,700 - mmdet - INFO - Epoch [2][190/245]	lr: 8.803e-05, eta: 9:05:05, time: 2.731, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0821, loss_rpn_bbox: 0.1636, s0.loss_cls: 0.1943, s0.acc: 95.7812, s0.loss_bbox: 0.0886, s1.loss_cls: 0.0434, s1.acc: 98.2910, s1.loss_bbox: 0.0224, s2.loss_cls: 0.0126, s2.acc: 98.9819, s2.loss_bbox: 0.0084, loss: 0.6155, grad_norm: 1.5851
2021-09-29 13:13:32,750 - mmdet - INFO - Epoch [2][200/245]	lr: 8.983e-05, eta: 9:04:47, time: 2.805, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1133, loss_rpn_bbox: 0.1930, s0.loss_cls: 0.2167, s0.acc: 95.3662, s0.loss_bbox: 0.0964, s1.loss_cls: 0.0547, s1.acc: 97.9028, s1.loss_bbox: 0.0270, s2.loss_cls: 0.0153, s2.acc: 98.7439, s2.loss_bbox: 0.0101, loss: 0.7265, grad_norm: 2.1860
2021-09-29 13:14:00,810 - mmdet - INFO - Epoch [2][210/245]	lr: 9.163e-05, eta: 9:04:29, time: 2.806, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0904, loss_rpn_bbox: 0.1596, s0.loss_cls: 0.1797, s0.acc: 95.8569, s0.loss_bbox: 0.0848, s1.loss_cls: 0.0452, s1.acc: 98.1311, s1.loss_bbox: 0.0241, s2.loss_cls: 0.0130, s2.acc: 98.9221, s2.loss_bbox: 0.0087, loss: 0.6054, grad_norm: 1.6717
2021-09-29 13:14:28,452 - mmdet - INFO - Epoch [2][220/245]	lr: 9.343e-05, eta: 9:04:00, time: 2.764, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1040, loss_rpn_bbox: 0.2079, s0.loss_cls: 0.2152, s0.acc: 95.0916, s0.loss_bbox: 0.1011, s1.loss_cls: 0.0560, s1.acc: 97.7551, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0174, s2.acc: 98.6011, s2.loss_bbox: 0.0117, loss: 0.7425, grad_norm: 1.6396
2021-09-29 13:14:56,407 - mmdet - INFO - Epoch [2][230/245]	lr: 9.523e-05, eta: 9:03:38, time: 2.795, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0844, loss_rpn_bbox: 0.1600, s0.loss_cls: 0.1993, s0.acc: 95.7227, s0.loss_bbox: 0.0888, s1.loss_cls: 0.0527, s1.acc: 97.8638, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0146, s2.acc: 98.7866, s2.loss_bbox: 0.0099, loss: 0.6368, grad_norm: 1.8847
2021-09-29 13:15:24,468 - mmdet - INFO - Epoch [2][240/245]	lr: 9.702e-05, eta: 9:03:19, time: 2.806, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0908, loss_rpn_bbox: 0.1676, s0.loss_cls: 0.2053, s0.acc: 95.4553, s0.loss_bbox: 0.0922, s1.loss_cls: 0.0542, s1.acc: 97.8577, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0174, s2.acc: 98.6914, s2.loss_bbox: 0.0103, loss: 0.6652, grad_norm: 2.0016
2021-09-29 13:15:38,132 - mmdet - INFO - Saving checkpoint at 2 epochs
[                                                  ] 0/977, elapsed: 0s, ETA:[  ] 1/977, 4.2 task/s, elapsed: 0s, ETA:   235s[  ] 2/977, 5.8 task/s, elapsed: 0s, ETA:   169s[  ] 3/977, 6.7 task/s, elapsed: 0s, ETA:   146s[  ] 4/977, 7.3 task/s, elapsed: 1s, ETA:   133s[  ] 5/977, 7.8 task/s, elapsed: 1s, ETA:   125s[  ] 6/977, 8.1 task/s, elapsed: 1s, ETA:   120s[  ] 7/977, 8.3 task/s, elapsed: 1s, ETA:   116s[  ] 8/977, 8.5 task/s, elapsed: 1s, ETA:   114s[  ] 9/977, 8.6 task/s, elapsed: 1s, ETA:   112s[  ] 10/977, 8.8 task/s, elapsed: 1s, ETA:   110s[  ] 11/977, 8.9 task/s, elapsed: 1s, ETA:   109s[  ] 12/977, 9.0 task/s, elapsed: 1s, ETA:   108s[  ] 13/977, 9.0 task/s, elapsed: 1s, ETA:   107s[  ] 14/977, 9.1 task/s, elapsed: 2s, ETA:   106s[  ] 15/977, 9.2 task/s, elapsed: 2s, ETA:   105s[  ] 16/977, 9.2 task/s, elapsed: 2s, ETA:   104s[  ] 17/977, 9.3 task/s, elapsed: 2s, ETA:   103s[  ] 18/977, 9.3 task/s, elapsed: 2s, ETA:   103s[  ] 19/977, 9.4 task/s, elapsed: 2s, ETA:   102s[  ] 20/977, 9.4 task/s, elapsed: 2s, ETA:   102s[  ] 21/977, 9.5 task/s, elapsed: 2s, ETA:   101s[  ] 22/977, 9.5 task/s, elapsed: 2s, ETA:   101s[  ] 23/977, 9.5 task/s, elapsed: 2s, ETA:   100s[  ] 24/977, 9.5 task/s, elapsed: 3s, ETA:   100s[  ] 25/977, 9.6 task/s, elapsed: 3s, ETA:   100s[  ] 26/977, 9.6 task/s, elapsed: 3s, ETA:    99s[  ] 27/977, 9.6 task/s, elapsed: 3s, ETA:    99s[  ] 28/977, 9.6 task/s, elapsed: 3s, ETA:    99s[  ] 29/977, 9.6 task/s, elapsed: 3s, ETA:    99s[  ] 30/977, 9.6 task/s, elapsed: 3s, ETA:    98s[  ] 31/977, 9.6 task/s, elapsed: 3s, ETA:    98s[  ] 32/977, 9.7 task/s, elapsed: 3s, ETA:    98s[  ] 33/977, 9.7 task/s, elapsed: 3s, ETA:    98s[  ] 34/977, 9.7 task/s, elapsed: 4s, ETA:    97s[  ] 35/977, 9.7 task/s, elapsed: 4s, ETA:    97s[  ] 36/977, 9.7 task/s, elapsed: 4s, ETA:    97s[  ] 37/977, 9.7 task/s, elapsed: 4s, ETA:    97s[  ] 38/977, 9.7 task/s, elapsed: 4s, ETA:    96s[  ] 39/977, 9.7 task/s, elapsed: 4s, ETA:    96s[  ] 40/977, 9.7 task/s, elapsed: 4s, ETA:    97s[  ] 41/977, 9.7 task/s, elapsed: 4s, ETA:    96s[  ] 42/977, 9.7 task/s, elapsed: 4s, ETA:    96s[  ] 43/977, 9.7 task/s, elapsed: 4s, ETA:    96s[  ] 44/977, 9.7 task/s, elapsed: 5s, ETA:    96s[  ] 45/977, 9.7 task/s, elapsed: 5s, ETA:    96s[  ] 46/977, 9.7 task/s, elapsed: 5s, ETA:    96s[  ] 47/977, 9.7 task/s, elapsed: 5s, ETA:    96s[  ] 48/977, 9.7 task/s, elapsed: 5s, ETA:    95s[  ] 49/977, 9.7 task/s, elapsed: 5s, ETA:    95s[  ] 50/977, 9.7 task/s, elapsed: 5s, ETA:    95s[  ] 51/977, 9.7 task/s, elapsed: 5s, ETA:    95s[  ] 52/977, 9.7 task/s, elapsed: 5s, ETA:    95s[  ] 53/977, 9.8 task/s, elapsed: 5s, ETA:    95s[  ] 54/977, 9.7 task/s, elapsed: 6s, ETA:    95s[  ] 55/977, 9.8 task/s, elapsed: 6s, ETA:    95s[  ] 56/977, 9.8 task/s, elapsed: 6s, ETA:    94s[  ] 57/977, 9.8 task/s, elapsed: 6s, ETA:    94s[  ] 58/977, 9.8 task/s, elapsed: 6s, ETA:    94s[  ] 59/977, 9.8 task/s, elapsed: 6s, ETA:    94s[  ] 60/977, 9.8 task/s, elapsed: 6s, ETA:    94s[  ] 61/977, 9.8 task/s, elapsed: 6s, ETA:    94s[  ] 62/977, 9.8 task/s, elapsed: 6s, ETA:    93s[  ] 63/977, 9.8 task/s, elapsed: 6s, ETA:    93s[  ] 64/977, 9.8 task/s, elapsed: 7s, ETA:    93s[  ] 65/977, 9.8 task/s, elapsed: 7s, ETA:    93s[  ] 66/977, 9.8 task/s, elapsed: 7s, ETA:    93s[  ] 67/977, 9.8 task/s, elapsed: 7s, ETA:    93s[  ] 68/977, 9.8 task/s, elapsed: 7s, ETA:    92s[  ] 69/977, 9.8 task/s, elapsed: 7s, ETA:    92s[  ] 70/977, 9.8 task/s, elapsed: 7s, ETA:    92s[  ] 71/977, 9.8 task/s, elapsed: 7s, ETA:    92s[  ] 72/977, 9.8 task/s, elapsed: 7s, ETA:    92s[  ] 73/977, 9.8 task/s, elapsed: 7s, ETA:    92s[  ] 74/977, 9.8 task/s, elapsed: 8s, ETA:    92s[  ] 75/977, 9.8 task/s, elapsed: 8s, ETA:    92s[  ] 76/977, 9.9 task/s, elapsed: 8s, ETA:    91s[  ] 77/977, 9.9 task/s, elapsed: 8s, ETA:    91s[  ] 78/977, 9.9 task/s, elapsed: 8s, ETA:    91s[  ] 79/977, 9.9 task/s, elapsed: 8s, ETA:    91s[  ] 80/977, 9.9 task/s, elapsed: 8s, ETA:    91s[  ] 81/977, 9.9 task/s, elapsed: 8s, ETA:    91s[  ] 82/977, 9.9 task/s, elapsed: 8s, ETA:    91s[  ] 83/977, 9.9 task/s, elapsed: 8s, ETA:    91s[  ] 84/977, 9.9 task/s, elapsed: 9s, ETA:    90s[  ] 85/977, 9.9 task/s, elapsed: 9s, ETA:    90s[  ] 86/977, 9.9 task/s, elapsed: 9s, ETA:    90s[  ] 87/977, 9.9 task/s, elapsed: 9s, ETA:    90s[  ] 88/977, 9.9 task/s, elapsed: 9s, ETA:    90s[  ] 89/977, 9.9 task/s, elapsed: 9s, ETA:    90s[  ] 90/977, 9.9 task/s, elapsed: 9s, ETA:    90s[  ] 91/977, 9.9 task/s, elapsed: 9s, ETA:    90s[  ] 92/977, 9.9 task/s, elapsed: 9s, ETA:    89s[  ] 93/977, 9.9 task/s, elapsed: 9s, ETA:    89s[  ] 94/977, 9.9 task/s, elapsed: 9s, ETA:    89s[  ] 95/977, 9.9 task/s, elapsed: 10s, ETA:    89s[  ] 96/977, 9.9 task/s, elapsed: 10s, ETA:    89s[  ] 97/977, 9.9 task/s, elapsed: 10s, ETA:    89s[  ] 98/977, 9.9 task/s, elapsed: 10s, ETA:    89s[  ] 99/977, 9.9 task/s, elapsed: 10s, ETA:    89s[  ] 100/977, 9.9 task/s, elapsed: 10s, ETA:    88s[  ] 101/977, 9.9 task/s, elapsed: 10s, ETA:    88s[  ] 102/977, 9.9 task/s, elapsed: 10s, ETA:    88s[  ] 103/977, 9.9 task/s, elapsed: 10s, ETA:    88s[  ] 104/977, 9.9 task/s, elapsed: 10s, ETA:    88s[  ] 105/977, 9.9 task/s, elapsed: 11s, ETA:    88s[  ] 106/977, 9.9 task/s, elapsed: 11s, ETA:    88s[  ] 107/977, 9.9 task/s, elapsed: 11s, ETA:    88s[  ] 108/977, 9.9 task/s, elapsed: 11s, ETA:    88s[  ] 109/977, 9.9 task/s, elapsed: 11s, ETA:    88s[  ] 110/977, 9.9 task/s, elapsed: 11s, ETA:    87s[  ] 111/977, 9.9 task/s, elapsed: 11s, ETA:    87s[  ] 112/977, 9.9 task/s, elapsed: 11s, ETA:    87s[  ] 113/977, 9.9 task/s, elapsed: 11s, ETA:    87s[  ] 114/977, 9.9 task/s, elapsed: 12s, ETA:    87s[  ] 115/977, 9.9 task/s, elapsed: 12s, ETA:    87s[  ] 116/977, 9.9 task/s, elapsed: 12s, ETA:    87s[  ] 117/977, 9.9 task/s, elapsed: 12s, ETA:    87s[  ] 118/977, 9.9 task/s, elapsed: 12s, ETA:    87s[  ] 119/977, 9.9 task/s, elapsed: 12s, ETA:    86s[  ] 120/977, 9.9 task/s, elapsed: 12s, ETA:    86s[  ] 121/977, 9.9 task/s, elapsed: 12s, ETA:    86s[  ] 122/977, 9.9 task/s, elapsed: 12s, ETA:    86s[  ] 123/977, 9.9 task/s, elapsed: 12s, ETA:    86s[  ] 124/977, 9.9 task/s, elapsed: 12s, ETA:    86s[  ] 125/977, 9.9 task/s, elapsed: 13s, ETA:    86s[  ] 126/977, 9.9 task/s, elapsed: 13s, ETA:    86s[  ] 127/977, 9.9 task/s, elapsed: 13s, ETA:    86s[  ] 128/977, 9.9 task/s, elapsed: 13s, ETA:    85s[  ] 129/977, 9.9 task/s, elapsed: 13s, ETA:    85s[  ] 130/977, 9.9 task/s, elapsed: 13s, ETA:    85s[  ] 131/977, 9.9 task/s, elapsed: 13s, ETA:    85s[  ] 132/977, 9.9 task/s, elapsed: 13s, ETA:    85s[  ] 133/977, 9.9 task/s, elapsed: 13s, ETA:    85s[  ] 134/977, 9.9 task/s, elapsed: 13s, ETA:    85s[  ] 135/977, 9.9 task/s, elapsed: 14s, ETA:    85s[  ] 136/977, 9.9 task/s, elapsed: 14s, ETA:    85s[  ] 137/977, 9.9 task/s, elapsed: 14s, ETA:    84s[  ] 138/977, 9.9 task/s, elapsed: 14s, ETA:    84s[  ] 139/977, 9.9 task/s, elapsed: 14s, ETA:    84s[  ] 140/977, 9.9 task/s, elapsed: 14s, ETA:    84s[  ] 141/977, 9.9 task/s, elapsed: 14s, ETA:    84s[  ] 142/977, 9.9 task/s, elapsed: 14s, ETA:    84s[  ] 143/977, 9.9 task/s, elapsed: 14s, ETA:    84s[  ] 144/977, 9.9 task/s, elapsed: 14s, ETA:    84s[  ] 145/977, 9.9 task/s, elapsed: 15s, ETA:    84s[  ] 146/977, 10.0 task/s, elapsed: 15s, ETA:    84s[  ] 147/977, 9.9 task/s, elapsed: 15s, ETA:    83s[  ] 148/977, 9.9 task/s, elapsed: 15s, ETA:    83s[  ] 149/977, 9.9 task/s, elapsed: 15s, ETA:    83s[  ] 150/977, 9.9 task/s, elapsed: 15s, ETA:    83s[  ] 151/977, 9.9 task/s, elapsed: 15s, ETA:    83s[  ] 152/977, 10.0 task/s, elapsed: 15s, ETA:    83s[  ] 153/977, 10.0 task/s, elapsed: 15s, ETA:    83s[  ] 154/977, 10.0 task/s, elapsed: 15s, ETA:    83s[  ] 155/977, 10.0 task/s, elapsed: 16s, ETA:    83s[  ] 156/977, 10.0 task/s, elapsed: 16s, ETA:    82s[  ] 157/977, 10.0 task/s, elapsed: 16s, ETA:    82s[  ] 158/977, 10.0 task/s, elapsed: 16s, ETA:    82s[  ] 159/977, 10.0 task/s, elapsed: 16s, ETA:    82s[  ] 160/977, 10.0 task/s, elapsed: 16s, ETA:    82s[  ] 161/977, 10.0 task/s, elapsed: 16s, ETA:    82s[  ] 162/977, 10.0 task/s, elapsed: 16s, ETA:    82s[  ] 163/977, 10.0 task/s, elapsed: 16s, ETA:    82s[  ] 164/977, 10.0 task/s, elapsed: 16s, ETA:    82s[  ] 165/977, 10.0 task/s, elapsed: 17s, ETA:    82s[  ] 166/977, 10.0 task/s, elapsed: 17s, ETA:    81s[  ] 167/977, 10.0 task/s, elapsed: 17s, ETA:    81s[  ] 168/977, 10.0 task/s, elapsed: 17s, ETA:    81s[  ] 169/977, 10.0 task/s, elapsed: 17s, ETA:    81s[  ] 170/977, 10.0 task/s, elapsed: 17s, ETA:    81s[  ] 171/977, 10.0 task/s, elapsed: 17s, ETA:    81s[  ] 172/977, 10.0 task/s, elapsed: 17s, ETA:    81s[  ] 173/977, 10.0 task/s, elapsed: 17s, ETA:    81s[  ] 174/977, 10.0 task/s, elapsed: 17s, ETA:    81s[  ] 175/977, 10.0 task/s, elapsed: 18s, ETA:    80s[  ] 176/977, 10.0 task/s, elapsed: 18s, ETA:    80s[  ] 177/977, 10.0 task/s, elapsed: 18s, ETA:    80s[  ] 178/977, 10.0 task/s, elapsed: 18s, ETA:    80s[  ] 179/977, 10.0 task/s, elapsed: 18s, ETA:    80s[  ] 180/977, 10.0 task/s, elapsed: 18s, ETA:    80s[  ] 181/977, 10.0 task/s, elapsed: 18s, ETA:    80s[  ] 182/977, 10.0 task/s, elapsed: 18s, ETA:    80s[  ] 183/977, 10.0 task/s, elapsed: 18s, ETA:    80s[  ] 184/977, 10.0 task/s, elapsed: 18s, ETA:    80s[  ] 185/977, 10.0 task/s, elapsed: 19s, ETA:    79s[  ] 186/977, 10.0 task/s, elapsed: 19s, ETA:    79s[  ] 187/977, 10.0 task/s, elapsed: 19s, ETA:    79s[  ] 188/977, 10.0 task/s, elapsed: 19s, ETA:    79s[  ] 189/977, 10.0 task/s, elapsed: 19s, ETA:    79s[  ] 190/977, 10.0 task/s, elapsed: 19s, ETA:    79s[  ] 191/977, 10.0 task/s, elapsed: 19s, ETA:    79s[  ] 192/977, 10.0 task/s, elapsed: 19s, ETA:    79s[  ] 193/977, 10.0 task/s, elapsed: 19s, ETA:    79s[  ] 194/977, 10.0 task/s, elapsed: 19s, ETA:    79s[  ] 195/977, 10.0 task/s, elapsed: 20s, ETA:    79s[  ] 196/977, 10.0 task/s, elapsed: 20s, ETA:    78s[  ] 197/977, 10.0 task/s, elapsed: 20s, ETA:    78s[  ] 198/977, 10.0 task/s, elapsed: 20s, ETA:    78s[  ] 199/977, 10.0 task/s, elapsed: 20s, ETA:    78s[  ] 200/977, 10.0 task/s, elapsed: 20s, ETA:    78s[  ] 201/977, 10.0 task/s, elapsed: 20s, ETA:    78s[  ] 202/977, 10.0 task/s, elapsed: 20s, ETA:    78s[  ] 203/977, 10.0 task/s, elapsed: 20s, ETA:    78s[  ] 204/977, 10.0 task/s, elapsed: 20s, ETA:    78s[  ] 205/977, 10.0 task/s, elapsed: 21s, ETA:    78s[  ] 206/977, 10.0 task/s, elapsed: 21s, ETA:    77s[  ] 207/977, 10.0 task/s, elapsed: 21s, ETA:    77s[  ] 208/977, 10.0 task/s, elapsed: 21s, ETA:    77s[  ] 209/977, 10.0 task/s, elapsed: 21s, ETA:    77s[  ] 210/977, 10.0 task/s, elapsed: 21s, ETA:    77s[  ] 211/977, 10.0 task/s, elapsed: 21s, ETA:    77s[  ] 212/977, 10.0 task/s, elapsed: 21s, ETA:    77s[  ] 213/977, 10.0 task/s, elapsed: 21s, ETA:    77s[  ] 214/977, 10.0 task/s, elapsed: 21s, ETA:    77s[  ] 215/977, 10.0 task/s, elapsed: 22s, ETA:    76s[  ] 216/977, 10.0 task/s, elapsed: 22s, ETA:    76s[  ] 217/977, 10.0 task/s, elapsed: 22s, ETA:    76s[  ] 218/977, 10.0 task/s, elapsed: 22s, ETA:    76s[  ] 219/977, 10.0 task/s, elapsed: 22s, ETA:    76s[  ] 220/977, 10.0 task/s, elapsed: 22s, ETA:    76s[  ] 221/977, 10.0 task/s, elapsed: 22s, ETA:    76s[  ] 222/977, 10.0 task/s, elapsed: 22s, ETA:    76s[  ] 223/977, 10.0 task/s, elapsed: 22s, ETA:    76s[  ] 224/977, 10.0 task/s, elapsed: 22s, ETA:    76s[  ] 225/977, 10.0 task/s, elapsed: 23s, ETA:    76s[  ] 226/977, 10.0 task/s, elapsed: 23s, ETA:    75s[  ] 227/977, 10.0 task/s, elapsed: 23s, ETA:    75s[  ] 228/977, 10.0 task/s, elapsed: 23s, ETA:    75s[  ] 229/977, 10.0 task/s, elapsed: 23s, ETA:    75s[  ] 230/977, 10.0 task/s, elapsed: 23s, ETA:    75s[  ] 231/977, 10.0 task/s, elapsed: 23s, ETA:    75s[  ] 232/977, 10.0 task/s, elapsed: 23s, ETA:    75s[  ] 233/977, 10.0 task/s, elapsed: 23s, ETA:    75s[  ] 234/977, 10.0 task/s, elapsed: 23s, ETA:    75s[  ] 235/977, 10.0 task/s, elapsed: 24s, ETA:    75s[  ] 236/977, 10.0 task/s, elapsed: 24s, ETA:    74s[  ] 237/977, 10.0 task/s, elapsed: 24s, ETA:    74s[  ] 238/977, 10.0 task/s, elapsed: 24s, ETA:    74s[  ] 239/977, 10.0 task/s, elapsed: 24s, ETA:    74s[  ] 240/977, 10.0 task/s, elapsed: 24s, ETA:    74s[  ] 241/977, 10.0 task/s, elapsed: 24s, ETA:    74s[  ] 242/977, 10.0 task/s, elapsed: 24s, ETA:    74s[  ] 243/977, 10.0 task/s, elapsed: 24s, ETA:    74s[  ] 244/977, 10.0 task/s, elapsed: 25s, ETA:    74s[  ] 245/977, 10.0 task/s, elapsed: 25s, ETA:    74s[  ] 246/977, 10.0 task/s, elapsed: 25s, ETA:    73s[  ] 247/977, 10.0 task/s, elapsed: 25s, ETA:    73s[  ] 248/977, 10.0 task/s, elapsed: 25s, ETA:    73s[  ] 249/977, 10.0 task/s, elapsed: 25s, ETA:    73s[  ] 250/977, 10.0 task/s, elapsed: 25s, ETA:    73s[  ] 251/977, 10.0 task/s, elapsed: 25s, ETA:    73s[  ] 252/977, 10.0 task/s, elapsed: 25s, ETA:    73s[  ] 253/977, 10.0 task/s, elapsed: 25s, ETA:    73s[  ] 254/977, 10.0 task/s, elapsed: 26s, ETA:    73s[  ] 255/977, 10.0 task/s, elapsed: 26s, ETA:    72s[  ] 256/977, 10.0 task/s, elapsed: 26s, ETA:    72s[  ] 257/977, 10.0 task/s, elapsed: 26s, ETA:    72s[  ] 258/977, 10.0 task/s, elapsed: 26s, ETA:    72s[  ] 259/977, 10.0 task/s, elapsed: 26s, ETA:    72s[  ] 260/977, 10.0 task/s, elapsed: 26s, ETA:    72s[  ] 261/977, 10.0 task/s, elapsed: 26s, ETA:    72s[  ] 262/977, 10.0 task/s, elapsed: 26s, ETA:    72s[  ] 263/977, 10.0 task/s, elapsed: 26s, ETA:    72s[  ] 264/977, 10.0 task/s, elapsed: 27s, ETA:    72s[  ] 265/977, 10.0 task/s, elapsed: 27s, ETA:    71s[  ] 266/977, 10.0 task/s, elapsed: 27s, ETA:    71s[  ] 267/977, 10.0 task/s, elapsed: 27s, ETA:    71s[  ] 268/977, 10.0 task/s, elapsed: 27s, ETA:    71s[  ] 269/977, 10.0 task/s, elapsed: 27s, ETA:    71s[  ] 270/977, 10.0 task/s, elapsed: 27s, ETA:    71s[  ] 271/977, 10.0 task/s, elapsed: 27s, ETA:    71s[  ] 272/977, 10.0 task/s, elapsed: 27s, ETA:    71s[  ] 273/977, 10.0 task/s, elapsed: 27s, ETA:    71s[  ] 274/977, 10.0 task/s, elapsed: 27s, ETA:    71s[  ] 275/977, 10.0 task/s, elapsed: 28s, ETA:    70s[  ] 276/977, 10.0 task/s, elapsed: 28s, ETA:    70s[  ] 277/977, 10.0 task/s, elapsed: 28s, ETA:    70s[  ] 278/977, 10.0 task/s, elapsed: 28s, ETA:    70s[  ] 279/977, 10.0 task/s, elapsed: 28s, ETA:    70s[  ] 280/977, 10.0 task/s, elapsed: 28s, ETA:    70s[  ] 281/977, 10.0 task/s, elapsed: 28s, ETA:    70s[  ] 282/977, 10.0 task/s, elapsed: 28s, ETA:    70s[  ] 283/977, 10.0 task/s, elapsed: 28s, ETA:    70s[  ] 284/977, 10.0 task/s, elapsed: 28s, ETA:    70s[  ] 285/977, 10.0 task/s, elapsed: 29s, ETA:    69s[  ] 286/977, 10.0 task/s, elapsed: 29s, ETA:    69s[  ] 287/977, 10.0 task/s, elapsed: 29s, ETA:    69s[  ] 288/977, 10.0 task/s, elapsed: 29s, ETA:    69s[  ] 289/977, 10.0 task/s, elapsed: 29s, ETA:    69s[  ] 290/977, 10.0 task/s, elapsed: 29s, ETA:    69s[  ] 291/977, 10.0 task/s, elapsed: 29s, ETA:    69s[  ] 292/977, 10.0 task/s, elapsed: 29s, ETA:    69s[  ] 293/977, 10.0 task/s, elapsed: 29s, ETA:    69s[  ] 294/977, 10.0 task/s, elapsed: 29s, ETA:    69s[  ] 295/977, 10.0 task/s, elapsed: 30s, ETA:    68s[  ] 296/977, 10.0 task/s, elapsed: 30s, ETA:    68s[  ] 297/977, 10.0 task/s, elapsed: 30s, ETA:    68s[  ] 298/977, 10.0 task/s, elapsed: 30s, ETA:    68s[  ] 299/977, 9.9 task/s, elapsed: 30s, ETA:    68s[  ] 300/977, 9.9 task/s, elapsed: 30s, ETA:    68s[  ] 301/977, 9.9 task/s, elapsed: 30s, ETA:    68s[  ] 302/977, 9.9 task/s, elapsed: 31s, ETA:    68s[  ] 303/977, 9.9 task/s, elapsed: 31s, ETA:    68s[  ] 304/977, 9.9 task/s, elapsed: 31s, ETA:    68s[  ] 305/977, 9.9 task/s, elapsed: 31s, ETA:    68s[  ] 306/977, 9.9 task/s, elapsed: 31s, ETA:    68s[  ] 307/977, 9.9 task/s, elapsed: 31s, ETA:    68s[  ] 308/977, 9.9 task/s, elapsed: 31s, ETA:    68s[  ] 309/977, 9.9 task/s, elapsed: 31s, ETA:    68s[  ] 310/977, 9.9 task/s, elapsed: 31s, ETA:    68s[  ] 311/977, 9.9 task/s, elapsed: 32s, ETA:    68s[  ] 312/977, 9.9 task/s, elapsed: 32s, ETA:    67s[  ] 313/977, 9.9 task/s, elapsed: 32s, ETA:    67s[  ] 314/977, 9.8 task/s, elapsed: 32s, ETA:    67s[  ] 315/977, 9.8 task/s, elapsed: 32s, ETA:    67s[  ] 316/977, 9.8 task/s, elapsed: 32s, ETA:    67s[  ] 317/977, 9.8 task/s, elapsed: 32s, ETA:    67s[  ] 318/977, 9.8 task/s, elapsed: 32s, ETA:    67s[  ] 319/977, 9.8 task/s, elapsed: 32s, ETA:    67s[  ] 320/977, 9.8 task/s, elapsed: 33s, ETA:    67s[  ] 321/977, 9.8 task/s, elapsed: 33s, ETA:    67s[  ] 322/977, 9.8 task/s, elapsed: 33s, ETA:    67s[  ] 323/977, 9.8 task/s, elapsed: 33s, ETA:    67s[  ] 324/977, 9.8 task/s, elapsed: 33s, ETA:    67s[  ] 325/977, 9.8 task/s, elapsed: 33s, ETA:    66s[  ] 326/977, 9.8 task/s, elapsed: 33s, ETA:    66s[  ] 327/977, 9.8 task/s, elapsed: 33s, ETA:    66s[  ] 328/977, 9.8 task/s, elapsed: 33s, ETA:    66s[  ] 329/977, 9.8 task/s, elapsed: 34s, ETA:    66s[  ] 330/977, 9.8 task/s, elapsed: 34s, ETA:    66s[  ] 331/977, 9.8 task/s, elapsed: 34s, ETA:    66s[  ] 332/977, 9.8 task/s, elapsed: 34s, ETA:    66s[  ] 333/977, 9.8 task/s, elapsed: 34s, ETA:    66s[  ] 334/977, 9.8 task/s, elapsed: 34s, ETA:    65s[  ] 335/977, 9.8 task/s, elapsed: 34s, ETA:    65s[  ] 336/977, 9.8 task/s, elapsed: 34s, ETA:    65s[  ] 337/977, 9.8 task/s, elapsed: 34s, ETA:    65s[  ] 338/977, 9.8 task/s, elapsed: 34s, ETA:    65s[  ] 339/977, 9.8 task/s, elapsed: 35s, ETA:    65s[  ] 340/977, 9.8 task/s, elapsed: 35s, ETA:    65s[  ] 341/977, 9.8 task/s, elapsed: 35s, ETA:    65s[  ] 342/977, 9.8 task/s, elapsed: 35s, ETA:    65s[  ] 343/977, 9.8 task/s, elapsed: 35s, ETA:    65s[  ] 344/977, 9.8 task/s, elapsed: 35s, ETA:    64s[  ] 345/977, 9.8 task/s, elapsed: 35s, ETA:    64s[  ] 346/977, 9.8 task/s, elapsed: 35s, ETA:    64s[  ] 347/977, 9.8 task/s, elapsed: 35s, ETA:    64s[  ] 348/977, 9.8 task/s, elapsed: 35s, ETA:    64s[  ] 349/977, 9.8 task/s, elapsed: 35s, ETA:    64s[  ] 350/977, 9.8 task/s, elapsed: 36s, ETA:    64s[  ] 351/977, 9.8 task/s, elapsed: 36s, ETA:    64s[  ] 352/977, 9.8 task/s, elapsed: 36s, ETA:    64s[  ] 353/977, 9.8 task/s, elapsed: 36s, ETA:    63s[  ] 354/977, 9.8 task/s, elapsed: 36s, ETA:    63s[  ] 355/977, 9.8 task/s, elapsed: 36s, ETA:    63s[  ] 356/977, 9.8 task/s, elapsed: 36s, ETA:    63s[  ] 357/977, 9.8 task/s, elapsed: 36s, ETA:    63s[  ] 358/977, 9.8 task/s, elapsed: 36s, ETA:    63s[  ] 359/977, 9.8 task/s, elapsed: 36s, ETA:    63s[  ] 360/977, 9.8 task/s, elapsed: 37s, ETA:    63s[  ] 361/977, 9.8 task/s, elapsed: 37s, ETA:    63s[  ] 362/977, 9.8 task/s, elapsed: 37s, ETA:    63s[  ] 363/977, 9.8 task/s, elapsed: 37s, ETA:    62s[  ] 364/977, 9.8 task/s, elapsed: 37s, ETA:    62s[  ] 365/977, 9.8 task/s, elapsed: 37s, ETA:    62s[  ] 366/977, 9.8 task/s, elapsed: 37s, ETA:    62s[  ] 367/977, 9.8 task/s, elapsed: 37s, ETA:    62s[  ] 368/977, 9.8 task/s, elapsed: 37s, ETA:    62s[  ] 369/977, 9.8 task/s, elapsed: 37s, ETA:    62s[  ] 370/977, 9.8 task/s, elapsed: 38s, ETA:    62s[  ] 371/977, 9.8 task/s, elapsed: 38s, ETA:    62s[  ] 372/977, 9.8 task/s, elapsed: 38s, ETA:    61s[  ] 373/977, 9.8 task/s, elapsed: 38s, ETA:    61s[  ] 374/977, 9.8 task/s, elapsed: 38s, ETA:    61s[  ] 375/977, 9.8 task/s, elapsed: 38s, ETA:    61s[  ] 376/977, 9.8 task/s, elapsed: 38s, ETA:    61s[  ] 377/977, 9.8 task/s, elapsed: 38s, ETA:    61s[  ] 378/977, 9.8 task/s, elapsed: 38s, ETA:    61s[  ] 379/977, 9.9 task/s, elapsed: 38s, ETA:    61s[  ] 380/977, 9.9 task/s, elapsed: 39s, ETA:    61s[  ] 381/977, 9.9 task/s, elapsed: 39s, ETA:    60s[  ] 382/977, 9.9 task/s, elapsed: 39s, ETA:    60s[  ] 383/977, 9.9 task/s, elapsed: 39s, ETA:    60s[  ] 384/977, 9.9 task/s, elapsed: 39s, ETA:    60s[  ] 385/977, 9.9 task/s, elapsed: 39s, ETA:    60s[  ] 386/977, 9.9 task/s, elapsed: 39s, ETA:    60s[  ] 387/977, 9.9 task/s, elapsed: 39s, ETA:    60s[  ] 388/977, 9.9 task/s, elapsed: 39s, ETA:    60s[  ] 389/977, 9.9 task/s, elapsed: 39s, ETA:    60s[  ] 390/977, 9.9 task/s, elapsed: 40s, ETA:    60s[  ] 391/977, 9.9 task/s, elapsed: 40s, ETA:    59s[  ] 392/977, 9.9 task/s, elapsed: 40s, ETA:    59s[  ] 393/977, 9.9 task/s, elapsed: 40s, ETA:    59s[  ] 394/977, 9.9 task/s, elapsed: 40s, ETA:    59s[  ] 395/977, 9.9 task/s, elapsed: 40s, ETA:    59s[  ] 396/977, 9.9 task/s, elapsed: 40s, ETA:    59s[  ] 397/977, 9.9 task/s, elapsed: 40s, ETA:    59s[  ] 398/977, 9.9 task/s, elapsed: 40s, ETA:    59s[  ] 399/977, 9.9 task/s, elapsed: 40s, ETA:    59s[  ] 400/977, 9.9 task/s, elapsed: 41s, ETA:    58s[  ] 401/977, 9.9 task/s, elapsed: 41s, ETA:    58s[  ] 402/977, 9.9 task/s, elapsed: 41s, ETA:    58s[  ] 403/977, 9.9 task/s, elapsed: 41s, ETA:    58s[  ] 404/977, 9.9 task/s, elapsed: 41s, ETA:    58s[  ] 405/977, 9.9 task/s, elapsed: 41s, ETA:    58s[  ] 406/977, 9.9 task/s, elapsed: 41s, ETA:    58s[  ] 407/977, 9.9 task/s, elapsed: 41s, ETA:    58s[  ] 408/977, 9.9 task/s, elapsed: 41s, ETA:    58s[  ] 409/977, 9.9 task/s, elapsed: 41s, ETA:    58s[  ] 410/977, 9.9 task/s, elapsed: 42s, ETA:    57s[  ] 411/977, 9.9 task/s, elapsed: 42s, ETA:    57s[  ] 412/977, 9.9 task/s, elapsed: 42s, ETA:    57s[  ] 413/977, 9.9 task/s, elapsed: 42s, ETA:    57s[  ] 414/977, 9.9 task/s, elapsed: 42s, ETA:    57s[  ] 415/977, 9.9 task/s, elapsed: 42s, ETA:    57s[  ] 416/977, 9.9 task/s, elapsed: 42s, ETA:    57s[  ] 417/977, 9.9 task/s, elapsed: 42s, ETA:    57s[  ] 418/977, 9.9 task/s, elapsed: 42s, ETA:    57s[  ] 419/977, 9.9 task/s, elapsed: 42s, ETA:    57s[  ] 420/977, 9.9 task/s, elapsed: 43s, ETA:    56s[  ] 421/977, 9.9 task/s, elapsed: 43s, ETA:    56s[  ] 422/977, 9.9 task/s, elapsed: 43s, ETA:    56s[  ] 423/977, 9.9 task/s, elapsed: 43s, ETA:    56s[  ] 424/977, 9.9 task/s, elapsed: 43s, ETA:    56s[  ] 425/977, 9.9 task/s, elapsed: 43s, ETA:    56s[  ] 426/977, 9.9 task/s, elapsed: 43s, ETA:    56s[  ] 427/977, 9.9 task/s, elapsed: 43s, ETA:    56s[  ] 428/977, 9.9 task/s, elapsed: 43s, ETA:    56s[  ] 429/977, 9.9 task/s, elapsed: 43s, ETA:    55s[  ] 430/977, 9.9 task/s, elapsed: 44s, ETA:    55s[  ] 431/977, 9.9 task/s, elapsed: 44s, ETA:    55s[  ] 432/977, 9.9 task/s, elapsed: 44s, ETA:    55s[  ] 433/977, 9.9 task/s, elapsed: 44s, ETA:    55s[  ] 434/977, 9.9 task/s, elapsed: 44s, ETA:    55s[  ] 435/977, 9.9 task/s, elapsed: 44s, ETA:    55s[  ] 436/977, 9.9 task/s, elapsed: 44s, ETA:    55s[  ] 437/977, 9.9 task/s, elapsed: 44s, ETA:    55s[  ] 438/977, 9.9 task/s, elapsed: 44s, ETA:    55s[  ] 439/977, 9.9 task/s, elapsed: 44s, ETA:    54s[  ] 440/977, 9.9 task/s, elapsed: 45s, ETA:    54s[  ] 441/977, 9.9 task/s, elapsed: 45s, ETA:    54s[  ] 442/977, 9.9 task/s, elapsed: 45s, ETA:    54s[  ] 443/977, 9.9 task/s, elapsed: 45s, ETA:    54s[  ] 444/977, 9.9 task/s, elapsed: 45s, ETA:    54s[  ] 445/977, 9.9 task/s, elapsed: 45s, ETA:    54s[  ] 446/977, 9.9 task/s, elapsed: 45s, ETA:    54s[  ] 447/977, 9.9 task/s, elapsed: 45s, ETA:    54s[  ] 448/977, 9.9 task/s, elapsed: 45s, ETA:    54s[  ] 449/977, 9.9 task/s, elapsed: 45s, ETA:    53s[  ] 450/977, 9.9 task/s, elapsed: 46s, ETA:    53s[  ] 451/977, 9.9 task/s, elapsed: 46s, ETA:    53s[  ] 452/977, 9.9 task/s, elapsed: 46s, ETA:    53s[  ] 453/977, 9.9 task/s, elapsed: 46s, ETA:    53s[  ] 454/977, 9.9 task/s, elapsed: 46s, ETA:    53s[  ] 455/977, 9.9 task/s, elapsed: 46s, ETA:    53s[  ] 456/977, 9.9 task/s, elapsed: 46s, ETA:    53s[  ] 457/977, 9.9 task/s, elapsed: 46s, ETA:    53s[  ] 458/977, 9.9 task/s, elapsed: 46s, ETA:    52s[  ] 459/977, 9.9 task/s, elapsed: 46s, ETA:    52s[  ] 460/977, 9.9 task/s, elapsed: 47s, ETA:    52s[  ] 461/977, 9.9 task/s, elapsed: 47s, ETA:    52s[  ] 462/977, 9.9 task/s, elapsed: 47s, ETA:    52s[  ] 463/977, 9.9 task/s, elapsed: 47s, ETA:    52s[  ] 464/977, 9.9 task/s, elapsed: 47s, ETA:    52s[  ] 465/977, 9.9 task/s, elapsed: 47s, ETA:    52s[  ] 466/977, 9.9 task/s, elapsed: 47s, ETA:    52s[  ] 467/977, 9.9 task/s, elapsed: 47s, ETA:    52s[  ] 468/977, 9.9 task/s, elapsed: 47s, ETA:    51s[  ] 469/977, 9.9 task/s, elapsed: 47s, ETA:    51s[  ] 470/977, 9.9 task/s, elapsed: 48s, ETA:    51s[  ] 471/977, 9.9 task/s, elapsed: 48s, ETA:    51s[  ] 472/977, 9.9 task/s, elapsed: 48s, ETA:    51s[  ] 473/977, 9.9 task/s, elapsed: 48s, ETA:    51s[  ] 474/977, 9.9 task/s, elapsed: 48s, ETA:    51s[  ] 475/977, 9.9 task/s, elapsed: 48s, ETA:    51s[  ] 476/977, 9.9 task/s, elapsed: 48s, ETA:    51s[  ] 477/977, 9.9 task/s, elapsed: 48s, ETA:    51s[  ] 478/977, 9.9 task/s, elapsed: 48s, ETA:    50s[  ] 479/977, 9.9 task/s, elapsed: 48s, ETA:    50s[  ] 480/977, 9.9 task/s, elapsed: 49s, ETA:    50s[  ] 481/977, 9.9 task/s, elapsed: 49s, ETA:    50s[  ] 482/977, 9.9 task/s, elapsed: 49s, ETA:    50s[  ] 483/977, 9.9 task/s, elapsed: 49s, ETA:    50s[  ] 484/977, 9.9 task/s, elapsed: 49s, ETA:    50s[  ] 485/977, 9.9 task/s, elapsed: 49s, ETA:    50s[  ] 486/977, 9.9 task/s, elapsed: 49s, ETA:    50s[  ] 487/977, 9.9 task/s, elapsed: 49s, ETA:    50s[  ] 488/977, 9.9 task/s, elapsed: 49s, ETA:    49s[> ] 489/977, 9.9 task/s, elapsed: 49s, ETA:    49s[> ] 490/977, 9.9 task/s, elapsed: 49s, ETA:    49s[> ] 491/977, 9.9 task/s, elapsed: 50s, ETA:    49s[> ] 492/977, 9.9 task/s, elapsed: 50s, ETA:    49s[> ] 493/977, 9.9 task/s, elapsed: 50s, ETA:    49s[> ] 494/977, 9.9 task/s, elapsed: 50s, ETA:    49s[> ] 495/977, 9.9 task/s, elapsed: 50s, ETA:    49s[> ] 496/977, 9.9 task/s, elapsed: 50s, ETA:    49s[> ] 497/977, 9.9 task/s, elapsed: 50s, ETA:    48s[> ] 498/977, 9.9 task/s, elapsed: 50s, ETA:    48s[> ] 499/977, 9.9 task/s, elapsed: 50s, ETA:    48s[> ] 500/977, 9.9 task/s, elapsed: 50s, ETA:    48s[> ] 501/977, 9.9 task/s, elapsed: 51s, ETA:    48s[> ] 502/977, 9.9 task/s, elapsed: 51s, ETA:    48s[> ] 503/977, 9.9 task/s, elapsed: 51s, ETA:    48s[> ] 504/977, 9.9 task/s, elapsed: 51s, ETA:    48s[> ] 505/977, 9.9 task/s, elapsed: 51s, ETA:    48s[> ] 506/977, 9.9 task/s, elapsed: 51s, ETA:    48s[> ] 507/977, 9.9 task/s, elapsed: 51s, ETA:    47s[> ] 508/977, 9.9 task/s, elapsed: 51s, ETA:    47s[> ] 509/977, 9.9 task/s, elapsed: 51s, ETA:    47s[> ] 510/977, 9.9 task/s, elapsed: 51s, ETA:    47s[> ] 511/977, 9.9 task/s, elapsed: 52s, ETA:    47s[> ] 512/977, 9.9 task/s, elapsed: 52s, ETA:    47s[> ] 513/977, 9.9 task/s, elapsed: 52s, ETA:    47s[> ] 514/977, 9.9 task/s, elapsed: 52s, ETA:    47s[> ] 515/977, 9.9 task/s, elapsed: 52s, ETA:    47s[> ] 516/977, 9.9 task/s, elapsed: 52s, ETA:    47s[> ] 517/977, 9.9 task/s, elapsed: 52s, ETA:    46s[> ] 518/977, 9.9 task/s, elapsed: 52s, ETA:    46s[> ] 519/977, 9.9 task/s, elapsed: 52s, ETA:    46s[> ] 520/977, 9.9 task/s, elapsed: 52s, ETA:    46s[> ] 521/977, 9.9 task/s, elapsed: 53s, ETA:    46s[> ] 522/977, 9.9 task/s, elapsed: 53s, ETA:    46s[> ] 523/977, 9.9 task/s, elapsed: 53s, ETA:    46s[> ] 524/977, 9.9 task/s, elapsed: 53s, ETA:    46s[> ] 525/977, 9.9 task/s, elapsed: 53s, ETA:    46s[> ] 526/977, 9.9 task/s, elapsed: 53s, ETA:    46s[> ] 527/977, 9.9 task/s, elapsed: 53s, ETA:    45s[> ] 528/977, 9.9 task/s, elapsed: 53s, ETA:    45s[> ] 529/977, 9.9 task/s, elapsed: 53s, ETA:    45s[> ] 530/977, 9.9 task/s, elapsed: 53s, ETA:    45s[> ] 531/977, 9.9 task/s, elapsed: 54s, ETA:    45s[> ] 532/977, 9.9 task/s, elapsed: 54s, ETA:    45s[> ] 533/977, 9.9 task/s, elapsed: 54s, ETA:    45s[> ] 534/977, 9.9 task/s, elapsed: 54s, ETA:    45s[> ] 535/977, 9.9 task/s, elapsed: 54s, ETA:    45s[> ] 536/977, 9.9 task/s, elapsed: 54s, ETA:    45s[> ] 537/977, 9.9 task/s, elapsed: 54s, ETA:    44s[> ] 538/977, 9.9 task/s, elapsed: 54s, ETA:    44s[> ] 539/977, 9.9 task/s, elapsed: 54s, ETA:    44s[> ] 540/977, 9.9 task/s, elapsed: 55s, ETA:    44s[> ] 541/977, 9.9 task/s, elapsed: 55s, ETA:    44s[> ] 542/977, 9.9 task/s, elapsed: 55s, ETA:    44s[> ] 543/977, 9.9 task/s, elapsed: 55s, ETA:    44s[> ] 544/977, 9.9 task/s, elapsed: 55s, ETA:    44s[> ] 545/977, 9.9 task/s, elapsed: 55s, ETA:    44s[> ] 546/977, 9.9 task/s, elapsed: 55s, ETA:    43s[> ] 547/977, 9.9 task/s, elapsed: 55s, ETA:    43s[> ] 548/977, 9.9 task/s, elapsed: 55s, ETA:    43s[> ] 549/977, 9.9 task/s, elapsed: 55s, ETA:    43s[> ] 550/977, 9.9 task/s, elapsed: 55s, ETA:    43s[> ] 551/977, 9.9 task/s, elapsed: 56s, ETA:    43s[> ] 552/977, 9.9 task/s, elapsed: 56s, ETA:    43s[> ] 553/977, 9.9 task/s, elapsed: 56s, ETA:    43s[> ] 554/977, 9.9 task/s, elapsed: 56s, ETA:    43s[> ] 555/977, 9.9 task/s, elapsed: 56s, ETA:    43s[> ] 556/977, 9.9 task/s, elapsed: 56s, ETA:    42s[> ] 557/977, 9.9 task/s, elapsed: 56s, ETA:    42s[> ] 558/977, 9.9 task/s, elapsed: 56s, ETA:    42s[> ] 559/977, 9.9 task/s, elapsed: 56s, ETA:    42s[> ] 560/977, 9.9 task/s, elapsed: 56s, ETA:    42s[> ] 561/977, 9.9 task/s, elapsed: 57s, ETA:    42s[> ] 562/977, 9.9 task/s, elapsed: 57s, ETA:    42s[> ] 563/977, 9.9 task/s, elapsed: 57s, ETA:    42s[> ] 564/977, 9.9 task/s, elapsed: 57s, ETA:    42s[> ] 565/977, 9.9 task/s, elapsed: 57s, ETA:    42s[> ] 566/977, 9.9 task/s, elapsed: 57s, ETA:    41s[> ] 567/977, 9.9 task/s, elapsed: 57s, ETA:    41s[> ] 568/977, 9.9 task/s, elapsed: 57s, ETA:    41s[> ] 569/977, 9.9 task/s, elapsed: 57s, ETA:    41s[> ] 570/977, 9.9 task/s, elapsed: 57s, ETA:    41s[> ] 571/977, 9.9 task/s, elapsed: 58s, ETA:    41s[> ] 572/977, 9.9 task/s, elapsed: 58s, ETA:    41s[> ] 573/977, 9.9 task/s, elapsed: 58s, ETA:    41s[> ] 574/977, 9.9 task/s, elapsed: 58s, ETA:    41s[> ] 575/977, 9.9 task/s, elapsed: 58s, ETA:    41s[> ] 576/977, 9.9 task/s, elapsed: 58s, ETA:    40s[> ] 577/977, 9.9 task/s, elapsed: 58s, ETA:    40s[> ] 578/977, 9.9 task/s, elapsed: 58s, ETA:    40s[> ] 579/977, 9.9 task/s, elapsed: 58s, ETA:    40s[> ] 580/977, 9.9 task/s, elapsed: 58s, ETA:    40s[> ] 581/977, 9.9 task/s, elapsed: 59s, ETA:    40s[> ] 582/977, 9.9 task/s, elapsed: 59s, ETA:    40s[> ] 583/977, 9.9 task/s, elapsed: 59s, ETA:    40s[> ] 584/977, 9.9 task/s, elapsed: 59s, ETA:    40s[> ] 585/977, 9.9 task/s, elapsed: 59s, ETA:    39s[> ] 586/977, 9.9 task/s, elapsed: 59s, ETA:    39s[> ] 587/977, 9.9 task/s, elapsed: 59s, ETA:    39s[> ] 588/977, 9.9 task/s, elapsed: 59s, ETA:    39s[> ] 589/977, 9.9 task/s, elapsed: 59s, ETA:    39s[> ] 590/977, 9.9 task/s, elapsed: 59s, ETA:    39s[> ] 591/977, 9.9 task/s, elapsed: 60s, ETA:    39s[> ] 592/977, 9.9 task/s, elapsed: 60s, ETA:    39s[> ] 593/977, 9.9 task/s, elapsed: 60s, ETA:    39s[> ] 594/977, 9.9 task/s, elapsed: 60s, ETA:    39s[> ] 595/977, 9.9 task/s, elapsed: 60s, ETA:    38s[> ] 596/977, 9.9 task/s, elapsed: 60s, ETA:    38s[> ] 597/977, 9.9 task/s, elapsed: 60s, ETA:    38s[> ] 598/977, 9.9 task/s, elapsed: 60s, ETA:    38s[> ] 599/977, 9.9 task/s, elapsed: 60s, ETA:    38s[> ] 600/977, 9.9 task/s, elapsed: 60s, ETA:    38s[> ] 601/977, 9.9 task/s, elapsed: 61s, ETA:    38s[> ] 602/977, 9.9 task/s, elapsed: 61s, ETA:    38s[> ] 603/977, 9.9 task/s, elapsed: 61s, ETA:    38s[> ] 604/977, 9.9 task/s, elapsed: 61s, ETA:    38s[> ] 605/977, 9.9 task/s, elapsed: 61s, ETA:    38s[> ] 606/977, 9.9 task/s, elapsed: 61s, ETA:    37s[> ] 607/977, 9.9 task/s, elapsed: 61s, ETA:    37s[> ] 608/977, 9.9 task/s, elapsed: 61s, ETA:    37s[> ] 609/977, 9.9 task/s, elapsed: 61s, ETA:    37s[> ] 610/977, 9.9 task/s, elapsed: 62s, ETA:    37s[> ] 611/977, 9.9 task/s, elapsed: 62s, ETA:    37s[> ] 612/977, 9.9 task/s, elapsed: 62s, ETA:    37s[> ] 613/977, 9.9 task/s, elapsed: 62s, ETA:    37s[> ] 614/977, 9.9 task/s, elapsed: 62s, ETA:    37s[> ] 615/977, 9.9 task/s, elapsed: 62s, ETA:    37s[> ] 616/977, 9.9 task/s, elapsed: 62s, ETA:    36s[> ] 617/977, 9.9 task/s, elapsed: 62s, ETA:    36s[> ] 618/977, 9.9 task/s, elapsed: 62s, ETA:    36s[> ] 619/977, 9.9 task/s, elapsed: 62s, ETA:    36s[> ] 620/977, 9.9 task/s, elapsed: 63s, ETA:    36s[> ] 621/977, 9.9 task/s, elapsed: 63s, ETA:    36s[> ] 622/977, 9.9 task/s, elapsed: 63s, ETA:    36s[> ] 623/977, 9.9 task/s, elapsed: 63s, ETA:    36s[> ] 624/977, 9.9 task/s, elapsed: 63s, ETA:    36s[> ] 625/977, 9.9 task/s, elapsed: 63s, ETA:    36s[> ] 626/977, 9.9 task/s, elapsed: 63s, ETA:    35s[> ] 627/977, 9.9 task/s, elapsed: 63s, ETA:    35s[> ] 628/977, 9.9 task/s, elapsed: 63s, ETA:    35s[> ] 629/977, 9.9 task/s, elapsed: 63s, ETA:    35s[> ] 630/977, 9.9 task/s, elapsed: 64s, ETA:    35s[> ] 631/977, 9.9 task/s, elapsed: 64s, ETA:    35s[> ] 632/977, 9.9 task/s, elapsed: 64s, ETA:    35s[> ] 633/977, 9.9 task/s, elapsed: 64s, ETA:    35s[> ] 634/977, 9.9 task/s, elapsed: 64s, ETA:    35s[> ] 635/977, 9.9 task/s, elapsed: 64s, ETA:    35s[> ] 636/977, 9.9 task/s, elapsed: 64s, ETA:    34s[> ] 637/977, 9.9 task/s, elapsed: 64s, ETA:    34s[> ] 638/977, 9.9 task/s, elapsed: 64s, ETA:    34s[> ] 639/977, 9.9 task/s, elapsed: 64s, ETA:    34s[> ] 640/977, 9.9 task/s, elapsed: 65s, ETA:    34s[> ] 641/977, 9.9 task/s, elapsed: 65s, ETA:    34s[> ] 642/977, 9.9 task/s, elapsed: 65s, ETA:    34s[> ] 643/977, 9.9 task/s, elapsed: 65s, ETA:    34s[> ] 644/977, 9.9 task/s, elapsed: 65s, ETA:    34s[> ] 645/977, 9.9 task/s, elapsed: 65s, ETA:    33s[> ] 646/977, 9.9 task/s, elapsed: 65s, ETA:    33s[> ] 647/977, 9.9 task/s, elapsed: 65s, ETA:    33s[> ] 648/977, 9.9 task/s, elapsed: 65s, ETA:    33s[> ] 649/977, 9.9 task/s, elapsed: 65s, ETA:    33s[> ] 650/977, 9.9 task/s, elapsed: 66s, ETA:    33s[> ] 651/977, 9.9 task/s, elapsed: 66s, ETA:    33s[> ] 652/977, 9.9 task/s, elapsed: 66s, ETA:    33s[> ] 653/977, 9.9 task/s, elapsed: 66s, ETA:    33s[> ] 654/977, 9.9 task/s, elapsed: 66s, ETA:    33s[> ] 655/977, 9.9 task/s, elapsed: 66s, ETA:    32s[> ] 656/977, 9.9 task/s, elapsed: 66s, ETA:    32s[> ] 657/977, 9.9 task/s, elapsed: 66s, ETA:    32s[> ] 658/977, 9.9 task/s, elapsed: 66s, ETA:    32s[> ] 659/977, 9.9 task/s, elapsed: 66s, ETA:    32s[> ] 660/977, 9.9 task/s, elapsed: 67s, ETA:    32s[> ] 661/977, 9.9 task/s, elapsed: 67s, ETA:    32s[> ] 662/977, 9.9 task/s, elapsed: 67s, ETA:    32s[> ] 663/977, 9.9 task/s, elapsed: 67s, ETA:    32s[> ] 664/977, 9.9 task/s, elapsed: 67s, ETA:    32s[> ] 665/977, 9.9 task/s, elapsed: 67s, ETA:    31s[> ] 666/977, 9.9 task/s, elapsed: 67s, ETA:    31s[> ] 667/977, 9.9 task/s, elapsed: 67s, ETA:    31s[> ] 668/977, 9.9 task/s, elapsed: 67s, ETA:    31s[> ] 669/977, 9.9 task/s, elapsed: 67s, ETA:    31s[> ] 670/977, 9.9 task/s, elapsed: 67s, ETA:    31s[> ] 671/977, 9.9 task/s, elapsed: 68s, ETA:    31s[> ] 672/977, 9.9 task/s, elapsed: 68s, ETA:    31s[> ] 673/977, 9.9 task/s, elapsed: 68s, ETA:    31s[> ] 674/977, 9.9 task/s, elapsed: 68s, ETA:    31s[> ] 675/977, 9.9 task/s, elapsed: 68s, ETA:    30s[> ] 676/977, 9.9 task/s, elapsed: 68s, ETA:    30s[> ] 677/977, 9.9 task/s, elapsed: 68s, ETA:    30s[> ] 678/977, 9.9 task/s, elapsed: 68s, ETA:    30s[> ] 679/977, 9.9 task/s, elapsed: 68s, ETA:    30s[> ] 680/977, 9.9 task/s, elapsed: 68s, ETA:    30s[> ] 681/977, 9.9 task/s, elapsed: 69s, ETA:    30s[> ] 682/977, 9.9 task/s, elapsed: 69s, ETA:    30s[> ] 683/977, 9.9 task/s, elapsed: 69s, ETA:    30s[> ] 684/977, 9.9 task/s, elapsed: 69s, ETA:    30s[> ] 685/977, 9.9 task/s, elapsed: 69s, ETA:    29s[> ] 686/977, 9.9 task/s, elapsed: 69s, ETA:    29s[> ] 687/977, 9.9 task/s, elapsed: 69s, ETA:    29s[> ] 688/977, 9.9 task/s, elapsed: 69s, ETA:    29s[> ] 689/977, 9.9 task/s, elapsed: 69s, ETA:    29s[> ] 690/977, 9.9 task/s, elapsed: 69s, ETA:    29s[> ] 691/977, 9.9 task/s, elapsed: 70s, ETA:    29s[> ] 692/977, 9.9 task/s, elapsed: 70s, ETA:    29s[> ] 693/977, 9.9 task/s, elapsed: 70s, ETA:    29s[> ] 694/977, 9.9 task/s, elapsed: 70s, ETA:    28s[> ] 695/977, 9.9 task/s, elapsed: 70s, ETA:    28s[> ] 696/977, 9.9 task/s, elapsed: 70s, ETA:    28s[> ] 697/977, 9.9 task/s, elapsed: 70s, ETA:    28s[> ] 698/977, 9.9 task/s, elapsed: 70s, ETA:    28s[> ] 699/977, 9.9 task/s, elapsed: 70s, ETA:    28s[> ] 700/977, 9.9 task/s, elapsed: 70s, ETA:    28s[> ] 701/977, 9.9 task/s, elapsed: 71s, ETA:    28s[> ] 702/977, 9.9 task/s, elapsed: 71s, ETA:    28s[> ] 703/977, 9.9 task/s, elapsed: 71s, ETA:    28s[> ] 704/977, 9.9 task/s, elapsed: 71s, ETA:    27s[> ] 705/977, 9.9 task/s, elapsed: 71s, ETA:    27s[> ] 706/977, 9.9 task/s, elapsed: 71s, ETA:    27s[> ] 707/977, 9.9 task/s, elapsed: 71s, ETA:    27s[> ] 708/977, 9.9 task/s, elapsed: 71s, ETA:    27s[> ] 709/977, 9.9 task/s, elapsed: 71s, ETA:    27s[> ] 710/977, 9.9 task/s, elapsed: 71s, ETA:    27s[> ] 711/977, 9.9 task/s, elapsed: 72s, ETA:    27s[> ] 712/977, 9.9 task/s, elapsed: 72s, ETA:    27s[> ] 713/977, 9.9 task/s, elapsed: 72s, ETA:    27s[> ] 714/977, 9.9 task/s, elapsed: 72s, ETA:    26s[> ] 715/977, 9.9 task/s, elapsed: 72s, ETA:    26s[> ] 716/977, 9.9 task/s, elapsed: 72s, ETA:    26s[> ] 717/977, 9.9 task/s, elapsed: 72s, ETA:    26s[> ] 718/977, 9.9 task/s, elapsed: 72s, ETA:    26s[> ] 719/977, 9.9 task/s, elapsed: 72s, ETA:    26s[> ] 720/977, 9.9 task/s, elapsed: 72s, ETA:    26s[> ] 721/977, 9.9 task/s, elapsed: 73s, ETA:    26s[> ] 722/977, 9.9 task/s, elapsed: 73s, ETA:    26s[> ] 723/977, 9.9 task/s, elapsed: 73s, ETA:    26s[> ] 724/977, 9.9 task/s, elapsed: 73s, ETA:    25s[> ] 725/977, 9.9 task/s, elapsed: 73s, ETA:    25s[> ] 726/977, 9.9 task/s, elapsed: 73s, ETA:    25s[> ] 727/977, 9.9 task/s, elapsed: 73s, ETA:    25s[> ] 728/977, 9.9 task/s, elapsed: 73s, ETA:    25s[> ] 729/977, 9.9 task/s, elapsed: 73s, ETA:    25s[> ] 730/977, 9.9 task/s, elapsed: 73s, ETA:    25s[> ] 731/977, 9.9 task/s, elapsed: 74s, ETA:    25s[> ] 732/977, 9.9 task/s, elapsed: 74s, ETA:    25s[> ] 733/977, 9.9 task/s, elapsed: 74s, ETA:    25s[> ] 734/977, 9.9 task/s, elapsed: 74s, ETA:    24s[> ] 735/977, 9.9 task/s, elapsed: 74s, ETA:    24s[> ] 736/977, 9.9 task/s, elapsed: 74s, ETA:    24s[> ] 737/977, 9.9 task/s, elapsed: 74s, ETA:    24s[> ] 738/977, 9.9 task/s, elapsed: 74s, ETA:    24s[> ] 739/977, 9.9 task/s, elapsed: 74s, ETA:    24s[> ] 740/977, 9.9 task/s, elapsed: 74s, ETA:    24s[> ] 741/977, 9.9 task/s, elapsed: 75s, ETA:    24s[> ] 742/977, 9.9 task/s, elapsed: 75s, ETA:    24s[> ] 743/977, 9.9 task/s, elapsed: 75s, ETA:    24s[> ] 744/977, 9.9 task/s, elapsed: 75s, ETA:    23s[> ] 745/977, 9.9 task/s, elapsed: 75s, ETA:    23s[> ] 746/977, 9.9 task/s, elapsed: 75s, ETA:    23s[> ] 747/977, 9.9 task/s, elapsed: 75s, ETA:    23s[> ] 748/977, 9.9 task/s, elapsed: 75s, ETA:    23s[> ] 749/977, 9.9 task/s, elapsed: 75s, ETA:    23s[> ] 750/977, 9.9 task/s, elapsed: 75s, ETA:    23s[> ] 751/977, 9.9 task/s, elapsed: 76s, ETA:    23s[> ] 752/977, 9.9 task/s, elapsed: 76s, ETA:    23s[> ] 753/977, 9.9 task/s, elapsed: 76s, ETA:    23s[> ] 754/977, 9.9 task/s, elapsed: 76s, ETA:    22s[> ] 755/977, 9.9 task/s, elapsed: 76s, ETA:    22s[> ] 756/977, 9.9 task/s, elapsed: 76s, ETA:    22s[> ] 757/977, 9.9 task/s, elapsed: 76s, ETA:    22s[> ] 758/977, 9.9 task/s, elapsed: 76s, ETA:    22s[> ] 759/977, 9.9 task/s, elapsed: 76s, ETA:    22s[> ] 760/977, 9.9 task/s, elapsed: 76s, ETA:    22s[> ] 761/977, 9.9 task/s, elapsed: 77s, ETA:    22s[> ] 762/977, 9.9 task/s, elapsed: 77s, ETA:    22s[> ] 763/977, 9.9 task/s, elapsed: 77s, ETA:    22s[> ] 764/977, 9.9 task/s, elapsed: 77s, ETA:    21s[> ] 765/977, 9.9 task/s, elapsed: 77s, ETA:    21s[> ] 766/977, 9.9 task/s, elapsed: 77s, ETA:    21s[> ] 767/977, 9.9 task/s, elapsed: 77s, ETA:    21s[> ] 768/977, 9.9 task/s, elapsed: 77s, ETA:    21s[> ] 769/977, 9.9 task/s, elapsed: 77s, ETA:    21s[> ] 770/977, 9.9 task/s, elapsed: 77s, ETA:    21s[> ] 771/977, 9.9 task/s, elapsed: 78s, ETA:    21s[> ] 772/977, 9.9 task/s, elapsed: 78s, ETA:    21s[> ] 773/977, 9.9 task/s, elapsed: 78s, ETA:    21s[> ] 774/977, 9.9 task/s, elapsed: 78s, ETA:    20s[> ] 775/977, 9.9 task/s, elapsed: 78s, ETA:    20s[> ] 776/977, 9.9 task/s, elapsed: 78s, ETA:    20s[> ] 777/977, 9.9 task/s, elapsed: 78s, ETA:    20s[> ] 778/977, 9.9 task/s, elapsed: 78s, ETA:    20s[> ] 779/977, 9.9 task/s, elapsed: 78s, ETA:    20s[> ] 780/977, 9.9 task/s, elapsed: 78s, ETA:    20s[> ] 781/977, 9.9 task/s, elapsed: 79s, ETA:    20s[> ] 782/977, 9.9 task/s, elapsed: 79s, ETA:    20s[> ] 783/977, 9.9 task/s, elapsed: 79s, ETA:    20s[> ] 784/977, 9.9 task/s, elapsed: 79s, ETA:    19s[> ] 785/977, 9.9 task/s, elapsed: 79s, ETA:    19s[> ] 786/977, 9.9 task/s, elapsed: 79s, ETA:    19s[> ] 787/977, 9.9 task/s, elapsed: 79s, ETA:    19s[> ] 788/977, 9.9 task/s, elapsed: 79s, ETA:    19s[> ] 789/977, 9.9 task/s, elapsed: 79s, ETA:    19s[> ] 790/977, 9.9 task/s, elapsed: 79s, ETA:    19s[> ] 791/977, 9.9 task/s, elapsed: 80s, ETA:    19s[> ] 792/977, 9.9 task/s, elapsed: 80s, ETA:    19s[> ] 793/977, 9.9 task/s, elapsed: 80s, ETA:    18s[> ] 794/977, 9.9 task/s, elapsed: 80s, ETA:    18s[> ] 795/977, 9.9 task/s, elapsed: 80s, ETA:    18s[> ] 796/977, 9.9 task/s, elapsed: 80s, ETA:    18s[> ] 797/977, 9.9 task/s, elapsed: 80s, ETA:    18s[> ] 798/977, 9.9 task/s, elapsed: 80s, ETA:    18s[> ] 799/977, 9.9 task/s, elapsed: 80s, ETA:    18s[> ] 800/977, 10.0 task/s, elapsed: 80s, ETA:    18s[> ] 801/977, 10.0 task/s, elapsed: 81s, ETA:    18s[> ] 802/977, 10.0 task/s, elapsed: 81s, ETA:    18s[> ] 803/977, 10.0 task/s, elapsed: 81s, ETA:    17s[> ] 804/977, 10.0 task/s, elapsed: 81s, ETA:    17s[> ] 805/977, 10.0 task/s, elapsed: 81s, ETA:    17s[> ] 806/977, 10.0 task/s, elapsed: 81s, ETA:    17s[> ] 807/977, 10.0 task/s, elapsed: 81s, ETA:    17s[> ] 808/977, 10.0 task/s, elapsed: 81s, ETA:    17s[> ] 809/977, 10.0 task/s, elapsed: 81s, ETA:    17s[> ] 810/977, 10.0 task/s, elapsed: 81s, ETA:    17s[> ] 811/977, 10.0 task/s, elapsed: 82s, ETA:    17s[> ] 812/977, 9.9 task/s, elapsed: 82s, ETA:    17s[> ] 813/977, 9.9 task/s, elapsed: 82s, ETA:    16s[> ] 814/977, 9.9 task/s, elapsed: 82s, ETA:    16s[> ] 815/977, 9.9 task/s, elapsed: 82s, ETA:    16s[> ] 816/977, 9.9 task/s, elapsed: 82s, ETA:    16s[> ] 817/977, 9.9 task/s, elapsed: 82s, ETA:    16s[> ] 818/977, 9.9 task/s, elapsed: 82s, ETA:    16s[> ] 819/977, 9.9 task/s, elapsed: 82s, ETA:    16s[> ] 820/977, 9.9 task/s, elapsed: 82s, ETA:    16s[> ] 821/977, 9.9 task/s, elapsed: 83s, ETA:    16s[> ] 822/977, 9.9 task/s, elapsed: 83s, ETA:    16s[> ] 823/977, 9.9 task/s, elapsed: 83s, ETA:    15s[> ] 824/977, 9.9 task/s, elapsed: 83s, ETA:    15s[> ] 825/977, 9.9 task/s, elapsed: 83s, ETA:    15s[> ] 826/977, 9.9 task/s, elapsed: 83s, ETA:    15s[> ] 827/977, 9.9 task/s, elapsed: 83s, ETA:    15s[> ] 828/977, 9.9 task/s, elapsed: 83s, ETA:    15s[> ] 829/977, 9.9 task/s, elapsed: 83s, ETA:    15s[> ] 830/977, 9.9 task/s, elapsed: 83s, ETA:    15s[> ] 831/977, 9.9 task/s, elapsed: 84s, ETA:    15s[> ] 832/977, 9.9 task/s, elapsed: 84s, ETA:    15s[> ] 833/977, 9.9 task/s, elapsed: 84s, ETA:    14s[> ] 834/977, 10.0 task/s, elapsed: 84s, ETA:    14s[> ] 835/977, 10.0 task/s, elapsed: 84s, ETA:    14s[> ] 836/977, 10.0 task/s, elapsed: 84s, ETA:    14s[> ] 837/977, 10.0 task/s, elapsed: 84s, ETA:    14s[> ] 838/977, 10.0 task/s, elapsed: 84s, ETA:    14s[> ] 839/977, 10.0 task/s, elapsed: 84s, ETA:    14s[> ] 840/977, 10.0 task/s, elapsed: 84s, ETA:    14s[> ] 841/977, 10.0 task/s, elapsed: 85s, ETA:    14s[> ] 842/977, 10.0 task/s, elapsed: 85s, ETA:    14s[> ] 843/977, 10.0 task/s, elapsed: 85s, ETA:    13s[> ] 844/977, 10.0 task/s, elapsed: 85s, ETA:    13s[> ] 845/977, 10.0 task/s, elapsed: 85s, ETA:    13s[> ] 846/977, 10.0 task/s, elapsed: 85s, ETA:    13s[> ] 847/977, 10.0 task/s, elapsed: 85s, ETA:    13s[> ] 848/977, 10.0 task/s, elapsed: 85s, ETA:    13s[> ] 849/977, 10.0 task/s, elapsed: 85s, ETA:    13s[> ] 850/977, 10.0 task/s, elapsed: 85s, ETA:    13s[> ] 851/977, 10.0 task/s, elapsed: 85s, ETA:    13s[> ] 852/977, 10.0 task/s, elapsed: 86s, ETA:    13s[> ] 853/977, 10.0 task/s, elapsed: 86s, ETA:    12s[> ] 854/977, 10.0 task/s, elapsed: 86s, ETA:    12s[> ] 855/977, 10.0 task/s, elapsed: 86s, ETA:    12s[> ] 856/977, 10.0 task/s, elapsed: 86s, ETA:    12s[> ] 857/977, 10.0 task/s, elapsed: 86s, ETA:    12s[> ] 858/977, 10.0 task/s, elapsed: 86s, ETA:    12s[> ] 859/977, 10.0 task/s, elapsed: 86s, ETA:    12s[> ] 860/977, 10.0 task/s, elapsed: 86s, ETA:    12s[> ] 861/977, 10.0 task/s, elapsed: 87s, ETA:    12s[> ] 862/977, 10.0 task/s, elapsed: 87s, ETA:    12s[> ] 863/977, 10.0 task/s, elapsed: 87s, ETA:    11s[> ] 864/977, 10.0 task/s, elapsed: 87s, ETA:    11s[> ] 865/977, 10.0 task/s, elapsed: 87s, ETA:    11s[> ] 866/977, 10.0 task/s, elapsed: 87s, ETA:    11s[> ] 867/977, 10.0 task/s, elapsed: 87s, ETA:    11s[> ] 868/977, 10.0 task/s, elapsed: 87s, ETA:    11s[> ] 869/977, 10.0 task/s, elapsed: 87s, ETA:    11s[> ] 870/977, 10.0 task/s, elapsed: 87s, ETA:    11s[> ] 871/977, 10.0 task/s, elapsed: 88s, ETA:    11s[> ] 872/977, 10.0 task/s, elapsed: 88s, ETA:    11s[> ] 873/977, 10.0 task/s, elapsed: 88s, ETA:    10s[> ] 874/977, 10.0 task/s, elapsed: 88s, ETA:    10s[> ] 875/977, 10.0 task/s, elapsed: 88s, ETA:    10s[> ] 876/977, 10.0 task/s, elapsed: 88s, ETA:    10s[> ] 877/977, 10.0 task/s, elapsed: 88s, ETA:    10s[> ] 878/977, 10.0 task/s, elapsed: 88s, ETA:    10s[> ] 879/977, 10.0 task/s, elapsed: 88s, ETA:    10s[> ] 880/977, 10.0 task/s, elapsed: 88s, ETA:    10s[> ] 881/977, 10.0 task/s, elapsed: 89s, ETA:    10s[> ] 882/977, 10.0 task/s, elapsed: 89s, ETA:    10s[> ] 883/977, 10.0 task/s, elapsed: 89s, ETA:     9s[> ] 884/977, 10.0 task/s, elapsed: 89s, ETA:     9s[> ] 885/977, 10.0 task/s, elapsed: 89s, ETA:     9s[> ] 886/977, 10.0 task/s, elapsed: 89s, ETA:     9s[> ] 887/977, 10.0 task/s, elapsed: 89s, ETA:     9s[> ] 888/977, 10.0 task/s, elapsed: 89s, ETA:     9s[> ] 889/977, 10.0 task/s, elapsed: 89s, ETA:     9s[> ] 890/977, 10.0 task/s, elapsed: 89s, ETA:     9s[> ] 891/977, 10.0 task/s, elapsed: 90s, ETA:     9s[> ] 892/977, 10.0 task/s, elapsed: 90s, ETA:     9s[> ] 893/977, 10.0 task/s, elapsed: 90s, ETA:     8s[> ] 894/977, 10.0 task/s, elapsed: 90s, ETA:     8s[> ] 895/977, 10.0 task/s, elapsed: 90s, ETA:     8s[> ] 896/977, 10.0 task/s, elapsed: 90s, ETA:     8s[> ] 897/977, 9.9 task/s, elapsed: 90s, ETA:     8s[> ] 898/977, 9.9 task/s, elapsed: 90s, ETA:     8s[> ] 899/977, 9.9 task/s, elapsed: 90s, ETA:     8s[> ] 900/977, 9.9 task/s, elapsed: 90s, ETA:     8s[> ] 901/977, 9.9 task/s, elapsed: 91s, ETA:     8s[> ] 902/977, 9.9 task/s, elapsed: 91s, ETA:     8s[> ] 903/977, 9.9 task/s, elapsed: 91s, ETA:     7s[> ] 904/977, 9.9 task/s, elapsed: 91s, ETA:     7s[> ] 905/977, 10.0 task/s, elapsed: 91s, ETA:     7s[> ] 906/977, 10.0 task/s, elapsed: 91s, ETA:     7s[> ] 907/977, 10.0 task/s, elapsed: 91s, ETA:     7s[> ] 908/977, 10.0 task/s, elapsed: 91s, ETA:     7s[> ] 909/977, 10.0 task/s, elapsed: 91s, ETA:     7s[> ] 910/977, 10.0 task/s, elapsed: 91s, ETA:     7s[> ] 911/977, 10.0 task/s, elapsed: 92s, ETA:     7s[> ] 912/977, 10.0 task/s, elapsed: 92s, ETA:     7s[> ] 913/977, 10.0 task/s, elapsed: 92s, ETA:     6s[> ] 914/977, 10.0 task/s, elapsed: 92s, ETA:     6s[> ] 915/977, 10.0 task/s, elapsed: 92s, ETA:     6s[> ] 916/977, 10.0 task/s, elapsed: 92s, ETA:     6s[> ] 917/977, 10.0 task/s, elapsed: 92s, ETA:     6s[> ] 918/977, 10.0 task/s, elapsed: 92s, ETA:     6s[> ] 919/977, 10.0 task/s, elapsed: 92s, ETA:     6s[> ] 920/977, 10.0 task/s, elapsed: 92s, ETA:     6s[> ] 921/977, 10.0 task/s, elapsed: 93s, ETA:     6s[> ] 922/977, 10.0 task/s, elapsed: 93s, ETA:     6s[> ] 923/977, 10.0 task/s, elapsed: 93s, ETA:     5s[> ] 924/977, 10.0 task/s, elapsed: 93s, ETA:     5s[> ] 925/977, 10.0 task/s, elapsed: 93s, ETA:     5s[> ] 926/977, 10.0 task/s, elapsed: 93s, ETA:     5s[> ] 927/977, 10.0 task/s, elapsed: 93s, ETA:     5s[> ] 928/977, 10.0 task/s, elapsed: 93s, ETA:     5s[> ] 929/977, 10.0 task/s, elapsed: 93s, ETA:     5s[> ] 930/977, 10.0 task/s, elapsed: 93s, ETA:     5s[> ] 931/977, 10.0 task/s, elapsed: 94s, ETA:     5s[> ] 932/977, 10.0 task/s, elapsed: 94s, ETA:     5s[> ] 933/977, 10.0 task/s, elapsed: 94s, ETA:     4s[> ] 934/977, 10.0 task/s, elapsed: 94s, ETA:     4s[> ] 935/977, 10.0 task/s, elapsed: 94s, ETA:     4s[> ] 936/977, 10.0 task/s, elapsed: 94s, ETA:     4s[> ] 937/977, 10.0 task/s, elapsed: 94s, ETA:     4s[> ] 938/977, 10.0 task/s, elapsed: 94s, ETA:     4s[> ] 939/977, 10.0 task/s, elapsed: 94s, ETA:     4s[> ] 940/977, 10.0 task/s, elapsed: 94s, ETA:     4s[> ] 941/977, 10.0 task/s, elapsed: 95s, ETA:     4s[> ] 942/977, 10.0 task/s, elapsed: 95s, ETA:     4s[> ] 943/977, 10.0 task/s, elapsed: 95s, ETA:     3s[> ] 944/977, 10.0 task/s, elapsed: 95s, ETA:     3s[> ] 945/977, 10.0 task/s, elapsed: 95s, ETA:     3s[> ] 946/977, 10.0 task/s, elapsed: 95s, ETA:     3s[> ] 947/977, 9.9 task/s, elapsed: 95s, ETA:     3s[> ] 948/977, 9.9 task/s, elapsed: 95s, ETA:     3s[> ] 949/977, 9.9 task/s, elapsed: 95s, ETA:     3s[> ] 950/977, 9.9 task/s, elapsed: 95s, ETA:     3s[> ] 951/977, 9.9 task/s, elapsed: 96s, ETA:     3s[> ] 952/977, 9.9 task/s, elapsed: 96s, ETA:     3s[> ] 953/977, 9.9 task/s, elapsed: 96s, ETA:     2s[> ] 954/977, 9.9 task/s, elapsed: 96s, ETA:     2s[> ] 955/977, 9.9 task/s, elapsed: 96s, ETA:     2s[> ] 956/977, 9.9 task/s, elapsed: 96s, ETA:     2s[> ] 957/977, 9.9 task/s, elapsed: 96s, ETA:     2s[> ] 958/977, 9.9 task/s, elapsed: 96s, ETA:     2s[> ] 959/977, 9.9 task/s, elapsed: 96s, ETA:     2s[> ] 960/977, 9.9 task/s, elapsed: 97s, ETA:     2s[> ] 961/977, 9.9 task/s, elapsed: 97s, ETA:     2s[> ] 962/977, 9.9 task/s, elapsed: 97s, ETA:     2s[> ] 963/977, 9.9 task/s, elapsed: 97s, ETA:     1s[> ] 964/977, 9.9 task/s, elapsed: 97s, ETA:     1s[> ] 965/977, 9.9 task/s, elapsed: 97s, ETA:     1s[> ] 966/977, 9.9 task/s, elapsed: 97s, ETA:     1s[> ] 967/977, 9.9 task/s, elapsed: 97s, ETA:     1s[> ] 968/977, 9.9 task/s, elapsed: 97s, ETA:     1s[> ] 969/977, 9.9 task/s, elapsed: 97s, ETA:     1s[> ] 970/977, 9.9 task/s, elapsed: 98s, ETA:     1s[> ] 971/977, 9.9 task/s, elapsed: 98s, ETA:     1s[> ] 972/977, 9.9 task/s, elapsed: 98s, ETA:     1s[> ] 973/977, 9.9 task/s, elapsed: 98s, ETA:     0s[> ] 974/977, 9.9 task/s, elapsed: 98s, ETA:     0s[> ] 975/977, 9.9 task/s, elapsed: 98s, ETA:     0s[> ] 976/977, 9.9 task/s, elapsed: 98s, ETA:     0s[>>] 977/977, 9.9 task/s, elapsed: 98s, ETA:     0s2021-09-29 13:17:18,256 - mmdet - INFO - Evaluating bbox...
2021-09-29 13:17:19,408 - mmdet - INFO - Exp name: waste_hrnet_16.py
2021-09-29 13:17:19,409 - mmdet - INFO - Epoch(val) [2][977]	bbox_mAP: 0.0020, bbox_mAP_50: 0.0080, bbox_mAP_75: 0.0010, bbox_mAP_s: 0.0000, bbox_mAP_m: 0.0000, bbox_mAP_l: 0.0030, bbox_mAP_copypaste: 0.002 0.008 0.001 0.000 0.000 0.003
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.94s).
Accumulating evaluation results...
DONE (t=0.18s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.008
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.003
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.008
2021-09-29 13:17:50,391 - mmdet - INFO - Epoch [3][10/245]	lr: 9.943e-05, eta: 8:58:28, time: 3.095, data_time: 0.321, memory: 29438, loss_rpn_cls: 0.0951, loss_rpn_bbox: 0.1774, s0.loss_cls: 0.1885, s0.acc: 95.7922, s0.loss_bbox: 0.0865, s1.loss_cls: 0.0493, s1.acc: 97.9553, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0145, s2.acc: 98.7610, s2.loss_bbox: 0.0100, loss: 0.6473, grad_norm: 1.5240
2021-09-29 13:18:18,639 - mmdet - INFO - Epoch [3][20/245]	lr: 9.961e-05, eta: 8:58:18, time: 2.825, data_time: 0.029, memory: 29438, loss_rpn_cls: 0.0836, loss_rpn_bbox: 0.1618, s0.loss_cls: 0.1722, s0.acc: 95.9827, s0.loss_bbox: 0.0823, s1.loss_cls: 0.0410, s1.acc: 98.2483, s1.loss_bbox: 0.0221, s2.loss_cls: 0.0118, s2.acc: 98.9795, s2.loss_bbox: 0.0085, loss: 0.5831, grad_norm: 1.4260
2021-09-29 13:18:46,536 - mmdet - INFO - Epoch [3][30/245]	lr: 9.961e-05, eta: 8:57:59, time: 2.790, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0758, loss_rpn_bbox: 0.1384, s0.loss_cls: 0.1710, s0.acc: 96.2415, s0.loss_bbox: 0.0804, s1.loss_cls: 0.0426, s1.acc: 98.3032, s1.loss_bbox: 0.0226, s2.loss_cls: 0.0112, s2.acc: 99.0808, s2.loss_bbox: 0.0076, loss: 0.5497, grad_norm: 1.3003
2021-09-29 13:19:14,269 - mmdet - INFO - Epoch [3][40/245]	lr: 9.961e-05, eta: 8:57:37, time: 2.773, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0878, loss_rpn_bbox: 0.1632, s0.loss_cls: 0.1896, s0.acc: 95.6543, s0.loss_bbox: 0.0886, s1.loss_cls: 0.0492, s1.acc: 97.9810, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0143, s2.acc: 98.8171, s2.loss_bbox: 0.0094, loss: 0.6280, grad_norm: 1.5690
2021-09-29 13:19:42,059 - mmdet - INFO - Epoch [3][50/245]	lr: 9.961e-05, eta: 8:57:15, time: 2.779, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0939, loss_rpn_bbox: 0.2002, s0.loss_cls: 0.2064, s0.acc: 95.1367, s0.loss_bbox: 0.1004, s1.loss_cls: 0.0483, s1.acc: 97.9211, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0134, s2.acc: 98.8135, s2.loss_bbox: 0.0099, loss: 0.6993, grad_norm: 1.5887
2021-09-29 13:20:09,603 - mmdet - INFO - Epoch [3][60/245]	lr: 9.961e-05, eta: 8:56:48, time: 2.754, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0983, loss_rpn_bbox: 0.1984, s0.loss_cls: 0.2079, s0.acc: 94.9573, s0.loss_bbox: 0.1029, s1.loss_cls: 0.0481, s1.acc: 97.9407, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0136, s2.acc: 98.7732, s2.loss_bbox: 0.0103, loss: 0.7059, grad_norm: 2.1655
2021-09-29 13:20:37,377 - mmdet - INFO - Epoch [3][70/245]	lr: 9.961e-05, eta: 8:56:25, time: 2.777, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1010, loss_rpn_bbox: 0.1773, s0.loss_cls: 0.2144, s0.acc: 94.8840, s0.loss_bbox: 0.1052, s1.loss_cls: 0.0507, s1.acc: 97.8040, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0152, s2.acc: 98.7329, s2.loss_bbox: 0.0105, loss: 0.7025, grad_norm: 1.7882
2021-09-29 13:21:04,518 - mmdet - INFO - Epoch [3][80/245]	lr: 9.961e-05, eta: 8:55:50, time: 2.714, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1082, loss_rpn_bbox: 0.2118, s0.loss_cls: 0.1982, s0.acc: 95.3040, s0.loss_bbox: 0.0949, s1.loss_cls: 0.0430, s1.acc: 98.1189, s1.loss_bbox: 0.0244, s2.loss_cls: 0.0113, s2.acc: 98.9185, s2.loss_bbox: 0.0100, loss: 0.7018, grad_norm: 1.7868
2021-09-29 13:21:32,433 - mmdet - INFO - Epoch [3][90/245]	lr: 9.961e-05, eta: 8:55:30, time: 2.792, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0946, loss_rpn_bbox: 0.1766, s0.loss_cls: 0.2052, s0.acc: 95.3955, s0.loss_bbox: 0.0968, s1.loss_cls: 0.0473, s1.acc: 97.9260, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0140, s2.acc: 98.7219, s2.loss_bbox: 0.0110, loss: 0.6724, grad_norm: 1.9430
2021-09-29 13:22:00,203 - mmdet - INFO - Epoch [3][100/245]	lr: 9.961e-05, eta: 8:55:07, time: 2.777, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0886, loss_rpn_bbox: 0.1838, s0.loss_cls: 0.2219, s0.acc: 94.8071, s0.loss_bbox: 0.1062, s1.loss_cls: 0.0566, s1.acc: 97.7002, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0154, s2.acc: 98.7061, s2.loss_bbox: 0.0103, loss: 0.7125, grad_norm: 1.9778
2021-09-29 13:22:27,959 - mmdet - INFO - Epoch [3][110/245]	lr: 9.961e-05, eta: 8:54:44, time: 2.776, data_time: 0.029, memory: 29438, loss_rpn_cls: 0.0931, loss_rpn_bbox: 0.1736, s0.loss_cls: 0.1959, s0.acc: 95.3418, s0.loss_bbox: 0.0991, s1.loss_cls: 0.0543, s1.acc: 97.7368, s1.loss_bbox: 0.0294, s2.loss_cls: 0.0169, s2.acc: 98.5730, s2.loss_bbox: 0.0117, loss: 0.6740, grad_norm: 1.6788
2021-09-29 13:22:55,711 - mmdet - INFO - Epoch [3][120/245]	lr: 9.961e-05, eta: 8:54:20, time: 2.775, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.0910, loss_rpn_bbox: 0.1760, s0.loss_cls: 0.1826, s0.acc: 95.6567, s0.loss_bbox: 0.0933, s1.loss_cls: 0.0440, s1.acc: 98.0676, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0115, s2.acc: 98.9648, s2.loss_bbox: 0.0091, loss: 0.6329, grad_norm: 1.5421
2021-09-29 13:23:23,295 - mmdet - INFO - Epoch [3][130/245]	lr: 9.961e-05, eta: 8:53:53, time: 2.758, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1051, loss_rpn_bbox: 0.2145, s0.loss_cls: 0.2075, s0.acc: 94.8877, s0.loss_bbox: 0.1057, s1.loss_cls: 0.0526, s1.acc: 97.6538, s1.loss_bbox: 0.0309, s2.loss_cls: 0.0150, s2.acc: 98.6731, s2.loss_bbox: 0.0121, loss: 0.7434, grad_norm: 1.5185
2021-09-29 13:23:50,937 - mmdet - INFO - Epoch [3][140/245]	lr: 9.961e-05, eta: 8:53:28, time: 2.764, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0844, loss_rpn_bbox: 0.1688, s0.loss_cls: 0.1739, s0.acc: 95.8301, s0.loss_bbox: 0.0873, s1.loss_cls: 0.0404, s1.acc: 98.2581, s1.loss_bbox: 0.0231, s2.loss_cls: 0.0108, s2.acc: 98.9709, s2.loss_bbox: 0.0089, loss: 0.5975, grad_norm: 1.4297
2021-09-29 13:24:18,760 - mmdet - INFO - Epoch [3][150/245]	lr: 9.961e-05, eta: 8:53:05, time: 2.782, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0876, loss_rpn_bbox: 0.1806, s0.loss_cls: 0.2014, s0.acc: 95.1245, s0.loss_bbox: 0.1010, s1.loss_cls: 0.0500, s1.acc: 97.7759, s1.loss_bbox: 0.0294, s2.loss_cls: 0.0140, s2.acc: 98.7781, s2.loss_bbox: 0.0110, loss: 0.6751, grad_norm: 1.7385
2021-09-29 13:24:46,758 - mmdet - INFO - Epoch [3][160/245]	lr: 9.961e-05, eta: 8:52:46, time: 2.800, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0734, loss_rpn_bbox: 0.1499, s0.loss_cls: 0.1681, s0.acc: 95.9998, s0.loss_bbox: 0.0833, s1.loss_cls: 0.0385, s1.acc: 98.3777, s1.loss_bbox: 0.0215, s2.loss_cls: 0.0092, s2.acc: 99.1638, s2.loss_bbox: 0.0074, loss: 0.5512, grad_norm: 1.4909
2021-09-29 13:25:14,416 - mmdet - INFO - Epoch [3][170/245]	lr: 9.961e-05, eta: 8:52:20, time: 2.766, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0772, loss_rpn_bbox: 0.1863, s0.loss_cls: 0.2023, s0.acc: 95.2319, s0.loss_bbox: 0.0993, s1.loss_cls: 0.0486, s1.acc: 97.9651, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0144, s2.acc: 98.8159, s2.loss_bbox: 0.0104, loss: 0.6652, grad_norm: 1.6010
2021-09-29 13:25:42,173 - mmdet - INFO - Epoch [3][180/245]	lr: 9.961e-05, eta: 8:51:56, time: 2.776, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.0980, loss_rpn_bbox: 0.1770, s0.loss_cls: 0.1925, s0.acc: 95.5615, s0.loss_bbox: 0.0920, s1.loss_cls: 0.0449, s1.acc: 98.0615, s1.loss_bbox: 0.0253, s2.loss_cls: 0.0131, s2.acc: 98.8354, s2.loss_bbox: 0.0101, loss: 0.6529, grad_norm: 1.5732
2021-09-29 13:26:09,563 - mmdet - INFO - Epoch [3][190/245]	lr: 9.961e-05, eta: 8:51:25, time: 2.739, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0922, loss_rpn_bbox: 0.1667, s0.loss_cls: 0.2250, s0.acc: 94.9805, s0.loss_bbox: 0.1038, s1.loss_cls: 0.0576, s1.acc: 97.6721, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0159, s2.acc: 98.7207, s2.loss_bbox: 0.0104, loss: 0.7013, grad_norm: 1.8672
2021-09-29 13:26:37,315 - mmdet - INFO - Epoch [3][200/245]	lr: 9.961e-05, eta: 8:51:01, time: 2.775, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1002, loss_rpn_bbox: 0.1775, s0.loss_cls: 0.1966, s0.acc: 95.3137, s0.loss_bbox: 0.0958, s1.loss_cls: 0.0449, s1.acc: 98.0371, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0129, s2.acc: 98.8647, s2.loss_bbox: 0.0100, loss: 0.6635, grad_norm: 1.5065
2021-09-29 13:27:04,908 - mmdet - INFO - Epoch [3][210/245]	lr: 9.961e-05, eta: 8:50:34, time: 2.759, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0923, loss_rpn_bbox: 0.1901, s0.loss_cls: 0.1983, s0.acc: 95.1001, s0.loss_bbox: 0.1010, s1.loss_cls: 0.0494, s1.acc: 97.8149, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0131, s2.acc: 98.8232, s2.loss_bbox: 0.0105, loss: 0.6832, grad_norm: 1.3511
2021-09-29 13:27:32,760 - mmdet - INFO - Epoch [3][220/245]	lr: 9.961e-05, eta: 8:50:11, time: 2.785, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0843, loss_rpn_bbox: 0.1781, s0.loss_cls: 0.1980, s0.acc: 95.4419, s0.loss_bbox: 0.0957, s1.loss_cls: 0.0527, s1.acc: 97.8076, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0158, s2.acc: 98.7329, s2.loss_bbox: 0.0110, loss: 0.6642, grad_norm: 1.8298
2021-09-29 13:28:00,382 - mmdet - INFO - Epoch [3][230/245]	lr: 9.961e-05, eta: 8:49:44, time: 2.762, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0727, loss_rpn_bbox: 0.1636, s0.loss_cls: 0.1539, s0.acc: 96.4136, s0.loss_bbox: 0.0772, s1.loss_cls: 0.0436, s1.acc: 97.9724, s1.loss_bbox: 0.0276, s2.loss_cls: 0.0120, s2.acc: 98.8623, s2.loss_bbox: 0.0104, loss: 0.5610, grad_norm: 1.4352
2021-09-29 13:28:28,071 - mmdet - INFO - Epoch [3][240/245]	lr: 9.961e-05, eta: 8:49:19, time: 2.769, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.1074, loss_rpn_bbox: 0.1970, s0.loss_cls: 0.1768, s0.acc: 95.7007, s0.loss_bbox: 0.0912, s1.loss_cls: 0.0447, s1.acc: 98.0994, s1.loss_bbox: 0.0256, s2.loss_cls: 0.0128, s2.acc: 98.9490, s2.loss_bbox: 0.0101, loss: 0.6656, grad_norm: 1.6412
2021-09-29 13:28:41,581 - mmdet - INFO - Saving checkpoint at 3 epochs
[                                                  ] 0/977, elapsed: 0s, ETA:[  ] 1/977, 4.1 task/s, elapsed: 0s, ETA:   238s[  ] 2/977, 5.8 task/s, elapsed: 0s, ETA:   168s[  ] 3/977, 6.8 task/s, elapsed: 0s, ETA:   144s[  ] 4/977, 7.4 task/s, elapsed: 1s, ETA:   132s[  ] 5/977, 7.8 task/s, elapsed: 1s, ETA:   125s[  ] 6/977, 8.1 task/s, elapsed: 1s, ETA:   120s[  ] 7/977, 8.2 task/s, elapsed: 1s, ETA:   118s[  ] 8/977, 8.4 task/s, elapsed: 1s, ETA:   115s[  ] 9/977, 8.4 task/s, elapsed: 1s, ETA:   115s[  ] 10/977, 8.4 task/s, elapsed: 1s, ETA:   114s[  ] 11/977, 8.5 task/s, elapsed: 1s, ETA:   114s[  ] 12/977, 8.5 task/s, elapsed: 1s, ETA:   114s[  ] 13/977, 8.5 task/s, elapsed: 2s, ETA:   114s[  ] 14/977, 8.5 task/s, elapsed: 2s, ETA:   113s[  ] 15/977, 8.5 task/s, elapsed: 2s, ETA:   113s[  ] 16/977, 8.5 task/s, elapsed: 2s, ETA:   113s[  ] 17/977, 8.5 task/s, elapsed: 2s, ETA:   112s[  ] 18/977, 8.5 task/s, elapsed: 2s, ETA:   112s[  ] 19/977, 8.6 task/s, elapsed: 2s, ETA:   112s[  ] 20/977, 8.6 task/s, elapsed: 2s, ETA:   111s[  ] 21/977, 8.7 task/s, elapsed: 2s, ETA:   110s[  ] 22/977, 8.7 task/s, elapsed: 3s, ETA:   110s[  ] 23/977, 8.7 task/s, elapsed: 3s, ETA:   109s[  ] 24/977, 8.8 task/s, elapsed: 3s, ETA:   109s[  ] 25/977, 8.8 task/s, elapsed: 3s, ETA:   108s[  ] 26/977, 8.8 task/s, elapsed: 3s, ETA:   108s[  ] 27/977, 8.8 task/s, elapsed: 3s, ETA:   107s[  ] 28/977, 8.9 task/s, elapsed: 3s, ETA:   107s[  ] 29/977, 8.9 task/s, elapsed: 3s, ETA:   107s[  ] 30/977, 8.9 task/s, elapsed: 3s, ETA:   106s[  ] 31/977, 8.9 task/s, elapsed: 3s, ETA:   106s[  ] 32/977, 8.9 task/s, elapsed: 4s, ETA:   106s[  ] 33/977, 9.0 task/s, elapsed: 4s, ETA:   105s[  ] 34/977, 9.0 task/s, elapsed: 4s, ETA:   105s[  ] 35/977, 9.0 task/s, elapsed: 4s, ETA:   105s[  ] 36/977, 9.0 task/s, elapsed: 4s, ETA:   104s[  ] 37/977, 9.0 task/s, elapsed: 4s, ETA:   104s[  ] 38/977, 9.1 task/s, elapsed: 4s, ETA:   104s[  ] 39/977, 9.1 task/s, elapsed: 4s, ETA:   103s[  ] 40/977, 9.1 task/s, elapsed: 4s, ETA:   103s[  ] 41/977, 9.1 task/s, elapsed: 4s, ETA:   103s[  ] 42/977, 9.1 task/s, elapsed: 5s, ETA:   102s[  ] 43/977, 9.2 task/s, elapsed: 5s, ETA:   102s[  ] 44/977, 9.2 task/s, elapsed: 5s, ETA:   102s[  ] 45/977, 9.2 task/s, elapsed: 5s, ETA:   102s[  ] 46/977, 9.2 task/s, elapsed: 5s, ETA:   102s[  ] 47/977, 9.1 task/s, elapsed: 5s, ETA:   102s[  ] 48/977, 9.1 task/s, elapsed: 5s, ETA:   102s[  ] 49/977, 9.1 task/s, elapsed: 5s, ETA:   102s[  ] 50/977, 9.1 task/s, elapsed: 5s, ETA:   102s[  ] 51/977, 9.1 task/s, elapsed: 6s, ETA:   102s[  ] 52/977, 9.1 task/s, elapsed: 6s, ETA:   102s[  ] 53/977, 9.1 task/s, elapsed: 6s, ETA:   102s[  ] 54/977, 9.1 task/s, elapsed: 6s, ETA:   102s[  ] 55/977, 9.1 task/s, elapsed: 6s, ETA:   102s[  ] 56/977, 9.0 task/s, elapsed: 6s, ETA:   102s[  ] 57/977, 9.0 task/s, elapsed: 6s, ETA:   102s[  ] 58/977, 9.1 task/s, elapsed: 6s, ETA:   102s[  ] 59/977, 9.1 task/s, elapsed: 7s, ETA:   101s[  ] 60/977, 9.1 task/s, elapsed: 7s, ETA:   101s[  ] 61/977, 9.1 task/s, elapsed: 7s, ETA:   101s[  ] 62/977, 9.1 task/s, elapsed: 7s, ETA:   101s[  ] 63/977, 9.1 task/s, elapsed: 7s, ETA:   100s[  ] 64/977, 9.1 task/s, elapsed: 7s, ETA:   100s[  ] 65/977, 9.1 task/s, elapsed: 7s, ETA:   100s[  ] 66/977, 9.1 task/s, elapsed: 7s, ETA:   100s[  ] 67/977, 9.1 task/s, elapsed: 7s, ETA:    99s[  ] 68/977, 9.2 task/s, elapsed: 7s, ETA:    99s[  ] 69/977, 9.2 task/s, elapsed: 8s, ETA:    99s[  ] 70/977, 9.2 task/s, elapsed: 8s, ETA:    99s[  ] 71/977, 9.2 task/s, elapsed: 8s, ETA:    99s[  ] 72/977, 9.2 task/s, elapsed: 8s, ETA:    98s[  ] 73/977, 9.2 task/s, elapsed: 8s, ETA:    98s[  ] 74/977, 9.2 task/s, elapsed: 8s, ETA:    98s[  ] 75/977, 9.2 task/s, elapsed: 8s, ETA:    98s[  ] 76/977, 9.2 task/s, elapsed: 8s, ETA:    98s[  ] 77/977, 9.2 task/s, elapsed: 8s, ETA:    97s[  ] 78/977, 9.2 task/s, elapsed: 8s, ETA:    97s[  ] 79/977, 9.3 task/s, elapsed: 9s, ETA:    97s[  ] 80/977, 9.3 task/s, elapsed: 9s, ETA:    97s[  ] 81/977, 9.2 task/s, elapsed: 9s, ETA:    97s[  ] 82/977, 9.2 task/s, elapsed: 9s, ETA:    97s[  ] 83/977, 9.2 task/s, elapsed: 9s, ETA:    97s[  ] 84/977, 9.2 task/s, elapsed: 9s, ETA:    97s[  ] 85/977, 9.2 task/s, elapsed: 9s, ETA:    97s[  ] 86/977, 9.2 task/s, elapsed: 9s, ETA:    97s[  ] 87/977, 9.2 task/s, elapsed: 9s, ETA:    97s[  ] 88/977, 9.2 task/s, elapsed: 10s, ETA:    97s[  ] 89/977, 9.2 task/s, elapsed: 10s, ETA:    97s[  ] 90/977, 9.2 task/s, elapsed: 10s, ETA:    97s[  ] 91/977, 9.2 task/s, elapsed: 10s, ETA:    97s[  ] 92/977, 9.2 task/s, elapsed: 10s, ETA:    97s[  ] 93/977, 9.2 task/s, elapsed: 10s, ETA:    97s[  ] 94/977, 9.2 task/s, elapsed: 10s, ETA:    96s[  ] 95/977, 9.2 task/s, elapsed: 10s, ETA:    96s[  ] 96/977, 9.2 task/s, elapsed: 10s, ETA:    96s[  ] 97/977, 9.2 task/s, elapsed: 11s, ETA:    96s[  ] 98/977, 9.2 task/s, elapsed: 11s, ETA:    96s[  ] 99/977, 9.2 task/s, elapsed: 11s, ETA:    95s[  ] 100/977, 9.2 task/s, elapsed: 11s, ETA:    95s[  ] 101/977, 9.2 task/s, elapsed: 11s, ETA:    95s[  ] 102/977, 9.2 task/s, elapsed: 11s, ETA:    95s[  ] 103/977, 9.2 task/s, elapsed: 11s, ETA:    95s[  ] 104/977, 9.2 task/s, elapsed: 11s, ETA:    95s[  ] 105/977, 9.2 task/s, elapsed: 11s, ETA:    94s[  ] 106/977, 9.2 task/s, elapsed: 11s, ETA:    94s[  ] 107/977, 9.3 task/s, elapsed: 12s, ETA:    94s[  ] 108/977, 9.3 task/s, elapsed: 12s, ETA:    94s[  ] 109/977, 9.3 task/s, elapsed: 12s, ETA:    94s[  ] 110/977, 9.3 task/s, elapsed: 12s, ETA:    93s[  ] 111/977, 9.3 task/s, elapsed: 12s, ETA:    93s[  ] 112/977, 9.3 task/s, elapsed: 12s, ETA:    93s[  ] 113/977, 9.3 task/s, elapsed: 12s, ETA:    93s[  ] 114/977, 9.3 task/s, elapsed: 12s, ETA:    93s[  ] 115/977, 9.3 task/s, elapsed: 12s, ETA:    93s[  ] 116/977, 9.3 task/s, elapsed: 12s, ETA:    92s[  ] 117/977, 9.3 task/s, elapsed: 13s, ETA:    92s[  ] 118/977, 9.3 task/s, elapsed: 13s, ETA:    92s[  ] 119/977, 9.3 task/s, elapsed: 13s, ETA:    92s[  ] 120/977, 9.3 task/s, elapsed: 13s, ETA:    92s[  ] 121/977, 9.3 task/s, elapsed: 13s, ETA:    92s[  ] 122/977, 9.3 task/s, elapsed: 13s, ETA:    91s[  ] 123/977, 9.4 task/s, elapsed: 13s, ETA:    91s[  ] 124/977, 9.4 task/s, elapsed: 13s, ETA:    91s[  ] 125/977, 9.4 task/s, elapsed: 13s, ETA:    91s[  ] 126/977, 9.4 task/s, elapsed: 13s, ETA:    91s[  ] 127/977, 9.4 task/s, elapsed: 14s, ETA:    91s[  ] 128/977, 9.4 task/s, elapsed: 14s, ETA:    91s[  ] 129/977, 9.4 task/s, elapsed: 14s, ETA:    91s[  ] 130/977, 9.4 task/s, elapsed: 14s, ETA:    90s[  ] 131/977, 9.4 task/s, elapsed: 14s, ETA:    90s[  ] 132/977, 9.4 task/s, elapsed: 14s, ETA:    90s[  ] 133/977, 9.4 task/s, elapsed: 14s, ETA:    90s[  ] 134/977, 9.4 task/s, elapsed: 14s, ETA:    90s[  ] 135/977, 9.4 task/s, elapsed: 14s, ETA:    90s[  ] 136/977, 9.4 task/s, elapsed: 14s, ETA:    90s[  ] 137/977, 9.4 task/s, elapsed: 15s, ETA:    89s[  ] 138/977, 9.4 task/s, elapsed: 15s, ETA:    89s[  ] 139/977, 9.4 task/s, elapsed: 15s, ETA:    89s[  ] 140/977, 9.4 task/s, elapsed: 15s, ETA:    89s[  ] 141/977, 9.4 task/s, elapsed: 15s, ETA:    89s[  ] 142/977, 9.4 task/s, elapsed: 15s, ETA:    89s[  ] 143/977, 9.4 task/s, elapsed: 15s, ETA:    89s[  ] 144/977, 9.4 task/s, elapsed: 15s, ETA:    88s[  ] 145/977, 9.4 task/s, elapsed: 15s, ETA:    88s[  ] 146/977, 9.4 task/s, elapsed: 15s, ETA:    88s[  ] 147/977, 9.4 task/s, elapsed: 16s, ETA:    88s[  ] 148/977, 9.4 task/s, elapsed: 16s, ETA:    88s[  ] 149/977, 9.4 task/s, elapsed: 16s, ETA:    88s[  ] 150/977, 9.4 task/s, elapsed: 16s, ETA:    88s[  ] 151/977, 9.4 task/s, elapsed: 16s, ETA:    88s[  ] 152/977, 9.4 task/s, elapsed: 16s, ETA:    87s[  ] 153/977, 9.4 task/s, elapsed: 16s, ETA:    87s[  ] 154/977, 9.4 task/s, elapsed: 16s, ETA:    87s[  ] 155/977, 9.4 task/s, elapsed: 16s, ETA:    87s[  ] 156/977, 9.5 task/s, elapsed: 17s, ETA:    87s[  ] 157/977, 9.5 task/s, elapsed: 17s, ETA:    87s[  ] 158/977, 9.5 task/s, elapsed: 17s, ETA:    87s[  ] 159/977, 9.5 task/s, elapsed: 17s, ETA:    86s[  ] 160/977, 9.5 task/s, elapsed: 17s, ETA:    86s[  ] 161/977, 9.5 task/s, elapsed: 17s, ETA:    86s[  ] 162/977, 9.5 task/s, elapsed: 17s, ETA:    86s[  ] 163/977, 9.5 task/s, elapsed: 17s, ETA:    86s[  ] 164/977, 9.5 task/s, elapsed: 17s, ETA:    86s[  ] 165/977, 9.5 task/s, elapsed: 17s, ETA:    86s[  ] 166/977, 9.5 task/s, elapsed: 18s, ETA:    86s[  ] 167/977, 9.5 task/s, elapsed: 18s, ETA:    85s[  ] 168/977, 9.5 task/s, elapsed: 18s, ETA:    85s[  ] 169/977, 9.5 task/s, elapsed: 18s, ETA:    85s[  ] 170/977, 9.5 task/s, elapsed: 18s, ETA:    85s[  ] 171/977, 9.5 task/s, elapsed: 18s, ETA:    85s[  ] 172/977, 9.5 task/s, elapsed: 18s, ETA:    85s[  ] 173/977, 9.5 task/s, elapsed: 18s, ETA:    85s[  ] 174/977, 9.5 task/s, elapsed: 18s, ETA:    85s[  ] 175/977, 9.5 task/s, elapsed: 18s, ETA:    84s[  ] 176/977, 9.5 task/s, elapsed: 19s, ETA:    84s[  ] 177/977, 9.5 task/s, elapsed: 19s, ETA:    84s[  ] 178/977, 9.5 task/s, elapsed: 19s, ETA:    84s[  ] 179/977, 9.5 task/s, elapsed: 19s, ETA:    84s[  ] 180/977, 9.5 task/s, elapsed: 19s, ETA:    84s[  ] 181/977, 9.5 task/s, elapsed: 19s, ETA:    84s[  ] 182/977, 9.5 task/s, elapsed: 19s, ETA:    84s[  ] 183/977, 9.5 task/s, elapsed: 19s, ETA:    84s[  ] 184/977, 9.5 task/s, elapsed: 19s, ETA:    83s[  ] 185/977, 9.5 task/s, elapsed: 19s, ETA:    83s[  ] 186/977, 9.5 task/s, elapsed: 20s, ETA:    83s[  ] 187/977, 9.5 task/s, elapsed: 20s, ETA:    83s[  ] 188/977, 9.5 task/s, elapsed: 20s, ETA:    83s[  ] 189/977, 9.5 task/s, elapsed: 20s, ETA:    83s[  ] 190/977, 9.5 task/s, elapsed: 20s, ETA:    83s[  ] 191/977, 9.5 task/s, elapsed: 20s, ETA:    83s[  ] 192/977, 9.5 task/s, elapsed: 20s, ETA:    82s[  ] 193/977, 9.5 task/s, elapsed: 20s, ETA:    82s[  ] 194/977, 9.5 task/s, elapsed: 20s, ETA:    82s[  ] 195/977, 9.5 task/s, elapsed: 20s, ETA:    82s[  ] 196/977, 9.5 task/s, elapsed: 21s, ETA:    82s[  ] 197/977, 9.5 task/s, elapsed: 21s, ETA:    82s[  ] 198/977, 9.5 task/s, elapsed: 21s, ETA:    82s[  ] 199/977, 9.5 task/s, elapsed: 21s, ETA:    82s[  ] 200/977, 9.5 task/s, elapsed: 21s, ETA:    81s[  ] 201/977, 9.5 task/s, elapsed: 21s, ETA:    81s[  ] 202/977, 9.5 task/s, elapsed: 21s, ETA:    81s[  ] 203/977, 9.5 task/s, elapsed: 21s, ETA:    81s[  ] 204/977, 9.5 task/s, elapsed: 21s, ETA:    81s[  ] 205/977, 9.5 task/s, elapsed: 21s, ETA:    81s[  ] 206/977, 9.6 task/s, elapsed: 22s, ETA:    81s[  ] 207/977, 9.6 task/s, elapsed: 22s, ETA:    81s[  ] 208/977, 9.6 task/s, elapsed: 22s, ETA:    81s[  ] 209/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 210/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 211/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 212/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 213/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 214/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 215/977, 9.6 task/s, elapsed: 22s, ETA:    80s[  ] 216/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 217/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 218/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 219/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 220/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 221/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 222/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 223/977, 9.6 task/s, elapsed: 23s, ETA:    79s[  ] 224/977, 9.6 task/s, elapsed: 23s, ETA:    78s[  ] 225/977, 9.6 task/s, elapsed: 23s, ETA:    78s[  ] 226/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 227/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 228/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 229/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 230/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 231/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 232/977, 9.6 task/s, elapsed: 24s, ETA:    78s[  ] 233/977, 9.6 task/s, elapsed: 24s, ETA:    77s[  ] 234/977, 9.6 task/s, elapsed: 24s, ETA:    77s[  ] 235/977, 9.6 task/s, elapsed: 24s, ETA:    77s[  ] 236/977, 9.6 task/s, elapsed: 25s, ETA:    77s[  ] 237/977, 9.6 task/s, elapsed: 25s, ETA:    77s[  ] 238/977, 9.6 task/s, elapsed: 25s, ETA:    77s[  ] 239/977, 9.6 task/s, elapsed: 25s, ETA:    77s[  ] 240/977, 9.6 task/s, elapsed: 25s, ETA:    77s[  ] 241/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 242/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 243/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 244/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 245/977, 9.6 task/s, elapsed: 25s, ETA:    76s[  ] 246/977, 9.6 task/s, elapsed: 26s, ETA:    76s[  ] 247/977, 9.6 task/s, elapsed: 26s, ETA:    76s[  ] 248/977, 9.6 task/s, elapsed: 26s, ETA:    76s[  ] 249/977, 9.6 task/s, elapsed: 26s, ETA:    76s[  ] 250/977, 9.6 task/s, elapsed: 26s, ETA:    75s[  ] 251/977, 9.6 task/s, elapsed: 26s, ETA:    75s[  ] 252/977, 9.6 task/s, elapsed: 26s, ETA:    75s[  ] 253/977, 9.6 task/s, elapsed: 26s, ETA:    75s[  ] 254/977, 9.6 task/s, elapsed: 26s, ETA:    75s[  ] 255/977, 9.6 task/s, elapsed: 26s, ETA:    75s[  ] 256/977, 9.6 task/s, elapsed: 27s, ETA:    75s[  ] 257/977, 9.6 task/s, elapsed: 27s, ETA:    75s[  ] 258/977, 9.6 task/s, elapsed: 27s, ETA:    75s[  ] 259/977, 9.6 task/s, elapsed: 27s, ETA:    74s[  ] 260/977, 9.6 task/s, elapsed: 27s, ETA:    74s[  ] 261/977, 9.6 task/s, elapsed: 27s, ETA:    74s[  ] 262/977, 9.6 task/s, elapsed: 27s, ETA:    74s[  ] 263/977, 9.6 task/s, elapsed: 27s, ETA:    74s[  ] 264/977, 9.7 task/s, elapsed: 27s, ETA:    74s[  ] 265/977, 9.7 task/s, elapsed: 27s, ETA:    74s[  ] 266/977, 9.7 task/s, elapsed: 28s, ETA:    74s[  ] 267/977, 9.7 task/s, elapsed: 28s, ETA:    74s[  ] 268/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 269/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 270/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 271/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 272/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 273/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 274/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 275/977, 9.7 task/s, elapsed: 28s, ETA:    73s[  ] 276/977, 9.7 task/s, elapsed: 29s, ETA:    73s[  ] 277/977, 9.7 task/s, elapsed: 29s, ETA:    73s[  ] 278/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 279/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 280/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 281/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 282/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 283/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 284/977, 9.7 task/s, elapsed: 29s, ETA:    72s[  ] 285/977, 9.7 task/s, elapsed: 30s, ETA:    72s[  ] 286/977, 9.7 task/s, elapsed: 30s, ETA:    72s[  ] 287/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 288/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 289/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 290/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 291/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 292/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 293/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 294/977, 9.7 task/s, elapsed: 30s, ETA:    71s[  ] 295/977, 9.7 task/s, elapsed: 31s, ETA:    71s[  ] 296/977, 9.7 task/s, elapsed: 31s, ETA:    71s[  ] 297/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 298/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 299/977, 9.7 task/s, elapsed: 31s, ETA:    70s[  ] 300/977, 9.6 task/s, elapsed: 31s, ETA:    70s[  ] 301/977, 9.6 task/s, elapsed: 31s, ETA:    70s[  ] 302/977, 9.6 task/s, elapsed: 31s, ETA:    70s[  ] 303/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 304/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 305/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 306/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 307/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 308/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 309/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 310/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 311/977, 9.6 task/s, elapsed: 32s, ETA:    70s[  ] 312/977, 9.6 task/s, elapsed: 33s, ETA:    70s[  ] 313/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 314/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 315/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 316/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 317/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 318/977, 9.6 task/s, elapsed: 33s, ETA:    69s[  ] 319/977, 9.5 task/s, elapsed: 33s, ETA:    69s[  ] 320/977, 9.5 task/s, elapsed: 34s, ETA:    69s[  ] 321/977, 9.5 task/s, elapsed: 34s, ETA:    69s[  ] 322/977, 9.5 task/s, elapsed: 34s, ETA:    69s[  ] 323/977, 9.5 task/s, elapsed: 34s, ETA:    69s[  ] 324/977, 9.5 task/s, elapsed: 34s, ETA:    68s[  ] 325/977, 9.5 task/s, elapsed: 34s, ETA:    68s[  ] 326/977, 9.5 task/s, elapsed: 34s, ETA:    68s[  ] 327/977, 9.5 task/s, elapsed: 34s, ETA:    68s[  ] 328/977, 9.5 task/s, elapsed: 34s, ETA:    68s[  ] 329/977, 9.5 task/s, elapsed: 35s, ETA:    68s[  ] 330/977, 9.5 task/s, elapsed: 35s, ETA:    68s[  ] 331/977, 9.5 task/s, elapsed: 35s, ETA:    68s[  ] 332/977, 9.5 task/s, elapsed: 35s, ETA:    68s[  ] 333/977, 9.5 task/s, elapsed: 35s, ETA:    68s[  ] 334/977, 9.5 task/s, elapsed: 35s, ETA:    67s[  ] 335/977, 9.5 task/s, elapsed: 35s, ETA:    67s[  ] 336/977, 9.5 task/s, elapsed: 35s, ETA:    67s[  ] 337/977, 9.5 task/s, elapsed: 35s, ETA:    67s[  ] 338/977, 9.5 task/s, elapsed: 35s, ETA:    67s[  ] 339/977, 9.5 task/s, elapsed: 36s, ETA:    67s[  ] 340/977, 9.5 task/s, elapsed: 36s, ETA:    67s[  ] 341/977, 9.5 task/s, elapsed: 36s, ETA:    67s[  ] 342/977, 9.5 task/s, elapsed: 36s, ETA:    67s[  ] 343/977, 9.5 task/s, elapsed: 36s, ETA:    66s[  ] 344/977, 9.5 task/s, elapsed: 36s, ETA:    66s[  ] 345/977, 9.5 task/s, elapsed: 36s, ETA:    66s[  ] 346/977, 9.5 task/s, elapsed: 36s, ETA:    66s[  ] 347/977, 9.5 task/s, elapsed: 36s, ETA:    66s[  ] 348/977, 9.5 task/s, elapsed: 36s, ETA:    66s[  ] 349/977, 9.5 task/s, elapsed: 37s, ETA:    66s[  ] 350/977, 9.6 task/s, elapsed: 37s, ETA:    66s[  ] 351/977, 9.6 task/s, elapsed: 37s, ETA:    66s[  ] 352/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 353/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 354/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 355/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 356/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 357/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 358/977, 9.6 task/s, elapsed: 37s, ETA:    65s[  ] 359/977, 9.6 task/s, elapsed: 38s, ETA:    65s[  ] 360/977, 9.6 task/s, elapsed: 38s, ETA:    65s[  ] 361/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 362/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 363/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 364/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 365/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 366/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 367/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 368/977, 9.6 task/s, elapsed: 38s, ETA:    64s[  ] 369/977, 9.6 task/s, elapsed: 39s, ETA:    64s[  ] 370/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 371/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 372/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 373/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 374/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 375/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 376/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 377/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 378/977, 9.6 task/s, elapsed: 39s, ETA:    63s[  ] 379/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 380/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 381/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 382/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 383/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 384/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 385/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 386/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 387/977, 9.6 task/s, elapsed: 40s, ETA:    62s[  ] 388/977, 9.6 task/s, elapsed: 40s, ETA:    61s[  ] 389/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 390/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 391/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 392/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 393/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 394/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 395/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 396/977, 9.6 task/s, elapsed: 41s, ETA:    61s[  ] 397/977, 9.6 task/s, elapsed: 41s, ETA:    60s[  ] 398/977, 9.6 task/s, elapsed: 41s, ETA:    60s[  ] 399/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 400/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 401/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 402/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 403/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 404/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 405/977, 9.6 task/s, elapsed: 42s, ETA:    60s[  ] 406/977, 9.6 task/s, elapsed: 42s, ETA:    59s[  ] 407/977, 9.6 task/s, elapsed: 42s, ETA:    59s[  ] 408/977, 9.6 task/s, elapsed: 42s, ETA:    59s[  ] 409/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 410/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 411/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 412/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 413/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 414/977, 9.6 task/s, elapsed: 43s, ETA:    59s[  ] 415/977, 9.6 task/s, elapsed: 43s, ETA:    58s[  ] 416/977, 9.6 task/s, elapsed: 43s, ETA:    58s[  ] 417/977, 9.6 task/s, elapsed: 43s, ETA:    58s[  ] 418/977, 9.6 task/s, elapsed: 43s, ETA:    58s[  ] 419/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 420/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 421/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 422/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 423/977, 9.6 task/s, elapsed: 44s, ETA:    58s[  ] 424/977, 9.6 task/s, elapsed: 44s, ETA:    57s[  ] 425/977, 9.6 task/s, elapsed: 44s, ETA:    57s[  ] 426/977, 9.6 task/s, elapsed: 44s, ETA:    57s[  ] 427/977, 9.6 task/s, elapsed: 44s, ETA:    57s[  ] 428/977, 9.6 task/s, elapsed: 44s, ETA:    57s[  ] 429/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 430/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 431/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 432/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 433/977, 9.6 task/s, elapsed: 45s, ETA:    57s[  ] 434/977, 9.6 task/s, elapsed: 45s, ETA:    56s[  ] 435/977, 9.6 task/s, elapsed: 45s, ETA:    56s[  ] 436/977, 9.6 task/s, elapsed: 45s, ETA:    56s[  ] 437/977, 9.6 task/s, elapsed: 45s, ETA:    56s[  ] 438/977, 9.6 task/s, elapsed: 45s, ETA:    56s[  ] 439/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 440/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 441/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 442/977, 9.6 task/s, elapsed: 46s, ETA:    56s[  ] 443/977, 9.6 task/s, elapsed: 46s, ETA:    55s[  ] 444/977, 9.6 task/s, elapsed: 46s, ETA:    55s[  ] 445/977, 9.6 task/s, elapsed: 46s, ETA:    55s[  ] 446/977, 9.6 task/s, elapsed: 46s, ETA:    55s[  ] 447/977, 9.6 task/s, elapsed: 46s, ETA:    55s[  ] 448/977, 9.6 task/s, elapsed: 46s, ETA:    55s[  ] 449/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 450/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 451/977, 9.6 task/s, elapsed: 47s, ETA:    55s[  ] 452/977, 9.6 task/s, elapsed: 47s, ETA:    54s[  ] 453/977, 9.6 task/s, elapsed: 47s, ETA:    54s[  ] 454/977, 9.6 task/s, elapsed: 47s, ETA:    54s[  ] 455/977, 9.6 task/s, elapsed: 47s, ETA:    54s[  ] 456/977, 9.6 task/s, elapsed: 47s, ETA:    54s[  ] 457/977, 9.6 task/s, elapsed: 47s, ETA:    54s[  ] 458/977, 9.6 task/s, elapsed: 47s, ETA:    54s[  ] 459/977, 9.6 task/s, elapsed: 48s, ETA:    54s[  ] 460/977, 9.6 task/s, elapsed: 48s, ETA:    54s[  ] 461/977, 9.6 task/s, elapsed: 48s, ETA:    53s[  ] 462/977, 9.6 task/s, elapsed: 48s, ETA:    53s[  ] 463/977, 9.6 task/s, elapsed: 48s, ETA:    53s[  ] 464/977, 9.6 task/s, elapsed: 48s, ETA:    53s[  ] 465/977, 9.7 task/s, elapsed: 48s, ETA:    53s[  ] 466/977, 9.6 task/s, elapsed: 48s, ETA:    53s[  ] 467/977, 9.6 task/s, elapsed: 48s, ETA:    53s[  ] 468/977, 9.6 task/s, elapsed: 48s, ETA:    53s[  ] 469/977, 9.7 task/s, elapsed: 49s, ETA:    53s[  ] 470/977, 9.7 task/s, elapsed: 49s, ETA:    53s[  ] 471/977, 9.7 task/s, elapsed: 49s, ETA:    52s[  ] 472/977, 9.7 task/s, elapsed: 49s, ETA:    52s[  ] 473/977, 9.7 task/s, elapsed: 49s, ETA:    52s[  ] 474/977, 9.7 task/s, elapsed: 49s, ETA:    52s[  ] 475/977, 9.7 task/s, elapsed: 49s, ETA:    52s[  ] 476/977, 9.7 task/s, elapsed: 49s, ETA:    52s[  ] 477/977, 9.7 task/s, elapsed: 49s, ETA:    52s[  ] 478/977, 9.7 task/s, elapsed: 50s, ETA:    52s[  ] 479/977, 9.7 task/s, elapsed: 50s, ETA:    52s[  ] 480/977, 9.7 task/s, elapsed: 50s, ETA:    51s[  ] 481/977, 9.7 task/s, elapsed: 50s, ETA:    51s[  ] 482/977, 9.7 task/s, elapsed: 50s, ETA:    51s[  ] 483/977, 9.7 task/s, elapsed: 50s, ETA:    51s[  ] 484/977, 9.7 task/s, elapsed: 50s, ETA:    51s[  ] 485/977, 9.7 task/s, elapsed: 50s, ETA:    51s[  ] 486/977, 9.7 task/s, elapsed: 50s, ETA:    51s[  ] 487/977, 9.7 task/s, elapsed: 50s, ETA:    51s[  ] 488/977, 9.7 task/s, elapsed: 51s, ETA:    51s[> ] 489/977, 9.7 task/s, elapsed: 51s, ETA:    51s[> ] 490/977, 9.7 task/s, elapsed: 51s, ETA:    50s[> ] 491/977, 9.7 task/s, elapsed: 51s, ETA:    50s[> ] 492/977, 9.7 task/s, elapsed: 51s, ETA:    50s[> ] 493/977, 9.7 task/s, elapsed: 51s, ETA:    50s[> ] 494/977, 9.7 task/s, elapsed: 51s, ETA:    50s[> ] 495/977, 9.7 task/s, elapsed: 51s, ETA:    50s[> ] 496/977, 9.7 task/s, elapsed: 51s, ETA:    50s[> ] 497/977, 9.7 task/s, elapsed: 51s, ETA:    50s[> ] 498/977, 9.7 task/s, elapsed: 52s, ETA:    50s[> ] 499/977, 9.7 task/s, elapsed: 52s, ETA:    49s[> ] 500/977, 9.7 task/s, elapsed: 52s, ETA:    49s[> ] 501/977, 9.7 task/s, elapsed: 52s, ETA:    49s[> ] 502/977, 9.7 task/s, elapsed: 52s, ETA:    49s[> ] 503/977, 9.7 task/s, elapsed: 52s, ETA:    49s[> ] 504/977, 9.7 task/s, elapsed: 52s, ETA:    49s[> ] 505/977, 9.7 task/s, elapsed: 52s, ETA:    49s[> ] 506/977, 9.7 task/s, elapsed: 52s, ETA:    49s[> ] 507/977, 9.7 task/s, elapsed: 52s, ETA:    49s[> ] 508/977, 9.7 task/s, elapsed: 53s, ETA:    49s[> ] 509/977, 9.7 task/s, elapsed: 53s, ETA:    48s[> ] 510/977, 9.7 task/s, elapsed: 53s, ETA:    48s[> ] 511/977, 9.7 task/s, elapsed: 53s, ETA:    48s[> ] 512/977, 9.7 task/s, elapsed: 53s, ETA:    48s[> ] 513/977, 9.7 task/s, elapsed: 53s, ETA:    48s[> ] 514/977, 9.7 task/s, elapsed: 53s, ETA:    48s[> ] 515/977, 9.7 task/s, elapsed: 53s, ETA:    48s[> ] 516/977, 9.7 task/s, elapsed: 53s, ETA:    48s[> ] 517/977, 9.7 task/s, elapsed: 53s, ETA:    48s[> ] 518/977, 9.7 task/s, elapsed: 54s, ETA:    47s[> ] 519/977, 9.7 task/s, elapsed: 54s, ETA:    47s[> ] 520/977, 9.7 task/s, elapsed: 54s, ETA:    47s[> ] 521/977, 9.7 task/s, elapsed: 54s, ETA:    47s[> ] 522/977, 9.7 task/s, elapsed: 54s, ETA:    47s[> ] 523/977, 9.7 task/s, elapsed: 54s, ETA:    47s[> ] 524/977, 9.7 task/s, elapsed: 54s, ETA:    47s[> ] 525/977, 9.7 task/s, elapsed: 54s, ETA:    47s[> ] 526/977, 9.7 task/s, elapsed: 54s, ETA:    47s[> ] 527/977, 9.7 task/s, elapsed: 54s, ETA:    47s[> ] 528/977, 9.7 task/s, elapsed: 55s, ETA:    46s[> ] 529/977, 9.7 task/s, elapsed: 55s, ETA:    46s[> ] 530/977, 9.7 task/s, elapsed: 55s, ETA:    46s[> ] 531/977, 9.7 task/s, elapsed: 55s, ETA:    46s[> ] 532/977, 9.7 task/s, elapsed: 55s, ETA:    46s[> ] 533/977, 9.7 task/s, elapsed: 55s, ETA:    46s[> ] 534/977, 9.7 task/s, elapsed: 55s, ETA:    46s[> ] 535/977, 9.7 task/s, elapsed: 55s, ETA:    46s[> ] 536/977, 9.7 task/s, elapsed: 55s, ETA:    46s[> ] 537/977, 9.7 task/s, elapsed: 55s, ETA:    45s[> ] 538/977, 9.7 task/s, elapsed: 56s, ETA:    45s[> ] 539/977, 9.7 task/s, elapsed: 56s, ETA:    45s[> ] 540/977, 9.7 task/s, elapsed: 56s, ETA:    45s[> ] 541/977, 9.7 task/s, elapsed: 56s, ETA:    45s[> ] 542/977, 9.7 task/s, elapsed: 56s, ETA:    45s[> ] 543/977, 9.7 task/s, elapsed: 56s, ETA:    45s[> ] 544/977, 9.7 task/s, elapsed: 56s, ETA:    45s[> ] 545/977, 9.7 task/s, elapsed: 56s, ETA:    45s[> ] 546/977, 9.7 task/s, elapsed: 56s, ETA:    45s[> ] 547/977, 9.7 task/s, elapsed: 56s, ETA:    44s[> ] 548/977, 9.7 task/s, elapsed: 57s, ETA:    44s[> ] 549/977, 9.7 task/s, elapsed: 57s, ETA:    44s[> ] 550/977, 9.7 task/s, elapsed: 57s, ETA:    44s[> ] 551/977, 9.7 task/s, elapsed: 57s, ETA:    44s[> ] 552/977, 9.7 task/s, elapsed: 57s, ETA:    44s[> ] 553/977, 9.7 task/s, elapsed: 57s, ETA:    44s[> ] 554/977, 9.7 task/s, elapsed: 57s, ETA:    44s[> ] 555/977, 9.7 task/s, elapsed: 57s, ETA:    44s[> ] 556/977, 9.7 task/s, elapsed: 57s, ETA:    43s[> ] 557/977, 9.7 task/s, elapsed: 58s, ETA:    43s[> ] 558/977, 9.7 task/s, elapsed: 58s, ETA:    43s[> ] 559/977, 9.7 task/s, elapsed: 58s, ETA:    43s[> ] 560/977, 9.7 task/s, elapsed: 58s, ETA:    43s[> ] 561/977, 9.7 task/s, elapsed: 58s, ETA:    43s[> ] 562/977, 9.7 task/s, elapsed: 58s, ETA:    43s[> ] 563/977, 9.7 task/s, elapsed: 58s, ETA:    43s[> ] 564/977, 9.7 task/s, elapsed: 58s, ETA:    43s[> ] 565/977, 9.7 task/s, elapsed: 58s, ETA:    43s[> ] 566/977, 9.7 task/s, elapsed: 58s, ETA:    42s[> ] 567/977, 9.7 task/s, elapsed: 59s, ETA:    42s[> ] 568/977, 9.7 task/s, elapsed: 59s, ETA:    42s[> ] 569/977, 9.7 task/s, elapsed: 59s, ETA:    42s[> ] 570/977, 9.7 task/s, elapsed: 59s, ETA:    42s[> ] 571/977, 9.7 task/s, elapsed: 59s, ETA:    42s[> ] 572/977, 9.7 task/s, elapsed: 59s, ETA:    42s[> ] 573/977, 9.7 task/s, elapsed: 59s, ETA:    42s[> ] 574/977, 9.7 task/s, elapsed: 59s, ETA:    42s[> ] 575/977, 9.7 task/s, elapsed: 59s, ETA:    41s[> ] 576/977, 9.7 task/s, elapsed: 59s, ETA:    41s[> ] 577/977, 9.7 task/s, elapsed: 60s, ETA:    41s[> ] 578/977, 9.7 task/s, elapsed: 60s, ETA:    41s[> ] 579/977, 9.7 task/s, elapsed: 60s, ETA:    41s[> ] 580/977, 9.7 task/s, elapsed: 60s, ETA:    41s[> ] 581/977, 9.7 task/s, elapsed: 60s, ETA:    41s[> ] 582/977, 9.7 task/s, elapsed: 60s, ETA:    41s[> ] 583/977, 9.7 task/s, elapsed: 60s, ETA:    41s[> ] 584/977, 9.7 task/s, elapsed: 60s, ETA:    41s[> ] 585/977, 9.7 task/s, elapsed: 60s, ETA:    40s[> ] 586/977, 9.7 task/s, elapsed: 60s, ETA:    40s[> ] 587/977, 9.7 task/s, elapsed: 61s, ETA:    40s[> ] 588/977, 9.7 task/s, elapsed: 61s, ETA:    40s[> ] 589/977, 9.7 task/s, elapsed: 61s, ETA:    40s[> ] 590/977, 9.7 task/s, elapsed: 61s, ETA:    40s[> ] 591/977, 9.7 task/s, elapsed: 61s, ETA:    40s[> ] 592/977, 9.7 task/s, elapsed: 61s, ETA:    40s[> ] 593/977, 9.7 task/s, elapsed: 61s, ETA:    40s[> ] 594/977, 9.7 task/s, elapsed: 61s, ETA:    39s[> ] 595/977, 9.7 task/s, elapsed: 61s, ETA:    39s[> ] 596/977, 9.7 task/s, elapsed: 61s, ETA:    39s[> ] 597/977, 9.7 task/s, elapsed: 62s, ETA:    39s[> ] 598/977, 9.7 task/s, elapsed: 62s, ETA:    39s[> ] 599/977, 9.7 task/s, elapsed: 62s, ETA:    39s[> ] 600/977, 9.7 task/s, elapsed: 62s, ETA:    39s[> ] 601/977, 9.7 task/s, elapsed: 62s, ETA:    39s[> ] 602/977, 9.7 task/s, elapsed: 62s, ETA:    39s[> ] 603/977, 9.7 task/s, elapsed: 62s, ETA:    39s[> ] 604/977, 9.7 task/s, elapsed: 62s, ETA:    38s[> ] 605/977, 9.7 task/s, elapsed: 62s, ETA:    38s[> ] 606/977, 9.7 task/s, elapsed: 62s, ETA:    38s[> ] 607/977, 9.7 task/s, elapsed: 63s, ETA:    38s[> ] 608/977, 9.7 task/s, elapsed: 63s, ETA:    38s[> ] 609/977, 9.7 task/s, elapsed: 63s, ETA:    38s[> ] 610/977, 9.7 task/s, elapsed: 63s, ETA:    38s[> ] 611/977, 9.7 task/s, elapsed: 63s, ETA:    38s[> ] 612/977, 9.7 task/s, elapsed: 63s, ETA:    38s[> ] 613/977, 9.7 task/s, elapsed: 63s, ETA:    38s[> ] 614/977, 9.7 task/s, elapsed: 63s, ETA:    37s[> ] 615/977, 9.7 task/s, elapsed: 63s, ETA:    37s[> ] 616/977, 9.7 task/s, elapsed: 63s, ETA:    37s[> ] 617/977, 9.7 task/s, elapsed: 64s, ETA:    37s[> ] 618/977, 9.7 task/s, elapsed: 64s, ETA:    37s[> ] 619/977, 9.7 task/s, elapsed: 64s, ETA:    37s[> ] 620/977, 9.7 task/s, elapsed: 64s, ETA:    37s[> ] 621/977, 9.7 task/s, elapsed: 64s, ETA:    37s[> ] 622/977, 9.7 task/s, elapsed: 64s, ETA:    37s[> ] 623/977, 9.7 task/s, elapsed: 64s, ETA:    36s[> ] 624/977, 9.7 task/s, elapsed: 64s, ETA:    36s[> ] 625/977, 9.7 task/s, elapsed: 64s, ETA:    36s[> ] 626/977, 9.7 task/s, elapsed: 65s, ETA:    36s[> ] 627/977, 9.7 task/s, elapsed: 65s, ETA:    36s[> ] 628/977, 9.7 task/s, elapsed: 65s, ETA:    36s[> ] 629/977, 9.7 task/s, elapsed: 65s, ETA:    36s[> ] 630/977, 9.7 task/s, elapsed: 65s, ETA:    36s[> ] 631/977, 9.7 task/s, elapsed: 65s, ETA:    36s[> ] 632/977, 9.7 task/s, elapsed: 65s, ETA:    36s[> ] 633/977, 9.7 task/s, elapsed: 65s, ETA:    35s[> ] 634/977, 9.7 task/s, elapsed: 65s, ETA:    35s[> ] 635/977, 9.7 task/s, elapsed: 65s, ETA:    35s[> ] 636/977, 9.7 task/s, elapsed: 66s, ETA:    35s[> ] 637/977, 9.7 task/s, elapsed: 66s, ETA:    35s[> ] 638/977, 9.7 task/s, elapsed: 66s, ETA:    35s[> ] 639/977, 9.7 task/s, elapsed: 66s, ETA:    35s[> ] 640/977, 9.7 task/s, elapsed: 66s, ETA:    35s[> ] 641/977, 9.7 task/s, elapsed: 66s, ETA:    35s[> ] 642/977, 9.7 task/s, elapsed: 66s, ETA:    35s[> ] 643/977, 9.7 task/s, elapsed: 66s, ETA:    34s[> ] 644/977, 9.7 task/s, elapsed: 66s, ETA:    34s[> ] 645/977, 9.7 task/s, elapsed: 66s, ETA:    34s[> ] 646/977, 9.7 task/s, elapsed: 67s, ETA:    34s[> ] 647/977, 9.7 task/s, elapsed: 67s, ETA:    34s[> ] 648/977, 9.7 task/s, elapsed: 67s, ETA:    34s[> ] 649/977, 9.7 task/s, elapsed: 67s, ETA:    34s[> ] 650/977, 9.7 task/s, elapsed: 67s, ETA:    34s[> ] 651/977, 9.7 task/s, elapsed: 67s, ETA:    34s[> ] 652/977, 9.7 task/s, elapsed: 67s, ETA:    33s[> ] 653/977, 9.7 task/s, elapsed: 67s, ETA:    33s[> ] 654/977, 9.7 task/s, elapsed: 67s, ETA:    33s[> ] 655/977, 9.7 task/s, elapsed: 67s, ETA:    33s[> ] 656/977, 9.7 task/s, elapsed: 68s, ETA:    33s[> ] 657/977, 9.7 task/s, elapsed: 68s, ETA:    33s[> ] 658/977, 9.7 task/s, elapsed: 68s, ETA:    33s[> ] 659/977, 9.7 task/s, elapsed: 68s, ETA:    33s[> ] 660/977, 9.7 task/s, elapsed: 68s, ETA:    33s[> ] 661/977, 9.7 task/s, elapsed: 68s, ETA:    33s[> ] 662/977, 9.7 task/s, elapsed: 68s, ETA:    32s[> ] 663/977, 9.7 task/s, elapsed: 68s, ETA:    32s[> ] 664/977, 9.7 task/s, elapsed: 68s, ETA:    32s[> ] 665/977, 9.7 task/s, elapsed: 68s, ETA:    32s[> ] 666/977, 9.7 task/s, elapsed: 69s, ETA:    32s[> ] 667/977, 9.7 task/s, elapsed: 69s, ETA:    32s[> ] 668/977, 9.7 task/s, elapsed: 69s, ETA:    32s[> ] 669/977, 9.7 task/s, elapsed: 69s, ETA:    32s[> ] 670/977, 9.7 task/s, elapsed: 69s, ETA:    32s[> ] 671/977, 9.7 task/s, elapsed: 69s, ETA:    31s[> ] 672/977, 9.7 task/s, elapsed: 69s, ETA:    31s[> ] 673/977, 9.7 task/s, elapsed: 69s, ETA:    31s[> ] 674/977, 9.7 task/s, elapsed: 69s, ETA:    31s[> ] 675/977, 9.7 task/s, elapsed: 69s, ETA:    31s[> ] 676/977, 9.7 task/s, elapsed: 70s, ETA:    31s[> ] 677/977, 9.7 task/s, elapsed: 70s, ETA:    31s[> ] 678/977, 9.7 task/s, elapsed: 70s, ETA:    31s[> ] 679/977, 9.7 task/s, elapsed: 70s, ETA:    31s[> ] 680/977, 9.7 task/s, elapsed: 70s, ETA:    31s[> ] 681/977, 9.7 task/s, elapsed: 70s, ETA:    30s[> ] 682/977, 9.7 task/s, elapsed: 70s, ETA:    30s[> ] 683/977, 9.7 task/s, elapsed: 70s, ETA:    30s[> ] 684/977, 9.7 task/s, elapsed: 70s, ETA:    30s[> ] 685/977, 9.7 task/s, elapsed: 70s, ETA:    30s[> ] 686/977, 9.7 task/s, elapsed: 71s, ETA:    30s[> ] 687/977, 9.7 task/s, elapsed: 71s, ETA:    30s[> ] 688/977, 9.7 task/s, elapsed: 71s, ETA:    30s[> ] 689/977, 9.7 task/s, elapsed: 71s, ETA:    30s[> ] 690/977, 9.7 task/s, elapsed: 71s, ETA:    30s[> ] 691/977, 9.7 task/s, elapsed: 71s, ETA:    29s[> ] 692/977, 9.7 task/s, elapsed: 71s, ETA:    29s[> ] 693/977, 9.7 task/s, elapsed: 71s, ETA:    29s[> ] 694/977, 9.7 task/s, elapsed: 71s, ETA:    29s[> ] 695/977, 9.7 task/s, elapsed: 72s, ETA:    29s[> ] 696/977, 9.7 task/s, elapsed: 72s, ETA:    29s[> ] 697/977, 9.7 task/s, elapsed: 72s, ETA:    29s[> ] 698/977, 9.7 task/s, elapsed: 72s, ETA:    29s[> ] 699/977, 9.7 task/s, elapsed: 72s, ETA:    29s[> ] 700/977, 9.7 task/s, elapsed: 72s, ETA:    29s[> ] 701/977, 9.7 task/s, elapsed: 72s, ETA:    28s[> ] 702/977, 9.7 task/s, elapsed: 72s, ETA:    28s[> ] 703/977, 9.7 task/s, elapsed: 73s, ETA:    28s[> ] 704/977, 9.7 task/s, elapsed: 73s, ETA:    28s[> ] 705/977, 9.7 task/s, elapsed: 73s, ETA:    28s[> ] 706/977, 9.7 task/s, elapsed: 73s, ETA:    28s[> ] 707/977, 9.7 task/s, elapsed: 73s, ETA:    28s[> ] 708/977, 9.7 task/s, elapsed: 73s, ETA:    28s[> ] 709/977, 9.7 task/s, elapsed: 73s, ETA:    28s[> ] 710/977, 9.7 task/s, elapsed: 73s, ETA:    28s[> ] 711/977, 9.7 task/s, elapsed: 73s, ETA:    27s[> ] 712/977, 9.7 task/s, elapsed: 74s, ETA:    27s[> ] 713/977, 9.7 task/s, elapsed: 74s, ETA:    27s[> ] 714/977, 9.7 task/s, elapsed: 74s, ETA:    27s[> ] 715/977, 9.7 task/s, elapsed: 74s, ETA:    27s[> ] 716/977, 9.7 task/s, elapsed: 74s, ETA:    27s[> ] 717/977, 9.7 task/s, elapsed: 74s, ETA:    27s[> ] 718/977, 9.7 task/s, elapsed: 74s, ETA:    27s[> ] 719/977, 9.7 task/s, elapsed: 74s, ETA:    27s[> ] 720/977, 9.7 task/s, elapsed: 74s, ETA:    27s[> ] 721/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 722/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 723/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 724/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 725/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 726/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 727/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 728/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 729/977, 9.7 task/s, elapsed: 75s, ETA:    26s[> ] 730/977, 9.7 task/s, elapsed: 76s, ETA:    26s[> ] 731/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 732/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 733/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 734/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 735/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 736/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 737/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 738/977, 9.7 task/s, elapsed: 76s, ETA:    25s[> ] 739/977, 9.7 task/s, elapsed: 77s, ETA:    25s[> ] 740/977, 9.7 task/s, elapsed: 77s, ETA:    25s[> ] 741/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 742/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 743/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 744/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 745/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 746/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 747/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 748/977, 9.7 task/s, elapsed: 77s, ETA:    24s[> ] 749/977, 9.7 task/s, elapsed: 78s, ETA:    24s[> ] 750/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 751/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 752/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 753/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 754/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 755/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 756/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 757/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 758/977, 9.7 task/s, elapsed: 78s, ETA:    23s[> ] 759/977, 9.7 task/s, elapsed: 79s, ETA:    23s[> ] 760/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 761/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 762/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 763/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 764/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 765/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 766/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 767/977, 9.7 task/s, elapsed: 79s, ETA:    22s[> ] 768/977, 9.7 task/s, elapsed: 80s, ETA:    22s[> ] 769/977, 9.7 task/s, elapsed: 80s, ETA:    22s[> ] 770/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 771/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 772/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 773/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 774/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 775/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 776/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 777/977, 9.7 task/s, elapsed: 80s, ETA:    21s[> ] 778/977, 9.7 task/s, elapsed: 81s, ETA:    21s[> ] 779/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 780/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 781/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 782/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 783/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 784/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 785/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 786/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 787/977, 9.7 task/s, elapsed: 81s, ETA:    20s[> ] 788/977, 9.7 task/s, elapsed: 82s, ETA:    20s[> ] 789/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 790/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 791/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 792/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 793/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 794/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 795/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 796/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 797/977, 9.7 task/s, elapsed: 82s, ETA:    19s[> ] 798/977, 9.7 task/s, elapsed: 83s, ETA:    19s[> ] 799/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 800/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 801/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 802/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 803/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 804/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 805/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 806/977, 9.7 task/s, elapsed: 83s, ETA:    18s[> ] 807/977, 9.7 task/s, elapsed: 84s, ETA:    18s[> ] 808/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 809/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 810/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 811/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 812/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 813/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 814/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 815/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 816/977, 9.7 task/s, elapsed: 84s, ETA:    17s[> ] 817/977, 9.7 task/s, elapsed: 85s, ETA:    17s[> ] 818/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 819/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 820/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 821/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 822/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 823/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 824/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 825/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 826/977, 9.7 task/s, elapsed: 85s, ETA:    16s[> ] 827/977, 9.7 task/s, elapsed: 86s, ETA:    16s[> ] 828/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 829/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 830/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 831/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 832/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 833/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 834/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 835/977, 9.7 task/s, elapsed: 86s, ETA:    15s[> ] 836/977, 9.7 task/s, elapsed: 87s, ETA:    15s[> ] 837/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 838/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 839/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 840/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 841/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 842/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 843/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 844/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 845/977, 9.7 task/s, elapsed: 87s, ETA:    14s[> ] 846/977, 9.7 task/s, elapsed: 88s, ETA:    14s[> ] 847/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 848/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 849/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 850/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 851/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 852/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 853/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 854/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 855/977, 9.7 task/s, elapsed: 88s, ETA:    13s[> ] 856/977, 9.7 task/s, elapsed: 89s, ETA:    13s[> ] 857/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 858/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 859/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 860/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 861/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 862/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 863/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 864/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 865/977, 9.7 task/s, elapsed: 89s, ETA:    12s[> ] 866/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 867/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 868/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 869/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 870/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 871/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 872/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 873/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 874/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 875/977, 9.7 task/s, elapsed: 90s, ETA:    11s[> ] 876/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 877/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 878/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 879/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 880/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 881/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 882/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 883/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 884/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 885/977, 9.7 task/s, elapsed: 91s, ETA:    10s[> ] 886/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 887/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 888/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 889/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 890/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 891/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 892/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 893/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 894/977, 9.7 task/s, elapsed: 92s, ETA:     9s[> ] 895/977, 9.7 task/s, elapsed: 92s, ETA:     8s[> ] 896/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 897/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 898/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 899/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 900/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 901/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 902/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 903/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 904/977, 9.7 task/s, elapsed: 93s, ETA:     8s[> ] 905/977, 9.7 task/s, elapsed: 93s, ETA:     7s[> ] 906/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 907/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 908/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 909/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 910/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 911/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 912/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 913/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 914/977, 9.7 task/s, elapsed: 94s, ETA:     7s[> ] 915/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 916/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 917/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 918/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 919/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 920/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 921/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 922/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 923/977, 9.7 task/s, elapsed: 95s, ETA:     6s[> ] 924/977, 9.7 task/s, elapsed: 95s, ETA:     5s[> ] 925/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 926/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 927/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 928/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 929/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 930/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 931/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 932/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 933/977, 9.7 task/s, elapsed: 96s, ETA:     5s[> ] 934/977, 9.7 task/s, elapsed: 96s, ETA:     4s[> ] 935/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 936/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 937/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 938/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 939/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 940/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 941/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 942/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 943/977, 9.7 task/s, elapsed: 97s, ETA:     4s[> ] 944/977, 9.7 task/s, elapsed: 97s, ETA:     3s[> ] 945/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 946/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 947/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 948/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 949/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 950/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 951/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 952/977, 9.7 task/s, elapsed: 98s, ETA:     3s[> ] 953/977, 9.7 task/s, elapsed: 98s, ETA:     2s[> ] 954/977, 9.7 task/s, elapsed: 98s, ETA:     2s[> ] 955/977, 9.7 task/s, elapsed: 98s, ETA:     2s[> ] 956/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 957/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 958/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 959/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 960/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 961/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 962/977, 9.7 task/s, elapsed: 99s, ETA:     2s[> ] 963/977, 9.7 task/s, elapsed: 99s, ETA:     1s[> ] 964/977, 9.7 task/s, elapsed: 99s, ETA:     1s[> ] 965/977, 9.7 task/s, elapsed: 99s, ETA:     1s[> ] 966/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 967/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 968/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 969/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 970/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 971/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 972/977, 9.7 task/s, elapsed: 100s, ETA:     1s[> ] 973/977, 9.7 task/s, elapsed: 100s, ETA:     0s[> ] 974/977, 9.7 task/s, elapsed: 100s, ETA:     0s[> ] 975/977, 9.7 task/s, elapsed: 100s, ETA:     0s[> ] 976/977, 9.7 task/s, elapsed: 101s, ETA:     0s[>>] 977/977, 9.7 task/s, elapsed: 101s, ETA:     0s2021-09-29 13:30:24,170 - mmdet - INFO - Evaluating bbox...
2021-09-29 13:30:25,029 - mmdet - INFO - Exp name: waste_hrnet_16.py
2021-09-29 13:30:25,030 - mmdet - INFO - Epoch(val) [3][977]	bbox_mAP: 0.0040, bbox_mAP_50: 0.0090, bbox_mAP_75: 0.0020, bbox_mAP_s: 0.0000, bbox_mAP_m: 0.0000, bbox_mAP_l: 0.0040, bbox_mAP_copypaste: 0.004 0.009 0.002 0.000 0.000 0.004
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.65s).
Accumulating evaluation results...
DONE (t=0.18s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.009
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.008
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.008
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.010
2021-09-29 13:30:56,114 - mmdet - INFO - Epoch [4][10/245]	lr: 9.911e-05, eta: 8:45:58, time: 3.106, data_time: 0.298, memory: 29438, loss_rpn_cls: 0.1022, loss_rpn_bbox: 0.1887, s0.loss_cls: 0.1807, s0.acc: 95.8240, s0.loss_bbox: 0.0884, s1.loss_cls: 0.0467, s1.acc: 98.0383, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0137, s2.acc: 98.8354, s2.loss_bbox: 0.0107, loss: 0.6570, grad_norm: 1.4861
2021-09-29 13:31:23,570 - mmdet - INFO - Epoch [4][20/245]	lr: 9.911e-05, eta: 8:45:31, time: 2.746, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0998, loss_rpn_bbox: 0.2054, s0.loss_cls: 0.2115, s0.acc: 95.1611, s0.loss_bbox: 0.1009, s1.loss_cls: 0.0557, s1.acc: 97.5562, s1.loss_bbox: 0.0321, s2.loss_cls: 0.0175, s2.acc: 98.4912, s2.loss_bbox: 0.0128, loss: 0.7356, grad_norm: 1.6792
2021-09-29 13:31:51,202 - mmdet - INFO - Epoch [4][30/245]	lr: 9.911e-05, eta: 8:45:07, time: 2.763, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.0920, loss_rpn_bbox: 0.1969, s0.loss_cls: 0.1971, s0.acc: 95.0842, s0.loss_bbox: 0.1023, s1.loss_cls: 0.0523, s1.acc: 97.5500, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0153, s2.acc: 98.5925, s2.loss_bbox: 0.0124, loss: 0.7003, grad_norm: 2.2127
2021-09-29 13:32:19,100 - mmdet - INFO - Epoch [4][40/245]	lr: 9.911e-05, eta: 8:44:46, time: 2.790, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1007, loss_rpn_bbox: 0.1948, s0.loss_cls: 0.1937, s0.acc: 95.4614, s0.loss_bbox: 0.0919, s1.loss_cls: 0.0472, s1.acc: 97.9028, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0131, s2.acc: 98.7573, s2.loss_bbox: 0.0106, loss: 0.6788, grad_norm: 1.6158
2021-09-29 13:32:46,660 - mmdet - INFO - Epoch [4][50/245]	lr: 9.911e-05, eta: 8:44:21, time: 2.756, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0715, loss_rpn_bbox: 0.1586, s0.loss_cls: 0.1774, s0.acc: 95.7202, s0.loss_bbox: 0.0895, s1.loss_cls: 0.0439, s1.acc: 97.8430, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0124, s2.acc: 98.7427, s2.loss_bbox: 0.0110, loss: 0.5934, grad_norm: 1.4071
2021-09-29 13:33:14,442 - mmdet - INFO - Epoch [4][60/245]	lr: 9.911e-05, eta: 8:43:58, time: 2.778, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.0841, loss_rpn_bbox: 0.1920, s0.loss_cls: 0.1858, s0.acc: 95.6787, s0.loss_bbox: 0.0886, s1.loss_cls: 0.0460, s1.acc: 97.9468, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0122, s2.acc: 98.8354, s2.loss_bbox: 0.0102, loss: 0.6453, grad_norm: 1.4933
2021-09-29 13:33:42,041 - mmdet - INFO - Epoch [4][70/245]	lr: 9.911e-05, eta: 8:43:33, time: 2.760, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.0760, loss_rpn_bbox: 0.1570, s0.loss_cls: 0.1758, s0.acc: 95.8008, s0.loss_bbox: 0.0900, s1.loss_cls: 0.0482, s1.acc: 97.9272, s1.loss_bbox: 0.0275, s2.loss_cls: 0.0152, s2.acc: 98.7402, s2.loss_bbox: 0.0107, loss: 0.6005, grad_norm: 1.2979
2021-09-29 13:34:09,394 - mmdet - INFO - Epoch [4][80/245]	lr: 9.911e-05, eta: 8:43:04, time: 2.735, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0821, loss_rpn_bbox: 0.1862, s0.loss_cls: 0.1705, s0.acc: 95.8118, s0.loss_bbox: 0.0879, s1.loss_cls: 0.0415, s1.acc: 98.1201, s1.loss_bbox: 0.0252, s2.loss_cls: 0.0114, s2.acc: 98.8953, s2.loss_bbox: 0.0101, loss: 0.6150, grad_norm: 1.2808
2021-09-29 13:34:37,106 - mmdet - INFO - Epoch [4][90/245]	lr: 9.911e-05, eta: 8:42:40, time: 2.771, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0845, loss_rpn_bbox: 0.1832, s0.loss_cls: 0.1856, s0.acc: 95.2759, s0.loss_bbox: 0.1008, s1.loss_cls: 0.0406, s1.acc: 98.0981, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0117, s2.acc: 98.9514, s2.loss_bbox: 0.0102, loss: 0.6426, grad_norm: 1.7558
2021-09-29 13:35:05,233 - mmdet - INFO - Epoch [4][100/245]	lr: 9.911e-05, eta: 8:42:22, time: 2.813, data_time: 0.029, memory: 29438, loss_rpn_cls: 0.0799, loss_rpn_bbox: 0.1721, s0.loss_cls: 0.1782, s0.acc: 95.4175, s0.loss_bbox: 0.0956, s1.loss_cls: 0.0395, s1.acc: 98.1104, s1.loss_bbox: 0.0258, s2.loss_cls: 0.0109, s2.acc: 98.9282, s2.loss_bbox: 0.0103, loss: 0.6124, grad_norm: 1.6154
2021-09-29 13:35:32,917 - mmdet - INFO - Epoch [4][110/245]	lr: 9.911e-05, eta: 8:41:58, time: 2.768, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0905, loss_rpn_bbox: 0.2013, s0.loss_cls: 0.1827, s0.acc: 95.4956, s0.loss_bbox: 0.0951, s1.loss_cls: 0.0427, s1.acc: 98.1238, s1.loss_bbox: 0.0250, s2.loss_cls: 0.0113, s2.acc: 99.0173, s2.loss_bbox: 0.0094, loss: 0.6580, grad_norm: 1.4044
2021-09-29 13:36:00,484 - mmdet - INFO - Epoch [4][120/245]	lr: 9.911e-05, eta: 8:41:32, time: 2.757, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0817, loss_rpn_bbox: 0.1717, s0.loss_cls: 0.1633, s0.acc: 95.7251, s0.loss_bbox: 0.0883, s1.loss_cls: 0.0408, s1.acc: 98.1555, s1.loss_bbox: 0.0242, s2.loss_cls: 0.0118, s2.acc: 99.0283, s2.loss_bbox: 0.0095, loss: 0.5913, grad_norm: 1.4056
2021-09-29 13:36:27,875 - mmdet - INFO - Epoch [4][130/245]	lr: 9.911e-05, eta: 8:41:03, time: 2.739, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0709, loss_rpn_bbox: 0.1595, s0.loss_cls: 0.1650, s0.acc: 96.0315, s0.loss_bbox: 0.0838, s1.loss_cls: 0.0428, s1.acc: 98.0872, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0119, s2.acc: 98.9148, s2.loss_bbox: 0.0098, loss: 0.5694, grad_norm: 1.7340
2021-09-29 13:36:55,333 - mmdet - INFO - Epoch [4][140/245]	lr: 9.911e-05, eta: 8:40:36, time: 2.746, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.0958, loss_rpn_bbox: 0.1806, s0.loss_cls: 0.2144, s0.acc: 95.0305, s0.loss_bbox: 0.1014, s1.loss_cls: 0.0451, s1.acc: 98.0017, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0127, s2.acc: 98.8489, s2.loss_bbox: 0.0106, loss: 0.6879, grad_norm: 2.0386
2021-09-29 13:37:22,940 - mmdet - INFO - Epoch [4][150/245]	lr: 9.911e-05, eta: 8:40:10, time: 2.761, data_time: 0.025, memory: 29438, loss_rpn_cls: 0.0678, loss_rpn_bbox: 0.1394, s0.loss_cls: 0.1712, s0.acc: 95.9473, s0.loss_bbox: 0.0819, s1.loss_cls: 0.0356, s1.acc: 98.4399, s1.loss_bbox: 0.0206, s2.loss_cls: 0.0092, s2.acc: 99.1248, s2.loss_bbox: 0.0075, loss: 0.5333, grad_norm: 1.4165
2021-09-29 13:37:50,756 - mmdet - INFO - Epoch [4][160/245]	lr: 9.911e-05, eta: 8:39:47, time: 2.782, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0897, loss_rpn_bbox: 0.1747, s0.loss_cls: 0.1897, s0.acc: 95.5566, s0.loss_bbox: 0.0924, s1.loss_cls: 0.0489, s1.acc: 97.6978, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0143, s2.acc: 98.6377, s2.loss_bbox: 0.0109, loss: 0.6494, grad_norm: 1.6199
2021-09-29 13:38:18,423 - mmdet - INFO - Epoch [4][170/245]	lr: 9.911e-05, eta: 8:39:22, time: 2.767, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.0800, loss_rpn_bbox: 0.1729, s0.loss_cls: 0.1728, s0.acc: 95.7593, s0.loss_bbox: 0.0905, s1.loss_cls: 0.0444, s1.acc: 97.9138, s1.loss_bbox: 0.0277, s2.loss_cls: 0.0116, s2.acc: 98.9258, s2.loss_bbox: 0.0093, loss: 0.6092, grad_norm: 1.1657
2021-09-29 13:38:46,083 - mmdet - INFO - Epoch [4][180/245]	lr: 9.911e-05, eta: 8:38:57, time: 2.766, data_time: 0.026, memory: 29438, loss_rpn_cls: 0.1001, loss_rpn_bbox: 0.2017, s0.loss_cls: 0.1865, s0.acc: 95.5505, s0.loss_bbox: 0.0911, s1.loss_cls: 0.0457, s1.acc: 97.9590, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0124, s2.acc: 98.8782, s2.loss_bbox: 0.0106, loss: 0.6753, grad_norm: 1.4560
2021-09-29 13:39:13,987 - mmdet - INFO - Epoch [4][190/245]	lr: 9.911e-05, eta: 8:38:35, time: 2.790, data_time: 0.027, memory: 29438, loss_rpn_cls: 0.0957, loss_rpn_bbox: 0.1879, s0.loss_cls: 0.1739, s0.acc: 96.0046, s0.loss_bbox: 0.0839, s1.loss_cls: 0.0422, s1.acc: 98.1519, s1.loss_bbox: 0.0248, s2.loss_cls: 0.0113, s2.acc: 98.9612, s2.loss_bbox: 0.0097, loss: 0.6295, grad_norm: 1.6930
2021-09-29 13:39:42,204 - mmdet - INFO - Epoch [4][200/245]	lr: 9.911e-05, eta: 8:38:17, time: 2.822, data_time: 0.028, memory: 29438, loss_rpn_cls: 0.0843, loss_rpn_bbox: 0.1825, s0.loss_cls: 0.1853, s0.acc: 95.7031, s0.loss_bbox: 0.0898, s1.loss_cls: 0.0457, s1.acc: 97.8784, s1.loss_bbox: 0.0277, s2.loss_cls: 0.0137, s2.acc: 98.6755, s2.loss_bbox: 0.0116, loss: 0.6406, grad_norm: 1.5623
/opt/conda/envs/psc/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2021-09-29 13:41:09,803 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.0a0
OpenCV: 4.5.3
MMCV: 1.3.14
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMDetection: 2.16.0+fd9f35b
------------------------------------------------------------

2021-09-29 13:41:10,925 - mmdet - INFO - Distributed training: False
2021-09-29 13:41:12,171 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '/opt/ml/detection/dataset/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
imsize = 800
multi_scale_dict = [
    dict(type='Resize', height=384, width=384),
    dict(type='Resize', height=416, width=416),
    dict(type='Resize', height=448, width=448),
    dict(type='Resize', height=480, width=480),
    dict(type='Resize', height=512, width=512),
    dict(type='Resize', height=544, width=544),
    dict(type='Resize', height=576, width=576),
    dict(type='Resize', height=608, width=608),
    dict(type='Resize', height=640, width=640),
    dict(type='Resize', height=672, width=672),
    dict(type='Resize', height=704, width=704),
    dict(type='Resize', height=736, width=736),
    dict(type='Resize', height=768, width=768),
    dict(type='Resize', height=800, width=800)
]
i = 800
alb_transform = [
    dict(
        type='OneOf',
        transforms=[
            dict(type='Resize', height=384, width=384),
            dict(type='Resize', height=416, width=416),
            dict(type='Resize', height=448, width=448),
            dict(type='Resize', height=480, width=480),
            dict(type='Resize', height=512, width=512),
            dict(type='Resize', height=544, width=544),
            dict(type='Resize', height=576, width=576),
            dict(type='Resize', height=608, width=608),
            dict(type='Resize', height=640, width=640),
            dict(type='Resize', height=672, width=672),
            dict(type='Resize', height=704, width=704),
            dict(type='Resize', height=736, width=736),
            dict(type='Resize', height=768, width=768),
            dict(type='Resize', height=800, width=800)
        ],
        p=1.0),
    dict(
        type='OneOf',
        transforms=[
            dict(type='GaussNoise', p=1.0),
            dict(type='GaussianBlur', p=1.0),
            dict(type='Blur', p=1.0)
        ],
        p=0.1),
    dict(
        type='OneOf',
        transforms=[
            dict(type='CLAHE', p=1.0),
            dict(type='RandomGamma', p=1.0),
            dict(type='HueSaturationValue', p=1.0),
            dict(type='ChannelDropout', p=1.0),
            dict(type='ChannelShuffle', p=1.0),
            dict(type='RGBShift', p=1.0)
        ],
        p=0.1),
    dict(
        type='OneOf',
        transforms=[
            dict(type='ShiftScaleRotate', p=1.0),
            dict(type='Rotate', p=1.0)
        ],
        p=0.1)
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(800, 800)),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Resize', height=384, width=384),
                    dict(type='Resize', height=416, width=416),
                    dict(type='Resize', height=448, width=448),
                    dict(type='Resize', height=480, width=480),
                    dict(type='Resize', height=512, width=512),
                    dict(type='Resize', height=544, width=544),
                    dict(type='Resize', height=576, width=576),
                    dict(type='Resize', height=608, width=608),
                    dict(type='Resize', height=640, width=640),
                    dict(type='Resize', height=672, width=672),
                    dict(type='Resize', height=704, width=704),
                    dict(type='Resize', height=736, width=736),
                    dict(type='Resize', height=768, width=768),
                    dict(type='Resize', height=800, width=800)
                ],
                p=1.0),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='GaussNoise', p=1.0),
                    dict(type='GaussianBlur', p=1.0),
                    dict(type='Blur', p=1.0)
                ],
                p=0.1),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='CLAHE', p=1.0),
                    dict(type='RandomGamma', p=1.0),
                    dict(type='HueSaturationValue', p=1.0),
                    dict(type='ChannelDropout', p=1.0),
                    dict(type='ChannelShuffle', p=1.0),
                    dict(type='RGBShift', p=1.0)
                ],
                p=0.1),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='ShiftScaleRotate', p=1.0),
                    dict(type='Rotate', p=1.0)
                ],
                p=0.1)
        ],
        bbox_params=dict(
            type='BboxParams',
            format='pascal_voc',
            label_fields=['gt_labels'],
            min_visibility=0.0,
            filter_lost_elements=True),
        keymap=dict(img='image', gt_bboxes='bboxes'),
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(type='CutOut', n_holes=4, cutout_shape=(30, 30)),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',
           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/train_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(800, 800)),
            dict(
                type='Albu',
                transforms=[
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Resize', height=384, width=384),
                            dict(type='Resize', height=416, width=416),
                            dict(type='Resize', height=448, width=448),
                            dict(type='Resize', height=480, width=480),
                            dict(type='Resize', height=512, width=512),
                            dict(type='Resize', height=544, width=544),
                            dict(type='Resize', height=576, width=576),
                            dict(type='Resize', height=608, width=608),
                            dict(type='Resize', height=640, width=640),
                            dict(type='Resize', height=672, width=672),
                            dict(type='Resize', height=704, width=704),
                            dict(type='Resize', height=736, width=736),
                            dict(type='Resize', height=768, width=768),
                            dict(type='Resize', height=800, width=800)
                        ],
                        p=1.0),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='GaussNoise', p=1.0),
                            dict(type='GaussianBlur', p=1.0),
                            dict(type='Blur', p=1.0)
                        ],
                        p=0.1),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='CLAHE', p=1.0),
                            dict(type='RandomGamma', p=1.0),
                            dict(type='HueSaturationValue', p=1.0),
                            dict(type='ChannelDropout', p=1.0),
                            dict(type='ChannelShuffle', p=1.0),
                            dict(type='RGBShift', p=1.0)
                        ],
                        p=0.1),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='ShiftScaleRotate', p=1.0),
                            dict(type='Rotate', p=1.0)
                        ],
                        p=0.1)
                ],
                bbox_params=dict(
                    type='BboxParams',
                    format='pascal_voc',
                    label_fields=['gt_labels'],
                    min_visibility=0.0,
                    filter_lost_elements=True),
                keymap=dict(img='image', gt_bboxes='bboxes'),
                update_pad_shape=False,
                skip_img_without_anno=True),
            dict(type='CutOut', n_holes=4, cutout_shape=(30, 30)),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/val_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/val_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
lr = 0.0001
optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.1,
    min_lr_ratio=1e-06)
total_epochs = 50
expr_name = 'hrn_cascade_16_cutout_832ms'
dist_params = dict(backend='nccl')
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=10,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(
            type='WandbLoggerHook',
            init_kwargs=dict(
                project='P-stage2-detection',
                name='hrn_cascade_16_cutout_832ms'))
    ])
custom_hooks = [dict(type='NumClassCheckHook')]
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
runner = dict(type='EpochBasedRunner', max_epochs=50)
work_dir = './work_dirs/hrn_cascade_16_cutout_832ms'
gpu_ids = range(0, 1)
model = dict(
    type='CascadeRCNN',
    backbone=dict(
        type='HRNet',
        extra=dict(
            stage1=dict(
                num_modules=1,
                num_branches=1,
                block='BOTTLENECK',
                num_blocks=(4, ),
                num_channels=(64, )),
            stage2=dict(
                num_modules=1,
                num_branches=2,
                block='BASIC',
                num_blocks=(4, 4),
                num_channels=(18, 36)),
            stage3=dict(
                num_modules=4,
                num_branches=3,
                block='BASIC',
                num_blocks=(4, 4, 4),
                num_channels=(18, 36, 72)),
            stage4=dict(
                num_modules=3,
                num_branches=4,
                block='BASIC',
                num_blocks=(4, 4, 4, 4),
                num_channels=(18, 36, 72, 144))),
        init_cfg=dict(
            type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18')),
    neck=dict(
        type='HRFPN',
        in_channels=[18, 36, 72, 144],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='DIoULoss', loss_weight=2.5)),
    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=2.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=2.5)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=3.0))
        ]),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=30),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=30),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=71)))

/opt/conda/envs/psc/lib/python3.8/site-packages/mmdet/core/anchor/builder.py:16: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` 
  warnings.warn(
2021-09-29 13:41:12,860 - mmdet - INFO - initialize HRNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://msra/hrnetv2_w18'}
2021-09-29 13:41:12,861 - mmcv - INFO - load model from: open-mmlab://msra/hrnetv2_w18
2021-09-29 13:41:12,861 - mmcv - INFO - Use load_from_openmmlab loader
2021-09-29 13:41:13,279 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: incre_modules.0.0.conv1.weight, incre_modules.0.0.bn1.weight, incre_modules.0.0.bn1.bias, incre_modules.0.0.bn1.running_mean, incre_modules.0.0.bn1.running_var, incre_modules.0.0.bn1.num_batches_tracked, incre_modules.0.0.conv2.weight, incre_modules.0.0.bn2.weight, incre_modules.0.0.bn2.bias, incre_modules.0.0.bn2.running_mean, incre_modules.0.0.bn2.running_var, incre_modules.0.0.bn2.num_batches_tracked, incre_modules.0.0.conv3.weight, incre_modules.0.0.bn3.weight, incre_modules.0.0.bn3.bias, incre_modules.0.0.bn3.running_mean, incre_modules.0.0.bn3.running_var, incre_modules.0.0.bn3.num_batches_tracked, incre_modules.0.0.downsample.0.weight, incre_modules.0.0.downsample.1.weight, incre_modules.0.0.downsample.1.bias, incre_modules.0.0.downsample.1.running_mean, incre_modules.0.0.downsample.1.running_var, incre_modules.0.0.downsample.1.num_batches_tracked, incre_modules.1.0.conv1.weight, incre_modules.1.0.bn1.weight, incre_modules.1.0.bn1.bias, incre_modules.1.0.bn1.running_mean, incre_modules.1.0.bn1.running_var, incre_modules.1.0.bn1.num_batches_tracked, incre_modules.1.0.conv2.weight, incre_modules.1.0.bn2.weight, incre_modules.1.0.bn2.bias, incre_modules.1.0.bn2.running_mean, incre_modules.1.0.bn2.running_var, incre_modules.1.0.bn2.num_batches_tracked, incre_modules.1.0.conv3.weight, incre_modules.1.0.bn3.weight, incre_modules.1.0.bn3.bias, incre_modules.1.0.bn3.running_mean, incre_modules.1.0.bn3.running_var, incre_modules.1.0.bn3.num_batches_tracked, incre_modules.1.0.downsample.0.weight, incre_modules.1.0.downsample.1.weight, incre_modules.1.0.downsample.1.bias, incre_modules.1.0.downsample.1.running_mean, incre_modules.1.0.downsample.1.running_var, incre_modules.1.0.downsample.1.num_batches_tracked, incre_modules.2.0.conv1.weight, incre_modules.2.0.bn1.weight, incre_modules.2.0.bn1.bias, incre_modules.2.0.bn1.running_mean, incre_modules.2.0.bn1.running_var, incre_modules.2.0.bn1.num_batches_tracked, incre_modules.2.0.conv2.weight, incre_modules.2.0.bn2.weight, incre_modules.2.0.bn2.bias, incre_modules.2.0.bn2.running_mean, incre_modules.2.0.bn2.running_var, incre_modules.2.0.bn2.num_batches_tracked, incre_modules.2.0.conv3.weight, incre_modules.2.0.bn3.weight, incre_modules.2.0.bn3.bias, incre_modules.2.0.bn3.running_mean, incre_modules.2.0.bn3.running_var, incre_modules.2.0.bn3.num_batches_tracked, incre_modules.2.0.downsample.0.weight, incre_modules.2.0.downsample.1.weight, incre_modules.2.0.downsample.1.bias, incre_modules.2.0.downsample.1.running_mean, incre_modules.2.0.downsample.1.running_var, incre_modules.2.0.downsample.1.num_batches_tracked, incre_modules.3.0.conv1.weight, incre_modules.3.0.bn1.weight, incre_modules.3.0.bn1.bias, incre_modules.3.0.bn1.running_mean, incre_modules.3.0.bn1.running_var, incre_modules.3.0.bn1.num_batches_tracked, incre_modules.3.0.conv2.weight, incre_modules.3.0.bn2.weight, incre_modules.3.0.bn2.bias, incre_modules.3.0.bn2.running_mean, incre_modules.3.0.bn2.running_var, incre_modules.3.0.bn2.num_batches_tracked, incre_modules.3.0.conv3.weight, incre_modules.3.0.bn3.weight, incre_modules.3.0.bn3.bias, incre_modules.3.0.bn3.running_mean, incre_modules.3.0.bn3.running_var, incre_modules.3.0.bn3.num_batches_tracked, incre_modules.3.0.downsample.0.weight, incre_modules.3.0.downsample.1.weight, incre_modules.3.0.downsample.1.bias, incre_modules.3.0.downsample.1.running_mean, incre_modules.3.0.downsample.1.running_var, incre_modules.3.0.downsample.1.num_batches_tracked, downsamp_modules.0.0.weight, downsamp_modules.0.0.bias, downsamp_modules.0.1.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.1.0.weight, downsamp_modules.1.0.bias, downsamp_modules.1.1.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.2.0.weight, downsamp_modules.2.0.bias, downsamp_modules.2.1.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.num_batches_tracked, final_layer.0.weight, final_layer.0.bias, final_layer.1.weight, final_layer.1.bias, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.num_batches_tracked, classifier.weight, classifier.bias

2021-09-29 13:41:13,371 - mmdet - INFO - initialize HRFPN with init_cfg {'type': 'Caffe2Xavier', 'layer': 'Conv2d'}
2021-09-29 13:41:13,395 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2021-09-29 13:41:13,403 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 13:41:13,723 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 13:41:14,041 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 13:41:17,900 - mmdet - INFO - Start running, host: root@965f40750ba2, work_dir: /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/work_dirs/hrn_cascade_16_cutout_832ms
2021-09-29 13:41:17,900 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_run:
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
2021-09-29 13:41:17,901 - mmdet - INFO - workflow: [('train', 1)], max: 50 epochs
wandb: Currently logged in as: ark10806 (use `wandb login --relogin` to force relogin)
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
wandb: Tracking run with wandb version 0.12.2
wandb: Syncing run hrn_cascade_16_cutout_832ms
wandb:  View project at https://wandb.ai/ark10806/P-stage2-detection
wandb:  View run at https://wandb.ai/ark10806/P-stage2-detection/runs/2aun1f54
wandb: Run data is saved locally in /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/wandb/run-20210929_134118-2aun1f54
wandb: Run `wandb offline` to turn off syncing.

/opt/conda/envs/psc/lib/python3.8/site-packages/torch/nn/functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn("Default upsampling behavior when mode={} is changed "
/opt/conda/envs/psc/lib/python3.8/site-packages/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` 
  warnings.warn('``grid_anchors`` would be deprecated soon. '
/opt/conda/envs/psc/lib/python3.8/site-packages/mmdet/core/anchor/anchor_generator.py:360: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` 
  warnings.warn(
2021-09-29 13:41:54,178 - mmdet - INFO - Epoch [1][10/245]	lr: 1.162e-05, eta: 10:10:01, time: 2.990, data_time: 0.290, memory: 29912, loss_rpn_cls: 0.6826, loss_rpn_bbox: 55.9414, s0.loss_cls: 2.7836, s0.acc: 7.3828, s0.loss_bbox: 460.8836, s1.loss_cls: 1.1381, s1.acc: 23.7122, s1.loss_bbox: 127.4493, s2.loss_cls: 0.6255, s2.acc: 8.1152, s2.loss_bbox: 198.1467, loss: 847.6509, grad_norm: 82597.0092
2021-09-29 13:42:21,732 - mmdet - INFO - Epoch [1][20/245]	lr: 1.342e-05, eta: 9:45:34, time: 2.755, data_time: 0.027, memory: 29912, loss_rpn_cls: 0.6804, loss_rpn_bbox: 6.6012, s0.loss_cls: 1.0945, s0.acc: 67.2754, s0.loss_bbox: 0.4542, s1.loss_cls: 0.3417, s1.acc: 84.6619, s1.loss_bbox: 0.0227, s2.loss_cls: 0.2932, s2.acc: 59.7144, s2.loss_bbox: 0.0113, loss: 9.4993, grad_norm: 3369.7805
/opt/conda/envs/psc/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2021-09-29 13:43:23,332 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.0a0
OpenCV: 4.5.3
MMCV: 1.3.14
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMDetection: 2.16.0+fd9f35b
------------------------------------------------------------

2021-09-29 13:43:24,447 - mmdet - INFO - Distributed training: False
2021-09-29 13:43:25,698 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '/opt/ml/detection/dataset/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
imsize = 800
multi_scale_dict = [
    dict(type='Resize', height=384, width=384),
    dict(type='Resize', height=416, width=416),
    dict(type='Resize', height=448, width=448),
    dict(type='Resize', height=480, width=480),
    dict(type='Resize', height=512, width=512),
    dict(type='Resize', height=544, width=544),
    dict(type='Resize', height=576, width=576),
    dict(type='Resize', height=608, width=608),
    dict(type='Resize', height=640, width=640),
    dict(type='Resize', height=672, width=672),
    dict(type='Resize', height=704, width=704),
    dict(type='Resize', height=736, width=736),
    dict(type='Resize', height=768, width=768),
    dict(type='Resize', height=800, width=800)
]
i = 800
alb_transform = [
    dict(
        type='OneOf',
        transforms=[
            dict(type='Resize', height=384, width=384),
            dict(type='Resize', height=416, width=416),
            dict(type='Resize', height=448, width=448),
            dict(type='Resize', height=480, width=480),
            dict(type='Resize', height=512, width=512),
            dict(type='Resize', height=544, width=544),
            dict(type='Resize', height=576, width=576),
            dict(type='Resize', height=608, width=608),
            dict(type='Resize', height=640, width=640),
            dict(type='Resize', height=672, width=672),
            dict(type='Resize', height=704, width=704),
            dict(type='Resize', height=736, width=736),
            dict(type='Resize', height=768, width=768),
            dict(type='Resize', height=800, width=800)
        ],
        p=1.0),
    dict(
        type='OneOf',
        transforms=[
            dict(type='GaussNoise', p=1.0),
            dict(type='GaussianBlur', p=1.0),
            dict(type='Blur', p=1.0)
        ],
        p=0.1),
    dict(
        type='OneOf',
        transforms=[
            dict(type='CLAHE', p=1.0),
            dict(type='RandomGamma', p=1.0),
            dict(type='HueSaturationValue', p=1.0),
            dict(type='ChannelDropout', p=1.0),
            dict(type='ChannelShuffle', p=1.0),
            dict(type='RGBShift', p=1.0)
        ],
        p=0.1),
    dict(
        type='OneOf',
        transforms=[
            dict(type='ShiftScaleRotate', p=1.0),
            dict(type='Rotate', p=1.0)
        ],
        p=0.1)
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(800, 800)),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Resize', height=384, width=384),
                    dict(type='Resize', height=416, width=416),
                    dict(type='Resize', height=448, width=448),
                    dict(type='Resize', height=480, width=480),
                    dict(type='Resize', height=512, width=512),
                    dict(type='Resize', height=544, width=544),
                    dict(type='Resize', height=576, width=576),
                    dict(type='Resize', height=608, width=608),
                    dict(type='Resize', height=640, width=640),
                    dict(type='Resize', height=672, width=672),
                    dict(type='Resize', height=704, width=704),
                    dict(type='Resize', height=736, width=736),
                    dict(type='Resize', height=768, width=768),
                    dict(type='Resize', height=800, width=800)
                ],
                p=1.0),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='GaussNoise', p=1.0),
                    dict(type='GaussianBlur', p=1.0),
                    dict(type='Blur', p=1.0)
                ],
                p=0.1),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='CLAHE', p=1.0),
                    dict(type='RandomGamma', p=1.0),
                    dict(type='HueSaturationValue', p=1.0),
                    dict(type='ChannelDropout', p=1.0),
                    dict(type='ChannelShuffle', p=1.0),
                    dict(type='RGBShift', p=1.0)
                ],
                p=0.1),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='ShiftScaleRotate', p=1.0),
                    dict(type='Rotate', p=1.0)
                ],
                p=0.1)
        ],
        bbox_params=dict(
            type='BboxParams',
            format='pascal_voc',
            label_fields=['gt_labels'],
            min_visibility=0.0,
            filter_lost_elements=True),
        keymap=dict(img='image', gt_bboxes='bboxes'),
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(type='CutOut', n_holes=4, cutout_shape=(30, 30)),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
classes = ('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',
           'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/train_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(800, 800)),
            dict(
                type='Albu',
                transforms=[
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Resize', height=384, width=384),
                            dict(type='Resize', height=416, width=416),
                            dict(type='Resize', height=448, width=448),
                            dict(type='Resize', height=480, width=480),
                            dict(type='Resize', height=512, width=512),
                            dict(type='Resize', height=544, width=544),
                            dict(type='Resize', height=576, width=576),
                            dict(type='Resize', height=608, width=608),
                            dict(type='Resize', height=640, width=640),
                            dict(type='Resize', height=672, width=672),
                            dict(type='Resize', height=704, width=704),
                            dict(type='Resize', height=736, width=736),
                            dict(type='Resize', height=768, width=768),
                            dict(type='Resize', height=800, width=800)
                        ],
                        p=1.0),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='GaussNoise', p=1.0),
                            dict(type='GaussianBlur', p=1.0),
                            dict(type='Blur', p=1.0)
                        ],
                        p=0.1),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='CLAHE', p=1.0),
                            dict(type='RandomGamma', p=1.0),
                            dict(type='HueSaturationValue', p=1.0),
                            dict(type='ChannelDropout', p=1.0),
                            dict(type='ChannelShuffle', p=1.0),
                            dict(type='RGBShift', p=1.0)
                        ],
                        p=0.1),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='ShiftScaleRotate', p=1.0),
                            dict(type='Rotate', p=1.0)
                        ],
                        p=0.1)
                ],
                bbox_params=dict(
                    type='BboxParams',
                    format='pascal_voc',
                    label_fields=['gt_labels'],
                    min_visibility=0.0,
                    filter_lost_elements=True),
                keymap=dict(img='image', gt_bboxes='bboxes'),
                update_pad_shape=False,
                skip_img_without_anno=True),
            dict(type='CutOut', n_holes=4, cutout_shape=(30, 30)),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/val_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        ann_file='/opt/ml/detection/dataset/val_v1.json',
        img_prefix='/opt/ml/detection/dataset/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
lr = 0.0001
optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.1,
    min_lr_ratio=1e-06)
total_epochs = 50
expr_name = 'hrn_cascade_16_cutout_384_800ms'
dist_params = dict(backend='nccl')
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=10,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(
            type='WandbLoggerHook',
            init_kwargs=dict(
                project='P-stage2-detection',
                name='hrn_cascade_16_cutout_384_800ms'))
    ])
custom_hooks = [dict(type='NumClassCheckHook')]
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
runner = dict(type='EpochBasedRunner', max_epochs=50)
work_dir = './work_dirs/hrn_cascade_16_cutout_384_800ms'
gpu_ids = range(0, 1)
model = dict(
    type='CascadeRCNN',
    backbone=dict(
        type='HRNet',
        extra=dict(
            stage1=dict(
                num_modules=1,
                num_branches=1,
                block='BOTTLENECK',
                num_blocks=(4, ),
                num_channels=(64, )),
            stage2=dict(
                num_modules=1,
                num_branches=2,
                block='BASIC',
                num_blocks=(4, 4),
                num_channels=(18, 36)),
            stage3=dict(
                num_modules=4,
                num_branches=3,
                block='BASIC',
                num_blocks=(4, 4, 4),
                num_channels=(18, 36, 72)),
            stage4=dict(
                num_modules=3,
                num_branches=4,
                block='BASIC',
                num_blocks=(4, 4, 4, 4),
                num_channels=(18, 36, 72, 144))),
        init_cfg=dict(
            type='Pretrained', checkpoint='open-mmlab://msra/hrnetv2_w18')),
    neck=dict(
        type='HRFPN',
        in_channels=[18, 36, 72, 144],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='DIoULoss', loss_weight=2.5)),
    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=2.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=2.5)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='DIoULoss', loss_weight=3.0))
        ]),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=30),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=30),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=71)))

/opt/conda/envs/psc/lib/python3.8/site-packages/mmdet/core/anchor/builder.py:16: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` 
  warnings.warn(
2021-09-29 13:43:26,384 - mmdet - INFO - initialize HRNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://msra/hrnetv2_w18'}
2021-09-29 13:43:26,384 - mmcv - INFO - load model from: open-mmlab://msra/hrnetv2_w18
2021-09-29 13:43:26,385 - mmcv - INFO - Use load_from_openmmlab loader
2021-09-29 13:43:26,820 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: incre_modules.0.0.conv1.weight, incre_modules.0.0.bn1.weight, incre_modules.0.0.bn1.bias, incre_modules.0.0.bn1.running_mean, incre_modules.0.0.bn1.running_var, incre_modules.0.0.bn1.num_batches_tracked, incre_modules.0.0.conv2.weight, incre_modules.0.0.bn2.weight, incre_modules.0.0.bn2.bias, incre_modules.0.0.bn2.running_mean, incre_modules.0.0.bn2.running_var, incre_modules.0.0.bn2.num_batches_tracked, incre_modules.0.0.conv3.weight, incre_modules.0.0.bn3.weight, incre_modules.0.0.bn3.bias, incre_modules.0.0.bn3.running_mean, incre_modules.0.0.bn3.running_var, incre_modules.0.0.bn3.num_batches_tracked, incre_modules.0.0.downsample.0.weight, incre_modules.0.0.downsample.1.weight, incre_modules.0.0.downsample.1.bias, incre_modules.0.0.downsample.1.running_mean, incre_modules.0.0.downsample.1.running_var, incre_modules.0.0.downsample.1.num_batches_tracked, incre_modules.1.0.conv1.weight, incre_modules.1.0.bn1.weight, incre_modules.1.0.bn1.bias, incre_modules.1.0.bn1.running_mean, incre_modules.1.0.bn1.running_var, incre_modules.1.0.bn1.num_batches_tracked, incre_modules.1.0.conv2.weight, incre_modules.1.0.bn2.weight, incre_modules.1.0.bn2.bias, incre_modules.1.0.bn2.running_mean, incre_modules.1.0.bn2.running_var, incre_modules.1.0.bn2.num_batches_tracked, incre_modules.1.0.conv3.weight, incre_modules.1.0.bn3.weight, incre_modules.1.0.bn3.bias, incre_modules.1.0.bn3.running_mean, incre_modules.1.0.bn3.running_var, incre_modules.1.0.bn3.num_batches_tracked, incre_modules.1.0.downsample.0.weight, incre_modules.1.0.downsample.1.weight, incre_modules.1.0.downsample.1.bias, incre_modules.1.0.downsample.1.running_mean, incre_modules.1.0.downsample.1.running_var, incre_modules.1.0.downsample.1.num_batches_tracked, incre_modules.2.0.conv1.weight, incre_modules.2.0.bn1.weight, incre_modules.2.0.bn1.bias, incre_modules.2.0.bn1.running_mean, incre_modules.2.0.bn1.running_var, incre_modules.2.0.bn1.num_batches_tracked, incre_modules.2.0.conv2.weight, incre_modules.2.0.bn2.weight, incre_modules.2.0.bn2.bias, incre_modules.2.0.bn2.running_mean, incre_modules.2.0.bn2.running_var, incre_modules.2.0.bn2.num_batches_tracked, incre_modules.2.0.conv3.weight, incre_modules.2.0.bn3.weight, incre_modules.2.0.bn3.bias, incre_modules.2.0.bn3.running_mean, incre_modules.2.0.bn3.running_var, incre_modules.2.0.bn3.num_batches_tracked, incre_modules.2.0.downsample.0.weight, incre_modules.2.0.downsample.1.weight, incre_modules.2.0.downsample.1.bias, incre_modules.2.0.downsample.1.running_mean, incre_modules.2.0.downsample.1.running_var, incre_modules.2.0.downsample.1.num_batches_tracked, incre_modules.3.0.conv1.weight, incre_modules.3.0.bn1.weight, incre_modules.3.0.bn1.bias, incre_modules.3.0.bn1.running_mean, incre_modules.3.0.bn1.running_var, incre_modules.3.0.bn1.num_batches_tracked, incre_modules.3.0.conv2.weight, incre_modules.3.0.bn2.weight, incre_modules.3.0.bn2.bias, incre_modules.3.0.bn2.running_mean, incre_modules.3.0.bn2.running_var, incre_modules.3.0.bn2.num_batches_tracked, incre_modules.3.0.conv3.weight, incre_modules.3.0.bn3.weight, incre_modules.3.0.bn3.bias, incre_modules.3.0.bn3.running_mean, incre_modules.3.0.bn3.running_var, incre_modules.3.0.bn3.num_batches_tracked, incre_modules.3.0.downsample.0.weight, incre_modules.3.0.downsample.1.weight, incre_modules.3.0.downsample.1.bias, incre_modules.3.0.downsample.1.running_mean, incre_modules.3.0.downsample.1.running_var, incre_modules.3.0.downsample.1.num_batches_tracked, downsamp_modules.0.0.weight, downsamp_modules.0.0.bias, downsamp_modules.0.1.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.1.0.weight, downsamp_modules.1.0.bias, downsamp_modules.1.1.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.2.0.weight, downsamp_modules.2.0.bias, downsamp_modules.2.1.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.num_batches_tracked, final_layer.0.weight, final_layer.0.bias, final_layer.1.weight, final_layer.1.bias, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.num_batches_tracked, classifier.weight, classifier.bias

2021-09-29 13:43:26,910 - mmdet - INFO - initialize HRFPN with init_cfg {'type': 'Caffe2Xavier', 'layer': 'Conv2d'}
2021-09-29 13:43:26,935 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2021-09-29 13:43:26,943 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 13:43:27,259 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 13:43:27,577 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-09-29 13:43:31,811 - mmdet - INFO - Start running, host: root@965f40750ba2, work_dir: /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/work_dirs/hrn_cascade_16_cutout_384_800ms
2021-09-29 13:43:31,812 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_run:
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
2021-09-29 13:43:31,812 - mmdet - INFO - workflow: [('train', 1)], max: 50 epochs
wandb: Currently logged in as: ark10806 (use `wandb login --relogin` to force relogin)
loading annotations into memory...
Done (t=0.06s)
creating index...
index created!
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
wandb: Tracking run with wandb version 0.12.2
wandb: Syncing run hrn_cascade_16_cutout_384_800ms
wandb:  View project at https://wandb.ai/ark10806/P-stage2-detection
wandb:  View run at https://wandb.ai/ark10806/P-stage2-detection/runs/1hadtheg
wandb: Run data is saved locally in /opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/wandb/run-20210929_134332-1hadtheg
wandb: Run `wandb offline` to turn off syncing.

/opt/conda/envs/psc/lib/python3.8/site-packages/torch/nn/functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn("Default upsampling behavior when mode={} is changed "
/opt/conda/envs/psc/lib/python3.8/site-packages/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` 
  warnings.warn('``grid_anchors`` would be deprecated soon. '
/opt/conda/envs/psc/lib/python3.8/site-packages/mmdet/core/anchor/anchor_generator.py:360: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` 
  warnings.warn(
2021-09-29 13:44:07,904 - mmdet - INFO - Epoch [1][10/245]	lr: 1.162e-05, eta: 10:01:47, time: 2.950, data_time: 0.315, memory: 29901, loss_rpn_cls: 0.6869, loss_rpn_bbox: 19.3267, s0.loss_cls: 1.2895, s0.acc: 63.2739, s0.loss_bbox: 522.4111, s1.loss_cls: 1.1838, s1.acc: 35.5627, s1.loss_bbox: 88.6435, s2.loss_cls: 0.2705, s2.acc: 72.8357, s2.loss_bbox: 0.0106, loss: 633.8226, grad_norm: 86703.2969
2021-09-29 13:44:34,549 - mmdet - INFO - Epoch [1][20/245]	lr: 1.342e-05, eta: 9:32:12, time: 2.664, data_time: 0.027, memory: 29901, loss_rpn_cls: 0.6804, loss_rpn_bbox: 9.2874, s0.loss_cls: 0.3756, s0.acc: 89.4226, s0.loss_bbox: 139.8389, s1.loss_cls: 0.3499, s1.acc: 78.4814, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0201, s2.acc: 99.0320, s2.loss_bbox: 0.0079, loss: 150.5890, grad_norm: 17592.3363
2021-09-29 13:45:01,131 - mmdet - INFO - Epoch [1][30/245]	lr: 1.522e-05, eta: 9:21:37, time: 2.658, data_time: 0.026, memory: 29901, loss_rpn_cls: 0.6492, loss_rpn_bbox: 0.2686, s0.loss_cls: 0.2466, s0.acc: 96.4075, s0.loss_bbox: 0.0829, s1.loss_cls: 0.0700, s1.acc: 98.4570, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0187, s2.acc: 98.9648, s2.loss_bbox: 0.0079, loss: 1.3704, grad_norm: 5.1977
2021-09-29 13:45:28,865 - mmdet - INFO - Epoch [1][40/245]	lr: 1.702e-05, eta: 9:21:58, time: 2.773, data_time: 0.026, memory: 29901, loss_rpn_cls: 0.5686, loss_rpn_bbox: 0.2246, s0.loss_cls: 0.2252, s0.acc: 96.4160, s0.loss_bbox: 0.0767, s1.loss_cls: 0.0683, s1.acc: 98.3655, s1.loss_bbox: 0.0221, s2.loss_cls: 0.0198, s2.acc: 98.8940, s2.loss_bbox: 0.0084, loss: 1.2137, grad_norm: 3.6839
2021-09-29 13:45:54,820 - mmdet - INFO - Epoch [1][50/245]	lr: 1.882e-05, eta: 9:14:45, time: 2.596, data_time: 0.026, memory: 29901, loss_rpn_cls: 0.4559, loss_rpn_bbox: 0.1675, s0.loss_cls: 0.1946, s0.acc: 96.6089, s0.loss_bbox: 0.0709, s1.loss_cls: 0.0537, s1.acc: 98.5754, s1.loss_bbox: 0.0185, s2.loss_cls: 0.0167, s2.acc: 99.0100, s2.loss_bbox: 0.0073, loss: 0.9851, grad_norm: 3.7008
Traceback (most recent call last):
  File "tools/train.py", line 189, in <module>
    main()
  File "tools/train.py", line 178, in main
    train_detector(
  File "/opt/conda/envs/psc/lib/python3.8/site-packages/mmdet/apis/train.py", line 174, in train_detector
    runner.run(data_loaders, cfg.workflow)
  File "/opt/conda/envs/psc/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py", line 127, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/opt/conda/envs/psc/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py", line 51, in train
    self.call_hook('after_train_iter')
  File "/opt/conda/envs/psc/lib/python3.8/site-packages/mmcv/runner/base_runner.py", line 307, in call_hook
    getattr(hook, fn_name)(self)
  File "/opt/conda/envs/psc/lib/python3.8/site-packages/mmcv/runner/hooks/logger/base.py", line 152, in after_train_iter
    self.log(runner)
  File "/opt/conda/envs/psc/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py", line 178, in log
    self._dump_log(log_dict, runner)
  File "/opt/conda/envs/psc/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py", line 135, in _dump_log
    with open(self.json_log_path, 'a+') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/detection/object-detection-level2-cv-03/1Phase/mmdetection/work_dirs/hrn_cascade_16_cutout_384_800ms/20210929_134323.log.json'
wandb: Waiting for W&B process to finish, PID 1477
wandb: Program failed with code 1.  Press ctrl-c to abort syncing.
